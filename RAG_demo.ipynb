{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65873,"status":"ok","timestamp":1755849358866,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"qdOLlUP1pq4q","outputId":"f8fca1fa-d649-432f-84b0-f5aace7318bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m737.3/981.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install langchain langchain-community openai tiktoken unstructured chromadb --quiet\n","!pip install beautifulsoup4 requests --quiet\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20259,"status":"ok","timestamp":1755849379765,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"MLtZdJSMuG5s","outputId":"fa4e1f17-4163-48cb-c71f-5c83def29df6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install langchain-google-genai faiss-cpu pypdf langchain  --quiet\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16953,"status":"ok","timestamp":1755849396713,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"-Ph-twlpu8LW","outputId":"1da342b0-6f2f-4478-a6bf-92d1e273be0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15 langchain-google-genai faiss-cpu pypdf langchain --quiet\n"]},{"cell_type":"markdown","metadata":{"id":"VGlenoMSFA34"},"source":["# single page scrape for demo"]},{"cell_type":"markdown","metadata":{"id":"SkdmRavPtERh"},"source":["## Website scraping"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1745,"status":"ok","timestamp":1754662214554,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"UhrXDJ37s8W7","outputId":"b50ee766-f24d-4391-d287-db3d189c302e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\n","\n","\n","\n","Building A Generative AI Platform\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Building A Generative AI Platform | Chip Huyen\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Chip Huyen\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Blog\n","Books\n","Events\n","\n","AI Guide\n","\n","AI Roadmap\n","Llama Police\n","ML Interviews\n","\n","\n","List 100\n","VN\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Table of Contents\n","\n","Step 1. Enhance Context\n","\n","RAGs\n","\n","RAGs with tabular data\n","Agentic RAGs\n","\n","\n","Query rewriting\n","\n","Step 2. Put in Guardrails\n","\n","Input guardrails\n","\n","Leaking private information to external APIs\n","Model jailbreaking\n","\n","\n","Output guardrails\n","\n","Output quality measurement\n","Failure management\n","\n","\n","Guardrail tradeoffs\n","\n","Step 3. Add Model Router and Gateway\n","\n","Router\n","Gateway\n","\n","Step 4. Reduce Latency with Cache\n","\n","Prompt cache\n","Exact cache\n","Semantic cache\n","\n","Step 5. Add Complex Logic and Write Actions\n","\n","Complex logic\n","Write actions\n","\n","Observability\n","\n","Metrics\n","Logs\n","Traces\n","\n","AI Pipeline Orchestration\n","Conclusion\n","References and Acknowledgments\n","\n","\n","\n","    Table of Contents \n","\n","\n","\n","\n","Building A Generative AI Platform\n","\n","\n","        \n","        Jul 25, 2024\n","      \n","      \n","        • Chip Huyen\n","\n","\n","\n","After stu\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","\n","url = \"https://huyenchip.com/2024/07/25/genai-platform.html\"\n","html = requests.get(url).text\n","soup = BeautifulSoup(html, \"html.parser\")\n","text = soup.get_text()\n","print(text[:1000])  # just preview\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3178,"status":"ok","timestamp":1754662222236,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"0myrXgaLtdLP","outputId":"68bb76d2-f623-4d99-deb5-271cbca75e6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Setup successful ✅\n"]}],"source":["import google.generativeai as genai\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","print(\"Setup successful ✅\")\n"]},{"cell_type":"markdown","metadata":{"id":"OaAgKJWiBb6c"},"source":["##  Wrap the scraped text as a LangChain Document"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYvUenGEvQEP"},"outputs":[],"source":["from langchain.docstore.document import Document\n","\n","docs = [Document(page_content=text, metadata={\"source\": url})]\n"]},{"cell_type":"markdown","metadata":{"id":"drIfdpuMBimY"},"source":["## Split the document into chunks"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1754662346559,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"X5Js16B_BTHK","outputId":"29345e5a-1b38-4240-ebd4-8441d27e8b9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of chunks: 74\n","Building A Generative AI Platform\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Building A Generative AI Platform | Chip Huyen\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Chip Huyen\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Blog\n","Books\n","Events\n","\n","AI Guide\n","\n","AI Roadmap\n","Llama Police\n","ML\n"]}],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,  # characters\n","    chunk_overlap=200\n",")\n","\n","chunks = text_splitter.split_documents(docs)\n","print(f\"Number of chunks: {len(chunks)}\")\n","print(chunks[0].page_content[:200])\n"]},{"cell_type":"markdown","metadata":{"id":"GC-CctNpB4Ob"},"source":["## Create Embeddings + Store in FAISS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gdBgHl-_Bp06"},"outputs":[],"source":["from langchain_google_genai import GoogleGenerativeAIEmbeddings\n","from langchain_community.vectorstores import FAISS\n","\n","# 1️⃣ Create the embedding model\n","embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","\n","# 2️⃣ Create FAISS vector store from chunks\n","vectorstore = FAISS.from_documents(chunks, embedding_model)\n","\n","# 3️⃣ Save the FAISS index locally (optional)\n","vectorstore.save_local(\"faiss_index\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8830,"status":"ok","timestamp":1754662510297,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"f9b8614d","outputId":"182401c4-d81e-4315-9397-96577fe001de"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install --upgrade --quiet  langchain-community"]},{"cell_type":"markdown","metadata":{"id":"qq4IvCK1Cj6e"},"source":["## Load FAISS and Ask Questions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1754662605973,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"CiiNke7UCkji","outputId":"2e48f9a7-9825-4602-b0d3-7169564da8cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Result 1:\n","Table of Contents \n","\n","\n","\n","\n","Building A Generative AI Platform\n","\n","\n","        \n","        Jul 25, 2024\n","      \n","      \n","        • Chip Huyen\n","\n","\n","\n","After studying how companies deploy generative AI applications, I noticed many similarities in their platforms. This post outlines the common components of a generative AI p\n","---\n","Result 2:\n","Our platform now looks like this. Guardrails can be independent tools or parts of model gateways, as discussed later. Scorers, if used, are grouped under model APIs since scorers are typically AI models, too. Models used for scoring are typically smaller and faster than models used for generation.\n","---\n","Result 3:\n","Building A Generative AI Platform\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Building A Generative AI Platform | Chip Huyen\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Chip Huyen\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Blog\n","Books\n","Events\n","\n","AI Guide\n","\n","AI Roadmap\n","Llama Police\n","ML Interviews\n","\n","\n","List 100\n","VN\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","Table of Contents\n","\n","Step 1. Enhance Context\n","\n","RAGs\n","\n","RAGs with t\n","---\n"]}],"source":["# Load the vectorstore\n","vectorstore = FAISS.load_local(\"faiss_index\", embedding_model, allow_dangerous_deserialization=True)\n","\n","# Search for similar chunks\n","query = \"What is a GenAI platform?\"\n","docs = vectorstore.similarity_search(query, k=3)\n","\n","for i, doc in enumerate(docs, start=1):\n","    print(f\"Result {i}:\")\n","    print(doc.page_content[:300])\n","    print(\"---\")\n"]},{"cell_type":"markdown","metadata":{"id":"Uy87gll9C80a"},"source":["## Use LLM for Final Answer (RAG)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1299,"status":"ok","timestamp":1754662769740,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"o0lCu4-5CpIP","outputId":"28017a0b-bf15-45bc-c82c-71ccc0b78090"},"outputs":[{"name":"stdout","output_type":"stream","text":["Answer: Based on the provided text, a GenAI platform is a system that receives a query, sends it to a model (which can be a third-party API like OpenAI or Google, or a self-hosted API), receives a response from the model, and returns that response to the user.  More complex platforms can include additional components like guardrails, context enhancement, model routers, gateways, caching, and mechanisms for complex logic and write actions.\n","\n","Sources: ['https://huyenchip.com/2024/07/25/genai-platform.html', 'https://huyenchip.com/2024/07/25/genai-platform.html', 'https://huyenchip.com/2024/07/25/genai-platform.html', 'https://huyenchip.com/2024/07/25/genai-platform.html']\n"]}],"source":["from langchain.chains import RetrievalQA\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n","\n","\n","# Create RetrievalQA chain\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    retriever=vectorstore.as_retriever(),\n","    return_source_documents=True\n",")\n","\n","# Ask a question\n","response = qa_chain({\"query\": \"What is a GenAI platform?\"})\n","print(\"Answer:\", response[\"result\"])\n","print(\"\\nSources:\", [doc.metadata[\"source\"] for doc in response[\"source_documents\"]])\n"]},{"cell_type":"markdown","metadata":{"id":"faxxlhzmFRdW"},"source":["## Minimal working RAG pipeline"]},{"cell_type":"markdown","metadata":{"id":"Vl16-9NEFb5w"},"source":["## Multi-URL Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4P4ulJWFczN"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","\n","def scrape_url(url):\n","    html = requests.get(url).text\n","    soup = BeautifulSoup(html, \"html.parser\")\n","    return soup.get_text(separator=\"\\n\")\n","\n","urls = [\n","    \"https://huyenchip.com/2024/07/25/genai-platform.html\",\n","    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n","    \"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/\",\n","    \"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\"\n","]\n","\n","documents = []\n","for url in urls:\n","    text = scrape_url(url)\n","    documents.append({\"url\": url, \"text\": text})\n"]},{"cell_type":"markdown","metadata":{"id":"gIXaCaoGIDxn"},"source":["## Chunking"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crYMyCN-IAfE"},"outputs":[],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=200\n",")\n","\n","chunks = []\n","for doc in documents:\n","    for chunk in text_splitter.split_text(doc[\"text\"]):\n","        chunks.append({\"text\": chunk, \"url\": doc[\"url\"]})\n"]},{"cell_type":"markdown","metadata":{"id":"L26jiyuzINDE"},"source":["## Embeddings + Vector Store (FAISS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJvPDJv7IJr8"},"outputs":[],"source":["from langchain_community.vectorstores import FAISS\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings\n","\n","embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","\n","texts = [c[\"text\"] for c in chunks]\n","metadatas = [{\"url\": c[\"url\"]} for c in chunks]\n","\n","vectorstore = FAISS.from_texts(texts, embedding_model, metadatas=metadatas)\n"]},{"cell_type":"markdown","metadata":{"id":"iw8l3chlIXtM"},"source":["## Retrieval + LLM Answer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1646,"status":"ok","timestamp":1754664120658,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"SIb5BBTKIP6_","outputId":"fbf77120-03ad-4612-f3f1-7e632156797f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-790224973.py:11: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  response = llm.predict(prompt)\n"]},{"name":"stdout","output_type":"stream","text":["Based on the provided text, a GenAI platform is a system with common components that allow for the deployment of generative AI applications.  The article outlines a typical architecture including a model gateway, routers, caching mechanisms, and guardrails (input and output).  The architecture is described in detail across several steps (Step 1-5)  and illustrated with code examples showing how a model gateway might interact with different APIs (OpenAI and Google's Gemini).  The author states that many similarities exist in how companies deploy these applications, leading to the outlined common components. (Paragraph beginning \"After studying...\")\n","Sources: ['https://huyenchip.com/2024/07/25/genai-platform.html']\n"]}],"source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n","\n","def answer_query(query):\n","    docs = vectorstore.similarity_search(query, k=4)\n","    context = \"\\n\\n\".join([d.page_content for d in docs])\n","    sources = [d.metadata[\"url\"] for d in docs]\n","\n","    prompt = f\"Answer the question based on the following context:\\n\\n{context}\\n\\nQuestion: {query}\\nAnswer with citations.\"\n","    response = llm.predict(prompt)\n","    return response, list(set(sources))\n","\n","question = \"What is a GenAI platform?\"\n","answer, sources = answer_query(question)\n","print(answer)\n","print(\"Sources:\", sources)\n"]},{"cell_type":"markdown","metadata":{"id":"PFWPuXCKJozv"},"source":["## Structure the Pipeline Properly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DphszFQ2Iakv"},"outputs":[],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain_google_genai import GoogleGenerativeAIEmbeddings\n","\n","# 1. Split text\n","splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","chunks = splitter.split_text(text)\n","\n","# 2. Create embeddings\n","embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","\n","# 3. Store in FAISS\n","db = FAISS.from_texts(chunks, embeddings)\n"]},{"cell_type":"markdown","metadata":{"id":"WOpDbfduKIxt"},"source":["## Add the Retrieval Step\n","When a user asks something:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":807,"status":"ok","timestamp":1754664582482,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"YQFV9F31KAOd","outputId":"e8ee5107-3290-4d8d-d369-f237c2e3d0ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["content='The provided text does not contain information about GenAI platforms.  Therefore, I cannot answer your question using the given context.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--a31e5e8b-fbcd-4062-a464-e625226196f4-0' usage_metadata={'input_tokens': 55, 'output_tokens': 26, 'total_tokens': 81, 'input_token_details': {'cache_read': 0}}\n"]}],"source":["query = \"What is a GenAI platform?\"\n","docs = db.similarity_search(query, k=3)  # Get top 3 relevant chunks\n","context = \" \".join([d.page_content for d in docs])\n","\n","prompt = f\"Answer based on the following context:\\n{context}\\n\\nQuestion: {query}\"\n","response = llm.invoke(prompt)\n","print(response)\n"]},{"cell_type":"markdown","metadata":{"id":"8Y7DUHh4LB7Q"},"source":["## Wrap scraped text into Document objects"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CAZ2hFCdKLik"},"outputs":[],"source":["from langchain.schema import Document\n","\n","docs = [Document(page_content=text, metadata={\"source\": url})]\n"]},{"cell_type":"markdown","metadata":{"id":"aDwzHzhOLGtg"},"source":["## Chunk the text (so retrieval is more accurate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ny_KwwQK9nL"},"outputs":[],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","chunks = splitter.split_documents(docs)\n"]},{"cell_type":"markdown","metadata":{"id":"Lv7Wfx4tLOi-"},"source":["## Embed chunks and store in FAISS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6Up9Zz1LK4-"},"outputs":[],"source":["from langchain_google_genai import GoogleGenerativeAIEmbeddings\n","from langchain.vectorstores import FAISS\n","\n","embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n","vectorstore = FAISS.from_documents(chunks, embeddings)\n"]},{"cell_type":"markdown","metadata":{"id":"ndpiSPWBLUS4"},"source":["## Create retriever + chain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUlb1QMYLQ-4"},"outputs":[],"source":["retriever = vectorstore.as_retriever()\n"]},{"cell_type":"markdown","metadata":{"id":"k2EO8ZJ6Lb_P"},"source":["## Ask questions with retrieval + Gemini"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2700,"status":"error","timestamp":1754664923308,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"-pI5fHOYLWoq","outputId":"5af8ba29-a374-40a2-e67e-81f8850339f6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-552822111.py:7: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  result = qa_chain.run(\"What is a GenAI platform?\")\n","WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n","  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n","  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n","  quota_dimensions {\n","    key: \"model\"\n","    value: \"gemini-1.5-pro\"\n","  }\n","  quota_dimensions {\n","    key: \"location\"\n","    value: \"global\"\n","  }\n","}\n","violations {\n","  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n","  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n","  quota_dimensions {\n","    key: \"model\"\n","    value: \"gemini-1.5-pro\"\n","  }\n","  quota_dimensions {\n","    key: \"location\"\n","    value: \"global\"\n","  }\n","}\n","violations {\n","  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n","  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n","  quota_dimensions {\n","    key: \"model\"\n","    value: \"gemini-1.5-pro\"\n","  }\n","  quota_dimensions {\n","    key: \"location\"\n","    value: \"global\"\n","  }\n","}\n",", links {\n","  description: \"Learn more about Gemini API quotas\"\n","  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n","}\n",", retry_delay {\n","  seconds: 39\n","}\n","].\n"]},{"ename":"ResourceExhausted","evalue":"429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 37\n}\n]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-552822111.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mqa_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetrievalQA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_chain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is a GenAI platform?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    628\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             ]\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    408\u001b[0m         }\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/retrieval_qa/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         answer = self.combine_documents_chain.run(\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    633\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             ]\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    408\u001b[0m         }\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/combine_documents/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Other keys are assumed to be needed for LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mother_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         output, extra_return_dict = self.combine_docs(\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/combine_documents/stuff.py\u001b[0m in \u001b[0;36mcombine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# Call predict on the LLM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     async def acombine_docs(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    408\u001b[0m         }\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             outputs = (\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     ) -> dict[str, str]:\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    978\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    979\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                 results.append(\n\u001b[0;32m--> 799\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    800\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1046\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mtool_choice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_choice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         )\n\u001b[0;32m--> 961\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m             ) from e\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 37\n}\n]"]}],"source":["from langchain.chains import RetrievalQA\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n","\n","qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n","result = qa_chain.run(\"What is a GenAI platform?\")\n","print(result)\n"]},{"cell_type":"markdown","metadata":{"id":"GogSI1jLvNe1"},"source":["## Step 1 — Data Ingestion from URLs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1732,"status":"ok","timestamp":1754722938777,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"II_LMfGGox89","outputId":"61c17acf-c2fe-4a4b-81bd-4c73ddd53531"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Saved: /content/drive/MyDrive/RAG_demo/data/genai-platform.html.txt\n","✅ Saved: /content/drive/MyDrive/RAG_demo/data/index.txt\n","✅ Saved: /content/drive/MyDrive/RAG_demo/data/index.txt\n","✅ Saved: /content/drive/MyDrive/RAG_demo/data/Building-Embedding-Search-at-Quora.txt\n"]}],"source":["import os\n","import requests\n","from bs4 import BeautifulSoup\n","\n","# Create data folder\n","data_dir = \"/content/drive/MyDrive/RAG_demo/data\"\n","os.makedirs(data_dir, exist_ok=True)\n","\n","urls = [\n","    \"https://huyenchip.com/2024/07/25/genai-platform.html\",\n","    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n","    \"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/\",\n","    \"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\"\n","]\n","\n","def download_webpage(url, save_dir):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        soup = BeautifulSoup(response.text, \"html.parser\")\n","        text = soup.get_text(separator=\"\\n\", strip=True)  # Extract clean text\n","        # Create filename from URL slug\n","        filename = url.split(\"/\")[-1] or \"index\"\n","        if not filename.endswith(\".txt\"):\n","            filename += \".txt\"\n","        save_path = os.path.join(save_dir, filename)\n","        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n","            f.write(text)\n","        print(f\"✅ Saved: {save_path}\")\n","    else:\n","        print(f\"❌ Failed: {url}\")\n","\n","for url in urls:\n","    download_webpage(url, data_dir)\n"]},{"cell_type":"markdown","metadata":{"id":"gebcSF1uvW1f"},"source":["## Render the page (reliable for JS-heavy sites) — use Playwright in Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27281,"status":"ok","timestamp":1754724047025,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"jZXIBpKLsTst","outputId":"701c56da-6988-4002-c36a-507d863b0f56"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting playwright==1.49.0\n","  Downloading playwright-1.49.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n","Collecting greenlet==3.1.1 (from playwright==1.49.0)\n","  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting pyee==12.0.0 (from playwright==1.49.0)\n","  Downloading pyee-12.0.0-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee==12.0.0->playwright==1.49.0) (4.14.1)\n","Downloading playwright-1.49.0-py3-none-manylinux1_x86_64.whl (44.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyee-12.0.0-py3-none-any.whl (14 kB)\n","Installing collected packages: pyee, greenlet, playwright\n","  Attempting uninstall: greenlet\n","    Found existing installation: greenlet 3.2.3\n","    Uninstalling greenlet-3.2.3:\n","      Successfully uninstalled greenlet-3.2.3\n","Successfully installed greenlet-3.1.1 playwright-1.49.0 pyee-12.0.0\n","Downloading Chromium 131.0.6778.33 (playwright build v1148)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1148/chromium-linux.zip\u001b[22m\n","\u001b[1G161.3 MiB [] 0% 10.7s\u001b[0K\u001b[1G161.3 MiB [] 0% 46.8s\u001b[0K\u001b[1G161.3 MiB [] 0% 30.1s\u001b[0K\u001b[1G161.3 MiB [] 0% 19.8s\u001b[0K\u001b[1G161.3 MiB [] 0% 10.7s\u001b[0K\u001b[1G161.3 MiB [] 1% 6.0s\u001b[0K\u001b[1G161.3 MiB [] 2% 4.4s\u001b[0K\u001b[1G161.3 MiB [] 3% 3.6s\u001b[0K\u001b[1G161.3 MiB [] 4% 3.1s\u001b[0K\u001b[1G161.3 MiB [] 5% 2.7s\u001b[0K\u001b[1G161.3 MiB [] 6% 2.5s\u001b[0K\u001b[1G161.3 MiB [] 6% 2.6s\u001b[0K\u001b[1G161.3 MiB [] 6% 2.8s\u001b[0K\u001b[1G161.3 MiB [] 8% 2.3s\u001b[0K\u001b[1G161.3 MiB [] 9% 2.2s\u001b[0K\u001b[1G161.3 MiB [] 9% 2.3s\u001b[0K\u001b[1G161.3 MiB [] 10% 2.3s\u001b[0K\u001b[1G161.3 MiB [] 10% 2.4s\u001b[0K\u001b[1G161.3 MiB [] 11% 2.4s\u001b[0K\u001b[1G161.3 MiB [] 12% 2.2s\u001b[0K\u001b[1G161.3 MiB [] 13% 2.1s\u001b[0K\u001b[1G161.3 MiB [] 14% 2.1s\u001b[0K\u001b[1G161.3 MiB [] 15% 2.0s\u001b[0K\u001b[1G161.3 MiB [] 16% 1.9s\u001b[0K\u001b[1G161.3 MiB [] 17% 1.9s\u001b[0K\u001b[1G161.3 MiB [] 18% 1.8s\u001b[0K\u001b[1G161.3 MiB [] 20% 1.7s\u001b[0K\u001b[1G161.3 MiB [] 21% 1.7s\u001b[0K\u001b[1G161.3 MiB [] 22% 1.6s\u001b[0K\u001b[1G161.3 MiB [] 23% 1.6s\u001b[0K\u001b[1G161.3 MiB [] 24% 1.6s\u001b[0K\u001b[1G161.3 MiB [] 25% 1.5s\u001b[0K\u001b[1G161.3 MiB [] 27% 1.4s\u001b[0K\u001b[1G161.3 MiB [] 28% 1.4s\u001b[0K\u001b[1G161.3 MiB [] 29% 1.4s\u001b[0K\u001b[1G161.3 MiB [] 31% 1.4s\u001b[0K\u001b[1G161.3 MiB [] 32% 1.3s\u001b[0K\u001b[1G161.3 MiB [] 34% 1.2s\u001b[0K\u001b[1G161.3 MiB [] 35% 1.2s\u001b[0K\u001b[1G161.3 MiB [] 37% 1.1s\u001b[0K\u001b[1G161.3 MiB [] 38% 1.1s\u001b[0K\u001b[1G161.3 MiB [] 40% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 42% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 43% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 44% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 45% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 46% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 47% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 48% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 49% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 50% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 52% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 53% 0.8s\u001b[0K\u001b[1G161.3 MiB [] 54% 0.8s\u001b[0K\u001b[1G161.3 MiB [] 55% 0.8s\u001b[0K\u001b[1G161.3 MiB [] 56% 0.8s\u001b[0K\u001b[1G161.3 MiB [] 58% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 60% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 61% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 62% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 64% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 65% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 66% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 67% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 68% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 70% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 71% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 72% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 73% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 74% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 75% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 76% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 77% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 78% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 79% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 80% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 81% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 82% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 83% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 84% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 86% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 87% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 89% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 90% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 92% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 93% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 94% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 95% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 96% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 97% 0.0s\u001b[0K\u001b[1G161.3 MiB [] 99% 0.0s\u001b[0K\u001b[1G161.3 MiB [] 100% 0.0s\u001b[0K\n","Chromium 131.0.6778.33 (playwright build v1148) downloaded to /root/.cache/ms-playwright/chromium-1148\n","Downloading FFMPEG playwright build v1010\u001b[2m from https://playwright.azureedge.net/builds/ffmpeg/1010/ffmpeg-linux.zip\u001b[22m\n","\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 3% 0.6s\u001b[0K\u001b[1G2.3 MiB [] 8% 0.4s\u001b[0K\u001b[1G2.3 MiB [] 16% 0.3s\u001b[0K\u001b[1G2.3 MiB [] 31% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 72% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 90% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 98% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n","FFMPEG playwright build v1010 downloaded to /root/.cache/ms-playwright/ffmpeg-1010\n","Downloading Chromium Headless Shell 131.0.6778.33 (playwright build v1148)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1148/chromium-headless-shell-linux.zip\u001b[22m\n","\u001b[1G100.9 MiB [] 0% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 0% 30.9s\u001b[0K\u001b[1G100.9 MiB [] 0% 22.6s\u001b[0K\u001b[1G100.9 MiB [] 0% 19.4s\u001b[0K\u001b[1G100.9 MiB [] 0% 11.0s\u001b[0K\u001b[1G100.9 MiB [] 1% 7.3s\u001b[0K\u001b[1G100.9 MiB [] 1% 5.0s\u001b[0K\u001b[1G100.9 MiB [] 2% 4.0s\u001b[0K\u001b[1G100.9 MiB [] 3% 4.0s\u001b[0K\u001b[1G100.9 MiB [] 4% 3.4s\u001b[0K\u001b[1G100.9 MiB [] 5% 3.0s\u001b[0K\u001b[1G100.9 MiB [] 6% 2.7s\u001b[0K\u001b[1G100.9 MiB [] 7% 2.4s\u001b[0K\u001b[1G100.9 MiB [] 8% 2.3s\u001b[0K\u001b[1G100.9 MiB [] 9% 2.2s\u001b[0K\u001b[1G100.9 MiB [] 10% 2.3s\u001b[0K\u001b[1G100.9 MiB [] 10% 2.4s\u001b[0K\u001b[1G100.9 MiB [] 11% 2.3s\u001b[0K\u001b[1G100.9 MiB [] 12% 2.3s\u001b[0K\u001b[1G100.9 MiB [] 13% 2.2s\u001b[0K\u001b[1G100.9 MiB [] 15% 2.0s\u001b[0K\u001b[1G100.9 MiB [] 17% 1.9s\u001b[0K\u001b[1G100.9 MiB [] 18% 1.9s\u001b[0K\u001b[1G100.9 MiB [] 19% 1.7s\u001b[0K\u001b[1G100.9 MiB [] 21% 1.6s\u001b[0K\u001b[1G100.9 MiB [] 23% 1.5s\u001b[0K\u001b[1G100.9 MiB [] 24% 1.5s\u001b[0K\u001b[1G100.9 MiB [] 26% 1.4s\u001b[0K\u001b[1G100.9 MiB [] 27% 1.4s\u001b[0K\u001b[1G100.9 MiB [] 28% 1.3s\u001b[0K\u001b[1G100.9 MiB [] 29% 1.3s\u001b[0K\u001b[1G100.9 MiB [] 31% 1.2s\u001b[0K\u001b[1G100.9 MiB [] 33% 1.2s\u001b[0K\u001b[1G100.9 MiB [] 34% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 35% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 36% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 37% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 38% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 39% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 40% 1.0s\u001b[0K\u001b[1G100.9 MiB [] 42% 1.0s\u001b[0K\u001b[1G100.9 MiB [] 44% 1.0s\u001b[0K\u001b[1G100.9 MiB [] 45% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 46% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 47% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 49% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 50% 0.8s\u001b[0K\u001b[1G100.9 MiB [] 52% 0.8s\u001b[0K\u001b[1G100.9 MiB [] 54% 0.7s\u001b[0K\u001b[1G100.9 MiB [] 56% 0.7s\u001b[0K\u001b[1G100.9 MiB [] 58% 0.7s\u001b[0K\u001b[1G100.9 MiB [] 59% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 61% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 63% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 65% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 66% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 68% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 70% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 72% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 73% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 74% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 75% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 76% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 77% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 78% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 79% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 81% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 83% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 85% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 86% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 88% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 90% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 92% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 93% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 94% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 96% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 98% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 100% 0.0s\u001b[0K\n","Chromium Headless Shell 131.0.6778.33 (playwright build v1148) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1148\n"]}],"source":["!pip install playwright==1.49.0  # or latest\n","!playwright install chromium\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4103,"status":"ok","timestamp":1754724115598,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"GWtbb6Tcs6xE","outputId":"8d2ec3a6-6127-4799-af8c-fd3f0d40fbe6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved: /content/drive/MyDrive/RAG_demo/data/quora_engineering.txt\n"]}],"source":["import asyncio\n","from playwright.async_api import async_playwright\n","from bs4 import BeautifulSoup\n","import os\n","\n","async def render_and_save_text(url, save_path):\n","    async with async_playwright() as p:\n","        browser = await p.chromium.launch(headless=True, args=['--no-sandbox','--disable-dev-shm-usage'])\n","        page = await browser.new_page(user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/116\")\n","        await page.goto(url, wait_until=\"networkidle\", timeout=30000)\n","        html = await page.content()\n","        await browser.close()\n","\n","    soup = BeautifulSoup(html, \"html.parser\")\n","    text = soup.get_text(separator=\"\\n\", strip=True)\n","    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(text)\n","    print(\"Saved:\", save_path)\n","\n","# Example:\n","save_path = \"/content/drive/MyDrive/RAG_demo/data/quora_engineering.txt\"\n","# Run the async function\n","await render_and_save_text(\"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\", save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Z6GAQvQtLPG"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","\n","url = \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\"\n","html = requests.get(url).text\n","soup = BeautifulSoup(html, \"html.parser\")\n","\n","# Remove scripts/styles\n","for tag in soup([\"script\", \"style\"]):\n","    tag.decompose()\n","\n","text = soup.get_text(separator=\"\\n\", strip=True)\n","with open(\"/content/drive/MyDrive/RAG_demo/data/hallucination.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14843,"status":"ok","timestamp":1754926751124,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"fW8vUvcKyAIp","outputId":"3c5daf18-8256-4853-8939-76ecf2b44527"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Re-ingested 35 chunks from https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/\n"]}],"source":["from langchain_community.document_loaders import UnstructuredURLLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# 1. Load the article from URL\n","url = \"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/\"\n","loader = UnstructuredURLLoader(urls=[url])\n","docs = loader.load()\n","\n","# 2. Add metadata for tracking\n","for doc in docs:\n","    doc.metadata[\"source\"] = url\n","\n","# 3. Split into smaller chunks\n","splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","split_docs = splitter.split_documents(docs)\n","\n","# 4. Add to your existing vectorstore\n","vectorstore.add_documents(split_docs)\n","\n","print(f\"✅ Re-ingested {len(split_docs)} chunks from {url}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5686,"status":"ok","timestamp":1754927277521,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"9CbEFQWi0FC4","outputId":"5309b576-c272-41e5-d302-67891c8ed833"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Added 35 chunks from https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/ and updated FAISS index.\n"]}],"source":["from langchain_community.document_loaders import UnstructuredURLLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_community.vectorstores import FAISS\n","\n","# 1. Load the article\n","url = \"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/\"\n","loader = UnstructuredURLLoader(urls=[url])\n","docs = loader.load()\n","\n","# 2. Add metadata\n","for doc in docs:\n","    doc.metadata[\"source\"] = url\n","\n","# 3. Split into chunks\n","splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","split_docs = splitter.split_documents(docs)\n","\n","# 4. Load existing FAISS vectorstore\n","embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","vectorstore = FAISS.load_local(\"/content/drive/MyDrive/RAG_demo/faiss_index\", embeddings, allow_dangerous_deserialization=True)\n","\n","# 5. Add documents (embeddings happen here automatically)\n","vectorstore.add_documents(split_docs)\n","\n","# 6. Save updated FAISS\n","vectorstore.save_local(\"/content/drive/MyDrive/RAG_demo/faiss_index\")\n","\n","print(f\"✅ Added {len(split_docs)} chunks from {url} and updated FAISS index.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1754927290190,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"GW-3bJy-uNBN","outputId":"91738531-6eda-4260-994c-da6565e97ded"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Remaining sources:\n","- /content/drive/MyDrive/RAG_demo/data/genai-platform.txt\n","- /content/drive/MyDrive/RAG_demo/data/hallucination.txt\n","- /content/drive/MyDrive/RAG_demo/data/quora_engineering.txt\n","- https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/\n"]}],"source":["# Verify removal\n","sources = {doc.metadata.get(\"source\", \"Unknown\") for doc in vectorstore.docstore._dict.values()}\n","print(\"\\nRemaining sources:\")\n","for s in sorted(sources):\n","    print(\"-\", s)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26631,"status":"ok","timestamp":1754927319195,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"5er82KE3wcER","outputId":"7b77ff6e-449b-4362-fceb-f5f6378a78e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cleanup complete. Removed 'index.txt' entries. New total docs: 368\n"]}],"source":["from langchain_community.vectorstores import FAISS  # or Chroma, depending on your setup\n","\n","\n","# Create embeddings\n","embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","# --- Step 1: Load your existing vectorstore ---\n","vectorstore_path = \"/content/drive/MyDrive/RAG_demo/faiss_index\"  # change if needed\n","vectorstore = FAISS.load_local(vectorstore_path, embeddings, allow_dangerous_deserialization=True)\n","\n","# --- Step 2: Filter out docs with old source ---\n","docs_to_keep = []\n","metadatas_to_keep = []\n","\n","for doc, metadata in zip(vectorstore.docstore._dict.values(), vectorstore.docstore._dict.values()):\n","    if \"index.txt\" not in metadata.metadata.get(\"source\", \"\"):\n","        docs_to_keep.append(doc)\n","        metadatas_to_keep.append(metadata.metadata)\n","\n","# --- Step 3: Rebuild vectorstore without old docs ---\n","new_vectorstore = FAISS.from_texts(\n","    [doc.page_content for doc in docs_to_keep],\n","    embeddings,\n","    metadatas=metadatas_to_keep\n",")\n","\n","# --- Step 4: Save cleaned store ---\n","new_vectorstore.save_local(vectorstore_path)\n","\n","print(f\"Cleanup complete. Removed 'index.txt' entries. New total docs: {len(docs_to_keep)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"zWAVadQQV3ZW"},"source":["## Step 2: Chunking & Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33097,"status":"ok","timestamp":1754751927779,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"AP-4Pvp_t_tY","outputId":"47f339e6-d3fd-48d5-cff2-9d10826e055f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n","Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0.post1)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.0.0)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n","Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.12)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.42)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.55.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.34.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n","Loaded 4 documents from /content/drive/MyDrive/RAG_demo/data\n","Split into 194 chunks\n","FAISS index saved successfully.\n"]}],"source":["!pip install langchain faiss-cpu sentence-transformers langchain-community\n","\n","from langchain_community.document_loaders import TextLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.vectorstores import FAISS\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","import os\n","\n","# Path to your folder\n","folder_path = \"/content/drive/MyDrive/RAG_demo/data\"\n","faiss_index_path = os.path.join(folder_path, \"faiss_index\")\n","\n","# Step 1: Load all .txt files\n","documents = []\n","for file_name in os.listdir(folder_path):\n","    if file_name.endswith(\".txt\"):\n","        loader = TextLoader(os.path.join(folder_path, file_name))\n","        documents.extend(loader.load())\n","\n","print(f\"Loaded {len(documents)} documents from {folder_path}\")\n","\n","# Step 2: Split into chunks\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,  # characters\n","    chunk_overlap=200  # overlap for better context\n",")\n","docs = text_splitter.split_documents(documents)\n","print(f\"Split into {len(docs)} chunks\")\n","\n","# Step 3: Create embeddings\n","embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","\n","# Step 4: Store in FAISS\n","db = FAISS.from_documents(docs, embeddings)\n","\n","# Save FAISS index\n","db.save_local(faiss_index_path)\n","print(\"FAISS index saved successfully.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_NTXX7U8olV"},"outputs":[],"source":["!pip install langchain faiss-cpu sentence-transformers langchain-community --quiet"]},{"cell_type":"markdown","metadata":{"id":"1Hm7F06KY6i8"},"source":["## Load FAISS Index"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":528,"referenced_widgets":["400529ec58c349cfa49b9a15307b62ae","bbd35eb777974fe28fe2f7b3c18babcc","1d418c3e6a7e4d8aa254bfb34775cbdd","92bb196ac29642cb922c263391d17f9a","b541932bda37446182c92f50329b9193","ac9ddcbaa56f4740a8d406aa35784abb","9b06c87e953145c490346a7be7ce8803","70703871283249e4b794287e0df93736","01e6dcd04ff2453c991bc4f39fafa922","9d67fb7cecdd47b689ab952f44216e8e","62439ec205ab4ffaa0b80447964257ef","f677109fef634d94a0b56f4be2a9b8fc","f995aec1a6104b39887cd75115b0fe95","a8016c7b7ddf4482b9eeef04789b6212","2b66102cd510401696f3c327b2bc0ec8","a9af02ed91f14b289de14d1e2f5b423f","6dee2a6bd3d24f1e88c6d8f63af523c7","470f7794777b48cb9ba04b21e21fa750","cbe71ab850884cc2a6dcd0d226986194","280da422dffd48b18b6f41029e878d02","3d9e50e4ffc54cfeae3a1a36657b338a","4bb9f039f5174245a695c79f89d95345","664e6896797f4915b2ff6f2f2ba6b1cd","4c1b12dfe5614661973ec3fee1065d11","6a528ee46de94434bd30bd62af1745aa","20a10c30bcc34e6eb3087fa5a71afead","d1133354fc4d44c49f8e2df90e79a225","acd5a4b1eb9c471b9c270765a4b1814c","03a1d102e9684912ba78b50bd429d69a","dbbed00dd239452e851710c7822a7c21","26ed36f52652471f9d15c8c86ac85eb8","1f948887f1ae49108a5c95940e6413b6","d033c5629a804e1ca2cb4409d82f1564","9b54557d71414731b3f85e123c0e6738","4f60165293d24f38ba4863abc7fee29d","98766379eb324797ab0fa7d3632fe7c2","9db7e8d254734a0fbd638ba5a7552035","cd5ce3ff2b314e51bff41603395c1e98","759feddd5a9842a9b8e4b2e3a34b4bed","0cfcd68d23fc404b81c313c6e2d40f6d","08cd2ccfeefa44299ef9c32af8e3b547","bd801a4375bb4df39e2c19379a746a91","32da07357965400bbf44d40662a13a54","08f2c5fd71b747b9b82cc6a051f43f5d","99025d20b74c40d18fb234eb7e36d3f3","b7bad02a417c49c0bb0e002d58365e79","6f4b5eb9f8ec404db0eba1eeeb863961","9e0c7d07304a428689e5dd6b76338e12","a29771d7e69b45ec86d2e7c5997c8425","3642add690b64b1c925eb095a1445026","d14461776fe5406a8d1e8d0484b8ed66","4fae92e8a4d34e469efb2501a8393dcc","0f0a4b774d454f43bd01d05d452e3a45","b516cbc50a264aa89f606c2744d1d076","0d68c215f8fc47cc9f288e4edff193bb","66eee02ec1404767802e2fb91a961cfe","6905ae290e204634ab144de7f8e86235","f2eca5f8157b4dc19398e848794fa1f4","9643f22a76d24fefbaa0b545175d874f","1ffb13c74ee543819d9375a7f90f0b09","b9fb8ef68be84829ba3a4f2767c50dfe","e4958389e1324dcf96260c8d08dcd33f","d51727dd1827439a8c29974ef94189fa","00ea95a09e804b51bc9afa1660a5e846","ecdc34cea2354eec9e73326f2d88e783","9f209bfbb53340b181ba20565e072c10","808a98d0ad2e459e86261bfdcaa47164","2a7207ba41ad4bfda97020aa046ea153","f4080c3f23304c31aba573debec374e6","7f4383d34f7643e89fd39593d2b20014","d97912bcca1c4ff3961aa987c80fa791","37c42167e9244c1a8bc580ac48628be1","2b9b1ba884cf43ee8a261cba9c5537b5","d003c44c1d964fe1b74dc16e4cae7184","91a90939c1554e8fba754af639f680b2","0765501ff35e487091bc4b51482cb61e","86997c9f7b1c41b687abe5f1d94b34e5","8a854b67345146c9b2272422a3b15253","59d07cb22dc941aeb09e47397c5df579","74ea1485b6464ced93468139862884d7","86398427d4ff488aaf4f4885939fecd7","0cde91ad6d8f4cd0b0f5bf70dc1a504d","1bd9f6bf82ac40bb8435e9087923e201","0f211a9edfda45bb9afd17169f0e860a","725c91296b4f440aac36386bc3cdbf74","6a478368fa02461bbdf41bc4230abe9b","272cec19191a407eba9aca392c300d0b","f074ee191bb6408ab7ab6c261546741f","a67d38aa6bda4dc7863cfd3cd7cb3f49","4c026d6070204bfaa827d02c50ba0e00","2b6c0fbcabb144bbbbd99660bfb2cb2d","fb6d9aecb92d47e39e0acdff9ad0362e","34b51f3c89314464bd7f5ac40db930e1","eed3de26550b4d8fa07f818d04dc8b22","fce13ca558264fe2bd88fa7079b86af3","f58478fe8b074fc99e24d05d8d66304b","3bd6bdec047b41298e20f74053558fea","cfe222934ee34f58b930e0d66776a085","20d1dbad5442498787b1a03a9b2d8de2","ac3a76f2efaa4222a4c0de4ab3d68488","a54ea7a38d6c41a7835e6ac7b36ac1ea","661317923f144e4ab35c1c98f14c2aa2","de6ad47623484fc79a76aa6e5dc97939","eb78df2038ed457494e42751aa153ea7","5852f9ad37f64dd1966f7284c1b1e780","a73a9932364245fdb0c6d21489168e34","1f722d8ce12144fbba1906a2adca05ce","1bd9f85f22134eb590d4b229be09ef05","79f6864ae2c94373b8fae469e4937724","c7335ba7e0d74506a198cc40a383955f","eef82c807adf45ee8b1ef026a3c469a7","a3a892523129473bbef023f38310a43a","ea4c11f7ca2f457f8703c219564256f6","b24f5e7fec9543ffa3f502135c042ff9","604bc8e427944da78af3b2867930d43c","a588b2220ce04968ad18efeaf2740f4f","8a8b3cc74b204f18a79b795fca6d3a46","8b344a352b2d42739683d6b856f5235f","0334d9bdc8814160811cfde584ed242a","45a3ea0eb10f456cb925e2a629352fd1","c2b9dcec16324d63a69837ea28d47e00"]},"executionInfo":{"elapsed":39140,"status":"ok","timestamp":1754795407963,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"d3248gHeWSfU","outputId":"e76f3d56-c9b6-4ecf-b580-12be7cada358"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-2143237963.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n","  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"400529ec58c349cfa49b9a15307b62ae","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f677109fef634d94a0b56f4be2a9b8fc","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"664e6896797f4915b2ff6f2f2ba6b1cd","version_major":2,"version_minor":0},"text/plain":["README.md: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b54557d71414731b3f85e123c0e6738","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99025d20b74c40d18fb234eb7e36d3f3","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66eee02ec1404767802e2fb91a961cfe","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"808a98d0ad2e459e86261bfdcaa47164","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a854b67345146c9b2272422a3b15253","version_major":2,"version_minor":0},"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a67d38aa6bda4dc7863cfd3cd7cb3f49","version_major":2,"version_minor":0},"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac3a76f2efaa4222a4c0de4ab3d68488","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eef82c807adf45ee8b1ef026a3c469a7","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from langchain_community.vectorstores import FAISS\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","import os\n","\n","# Paths\n","folder_path = \"/content/drive/MyDrive/RAG_demo/data\"\n","faiss_index_path = os.path.join(folder_path, \"faiss_index\")\n","\n","# Load the embedding model\n","embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","\n","# Load the index\n","vectorstore = FAISS.load_local(faiss_index_path, embeddings=embeddings, allow_dangerous_deserialization=True)"]},{"cell_type":"markdown","metadata":{"id":"A7y-awSYZNRT"},"source":["## Query the Index"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1754795411948,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"VeAXeZkXY9s-","outputId":"c36808d1-702d-4623-d011-a4e4763b1ec6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Result 1 ---\n","\n","Factual inconsistent responses\n","hallucinated by the model. Hallucination detection is an active area of research with solutions such as\n","SelfCheckGPT\n","(Manakul et al., 2023) and\n","SAFE\n",", Search Engine Factuality Evaluator (Wei et al., 2024). You can mitigate hallucinations by providing models with sufficient context and prompting techniques such as chain-of-thought. Hallucination detection and mitigation are discussed further in my upcoming book\n","AI Engineering\n",".\n","Responses that contain sensitive information\n",". This can happen in two scenarios.\n","Your model was trained on sensitive data and regurgitates it back.\n","Your system retrieves sensitive information from your internal database to enrich its context, and then it passes this sensitive information on to the response.\n","\n","--- Result 2 ---\n","\n","Citation\n","#\n","Cited as:\n","Weng, Lilian. (Jul 2024). Extrinsic Hallucinations in LLMs. Lil’Log. https://lilianweng.github.io/posts/2024-07-07-hallucination/.\n","Or\n","@article{weng2024hallucination,\n","  title   = \"Extrinsic Hallucinations in LLMs.\",\n","  author  = \"Weng, Lilian\",\n","  journal = \"lilianweng.github.io\",\n","  year    = \"2024\",\n","  month   = \"Jul\",\n","  url     = \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\"\n","}\n","References\n","#\n","[1] Ji et al.\n","“Survey of hallucination in natural language generation.”\n","ACM Computing Surveys (2022)\n","[2] Gekhman et al.\n","“Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?”\n","arXiv preprint arXiv:2405.05904 (2024).\n","[3] Min et al.\n","“FActScore: Fine-grained atomic evaluation of factual precision in long form text generation.”\n","EMNLP 2023.\n","[4] Wei et al. 2024\n","“Long-form Factuality in LLMs”\n","arXiv preprint arXiv:2403.18802 (2024).\n","[5] Chern et al.\n","\n","--- Result 3 ---\n","\n","Extrinsic Hallucinations in LLMs | Lil'Log\n","Lil'Log\n","|\n","Posts\n","Archive\n","Search\n","Tags\n","FAQ\n","Extrinsic Hallucinations in LLMs\n","Date: July 7, 2024  |  Estimated Reading Time: 29 min  |  Author: Lilian Weng\n","Table of Contents\n","What Causes Hallucinations?\n","Pre-training Data Issues\n","Fine-tuning New Knowledge\n","Hallucination Detection\n","Retrieval-Augmented Evaluation\n","Sampling-Based Detection\n","Calibration of Unknown Knowledge\n","Indirect Query\n","Anti-Hallucination Methods\n","RAG → Edits and Attribution\n","Chain of Actions\n","Sampling Methods\n","Fine-tuning for Factuality\n","Fine-tuning for Attribution\n","Appendix: Evaluation Benchmarks\n","Citation\n","References\n","Hallucination in large language models usually refers to the model generating unfaithful, fabricated, inconsistent, or nonsensical content. As a term, hallucination has been somewhat generalized to cases when the model makes mistakes. Here, I would like to narrow down the problem of hallucination to cases where the model output is fabricated and\n","not grounded\n"]}],"source":["query = \"What is hallucination in AI?\"\n","docs = vectorstore.similarity_search(query, k=3)\n","\n","for i, doc in enumerate(docs, 1):\n","    print(f\"\\n--- Result {i} ---\\n\")\n","    print(doc.page_content)\n"]},{"cell_type":"markdown","metadata":{"id":"_U1swqb1EQ23"},"source":["## store the API Key"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4494,"status":"ok","timestamp":1754883043137,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"T3w89ORmBhPW","outputId":"d9cbc28b-8561-497d-ab86-76445a579a0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Gemini API key: ··········\n","Key set successfully!\n"]}],"source":["import os\n","from getpass import getpass\n","\n","# Prompt you to enter API key securely\n","os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Gemini API key: \")\n","\n","# Check (for debugging only; remove print later)\n","print(\"Key set successfully!\")\n"]},{"cell_type":"markdown","metadata":{"id":"73QU47E0ecA4"},"source":["## FAISS index + retrieval + LLM answering pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6368,"status":"ok","timestamp":1754883061526,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"AM4PIe7HZbw8","outputId":"9d455bcb-7c1b-4783-8a8d-4f128bf9256b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Google API key: ··········\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-493768814.py:55: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  return qa.run(question)\n"]},{"name":"stdout","output_type":"stream","text":["The provided text mentions RAG pipelines in several ways:\n","\n","* **RAGatouille:** This Python library simplifies the use of advanced retrieval methods within RAG pipelines, particularly making complex models like ColBERT more accessible.  Its goal is to make applying these methods easier for developers without deep expertise.\n","\n","* **Self-RAG:** This framework retrieves multiple documents in parallel and critiques its own generation to improve quality, guided by special tokens.  This is a specific type of RAG pipeline.\n","\n","* **AI Pipeline Orchestration:**  This section discusses RAG applications as an example of an AI application that can be orchestrated.  It notes that in a RAG application, retrieval quality is often evaluated using context relevance and context precision.\n"]}],"source":["# --- Load FAISS index and set up QA pipeline ---\n","\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain.chains import RetrievalQA\n","from langchain.prompts import PromptTemplate\n","import os\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","# 1. Load embeddings model\n","embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","# 2. Load FAISS index from path\n","FAISS_PATH = \"/content/drive/MyDrive/RAG_demo/faiss_index\"\n","faiss_index = FAISS.load_local(FAISS_PATH, embeddings, allow_dangerous_deserialization=True)\n","\n","\n","# Prompt you to enter API key securely\n","os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API key: \")\n","\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-1.5-flash\",\n","    temperature=0,\n","    google_api_key=os.environ[\"GOOGLE_API_KEY\"]  # force usage of API key\n",")\n","\n","\n","# 3. Initialize LLM\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n","\n","# 4. Create QA chain with custom prompt\n","template = \"\"\"\n","Use the provided documents to answer the question.\n","If the answer is not in the documents, say:\n","\"The answer is not available in the provided context.\"\n","\n","Context:\n","{context}\n","\n","Question: {question}\n","Answer:\n","\"\"\"\n","QA_PROMPT = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n","\n","qa = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    retriever=faiss_index.as_retriever(),\n","    chain_type=\"stuff\",\n","    chain_type_kwargs={\"prompt\": QA_PROMPT}\n",")\n","\n","# 5. Wrap into a function\n","def query_docs(question):\n","    return qa.run(question)\n","\n","# Example usage:\n","print(query_docs(\"What does the document say about RAG pipelines?\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12460,"status":"ok","timestamp":1755010920050,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"wPS4li68tUap","outputId":"adfa23bf-c0c9-457c-ba0c-c9664311be13"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m71.7/74.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/443.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m419.8/443.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.5/443.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install langchain-openai --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3374,"status":"ok","timestamp":1754887507428,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"nnsbU_qjnfZo","outputId":"36743fc2-3600-4857-c15e-d00ce96e83a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Google API key: ··········\n","\n","Answer: Based on the provided text, `genai` is a Python library (`import google.generativeai as genai`) used to interact with Google's generative AI models.  The code shows it's used to configure an API key and generate content.\n","Sources: genai-platform.txt\n"]}],"source":["# --- Step 1: Imports ---\n","from langchain_community.vectorstores import FAISS\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import RetrievalQA\n","import os\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain.chains import RetrievalQA\n","from langchain.prompts import PromptTemplate\n","import os\n","from typing import List\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from getpass import getpass\n","\n","# --- Step 2: Configuration ---\n","FAISS_PATH = \"/content/drive/MyDrive/RAG_demo/faiss_index\"\n","# Prompt you to enter API key securely\n","os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API key: \")\n","\n","# --- Step 3: Load FAISS index ---\n","embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","vectorstore = FAISS.load_local(FAISS_PATH, embedding_model, allow_dangerous_deserialization=True)\n","\n","# --- Step 4: Setup LLM ---\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-1.5-flash\",\n","    temperature=0,\n","    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",")\n","\n","# --- Step 5: Create prompt template (optional for better control) ---\n","prompt_template = \"\"\"\n","Use the provided context to answer the question.\n","If the answer is not in the context, say you don't know.\n","Also, return the source documents.\n","\n","Context:\n","{context}\n","\n","Question:\n","{question}\n","\n","Answer:\n","\"\"\"\n","prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n","\n","# --- Step 6: Wrap into function ---\n","def query_with_citations(question: str):\n","    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n","    docs = retriever.get_relevant_documents(question)\n","\n","    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n","    formatted_prompt = prompt.format(context=context, question=question)\n","\n","    response = llm.invoke(formatted_prompt)\n","\n","    # Extract sources, remove duplicates, keep only file names\n","    sources = sorted({os.path.basename(doc.metadata.get(\"source\", \"Unknown\")) for doc in docs})\n","\n","    return {\n","        \"answer\": response.content.strip(),\n","        \"sources\": sources\n","    }\n","\n","# --- Step 7: Test query ---\n","if __name__ == \"__main__\":\n","    user_query = \"What is genai?\"\n","    result = query_with_citations(user_query)\n","    print(\"\\nAnswer:\", result[\"answer\"])\n","    print(\"Sources:\", \", \".join(result[\"sources\"]))\n"]},{"cell_type":"markdown","metadata":{"id":"kemD4C0Lfy1l"},"source":["## Add Re-ranking"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9361,"status":"ok","timestamp":1754929143385,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"DTtGmlz5L-d4","outputId":"0526350b-b2d6-4968-8c80-cbe4af0b474f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Google API key: ··········\n","\n","Answer: Based on the provided text, `genai` is a Python library (`import google.generativeai as genai`) used to interact with Google's generative AI models.  The code shows it's used to configure an API key and generate content.\n","Sources: /content/drive/MyDrive/RAG_demo/data/genai-platform.txt\n"]}],"source":["# --- Step 1: Imports ---\n","from langchain_community.vectorstores import FAISS\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import RetrievalQA\n","import os\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain.chains import RetrievalQA\n","from langchain.prompts import PromptTemplate\n","import os\n","from typing import List\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from getpass import getpass\n","\n","# --- Step 2: Configuration ---\n","FAISS_PATH = \"/content/drive/MyDrive/RAG_demo/faiss_index\"\n","# Prompt you to enter API key securely\n","os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API key: \")\n","\n","# --- Step 3: Load FAISS index ---\n","embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","vectorstore = FAISS.load_local(FAISS_PATH, embedding_model, allow_dangerous_deserialization=True)\n","\n","# --- Step 4: Setup LLM ---\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-1.5-flash\",\n","    temperature=0,\n","    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",")\n","\n","# --- Step 5: Create prompt template ---\n","prompt_template = \"\"\"\n","Use the provided context to answer the question.\n","If the answer is not in the context, say: I couldn't find anything in my knowledge base about that topic. I can only answer questions related to AI, RAG, and the documents you provided.\n","\n","Context:\n","{context}\n","\n","Question:\n","{question}\n","\n","Answer:\n","\"\"\"\n","prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n","\n","# --- Step 6: Wrap into function ---\n","def query_with_citations(question: str):\n","    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})  # fetch more\n","    docs = retriever.get_relevant_documents(question)\n","\n","    # Keep top 3 by vector similarity\n","    docs = docs[:3]\n","\n","    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n","    formatted_prompt = prompt.format(context=context, question=question)\n","\n","    response = llm.invoke(formatted_prompt)\n","    answer_text = response.content.strip()\n","\n","    # Only show sources if it's not the fallback\n","    fallback_msg = \"I couldn't find anything in my knowledge base about that topic\"\n","    if fallback_msg.lower() in answer_text.lower():\n","        sources = []  # No sources for out-of-scope answers\n","    else:\n","        sources = list(set(doc.metadata.get(\"source\", \"Unknown\") for doc in docs))\n","\n","    return {\n","        \"answer\": answer_text,\n","        \"sources\": sources\n","    }\n","\n","# --- Step 7: Test query ---\n","if __name__ == \"__main__\":\n","    user_query = \"what is genai?\"\n","    result = query_with_citations(user_query)\n","\n","    print(\"\\nAnswer:\", result[\"answer\"])\n","    if result[\"sources\"]:\n","        print(\"Sources:\", \", \".join(result[\"sources\"]))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143499,"status":"ok","timestamp":1755010907582,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"AiHY3QEtUXMP","outputId":"79aa28cd-1355-493b-8a64-cdea86718d2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# --- Step 0: Install needed packages ---\n","!pip install faiss-cpu langchain-community langchain-google-genai sentence-transformers --quiet"]},{"cell_type":"markdown","metadata":{"id":"hgmvtY1x9ALz"},"source":["## Full RAG Pipeline with citations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17423,"status":"ok","timestamp":1755011459713,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"Gn7BfUoy3rim","outputId":"f581c921-a9e5-4cc6-bfbd-3a9f01484fa0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Google API key: ··········\n","\n","Answer: Embedding-based retrieval, also known as vector search, converts chunks of data into embedding vectors using an embedding model (like BERT, sentence-transformers, or proprietary models from OpenAI or Google).  A query is also converted into an embedding vector. The data whose vector is closest to the query embedding (as determined by a vector search algorithm) is then retrieved.  This is usually framed as a nearest-neighbor search, often using approximate nearest neighbor (ANN) algorithms like FAISS.\n","Sources: https://huyenchip.com/2024/07/25/genai-platform.html, https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\n"]}],"source":["# --- Step 1: Imports ---\n","from langchain_community.vectorstores import FAISS\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import RetrievalQA\n","import os\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain.chains import RetrievalQA\n","from langchain.prompts import PromptTemplate\n","import os\n","from typing import List\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from getpass import getpass\n","\n","# --- Step 2: Configuration ---\n","FAISS_PATH = \"/content/drive/MyDrive/RAG_demo/faiss_index\"\n","# Prompt you to enter API key securely\n","os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API key: \")\n","\n","# --- Step 3: Load FAISS index ---\n","embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","vectorstore = FAISS.load_local(FAISS_PATH, embedding_model, allow_dangerous_deserialization=True)\n","\n","# --- Step 4: Setup LLM ---\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-1.5-flash\",\n","    temperature=0,\n","    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",")\n","\n","# --- Step 5: Create prompt template ---\n","prompt_template = \"\"\"\n","Use the provided context to answer the question.\n","If the answer is not in the context, say: I couldn't find anything in my knowledge base about that topic. I can only answer questions related to AI, RAG, and the documents you provided.\n","\n","Context:\n","{context}\n","\n","Question:\n","{question}\n","\n","Answer:\n","\"\"\"\n","prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n","\n","# --- Step 6: Wrap into function ---\n","def query_with_citations(question: str):\n","    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})  # fetch more\n","    docs = retriever.get_relevant_documents(question)\n","\n","    # Keep top 3 by vector similarity\n","    docs = docs[:3]\n","\n","    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n","    formatted_prompt = prompt.format(context=context, question=question)\n","\n","    response = llm.invoke(formatted_prompt)\n","    answer_text = response.content.strip()\n","\n","    # Mapping from file paths to desired URL format\n","    source_url_map = {\n","        \"/content/drive/MyDrive/RAG_demo/data/genai-platform.txt\": \"https://huyenchip.com/2024/07/25/genai-platform.html\",\n","        \"/content/drive/MyDrive/RAG_demo/data/hallucination.txt\": \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n","        \"/content/drive/MyDrive/RAG_demo/data/quora_engineering.txt\": \"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\"\n","    }\n","\n","    def format_sources(sources):\n","        \"\"\"Convert FAISS/metadata sources to consistent URL format.\"\"\"\n","        return [source_url_map.get(src, src) for src in sources]\n","\n","    # Only show sources if it's not the fallback\n","    fallback_msg = \"I couldn't find anything in my knowledge base about that topic\"\n","    if fallback_msg.lower() in answer_text.lower():\n","        sources = []  # No sources for out-of-scope answers\n","    else:\n","        sources = list(set(doc.metadata.get(\"source\", \"Unknown\") for doc in docs))\n","        sources = format_sources(sources)  # <-- Apply URL mapping here\n","\n","    return {\n","        \"answer\": answer_text,\n","        \"sources\": sources\n","    }\n","\n","# --- Step 7: Test query ---\n","if __name__ == \"__main__\":\n","    user_query = \"What is embedding based retieval?\"\n","    result = query_with_citations(user_query)\n","\n","    print(\"\\nAnswer:\", result[\"answer\"])\n","    if result[\"sources\"]:\n","        print(\"Sources:\", \", \".join(result[\"sources\"]))\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iOthQPyB64sj"},"source":["# HYBRID RETRIEVAL (BM25 + FAISS) + reranker"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i_ecTWuP6auB"},"outputs":[],"source":["!pip install rank_bm25 sentence-transformers faiss-cpu --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12505,"status":"ok","timestamp":1755014250658,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"hNQSjvVj1TVo","outputId":"98ec9d74-c141-44b0-f352-53948f4eb8e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Google API key: ··········\n","Building BM25 index from vectorstore (this may take a sec)...\n","BM25 built over 368 chunks.\n","Loading cross-encoder reranker (may take memory/time)...\n","Running quick hybrid test...\n","\n","Answer: ColBERT (Contextualized Late Interaction over BERT) is a model stemming from Stanford University that uses BERT's deep language understanding but with a novel \"late interaction\" mechanism.  This means query and document representations are processed separately until the final stages of retrieval.  Late interaction matters because it allows for efficient and precise retrieval, unlike \"early interac\n","Sources: ['https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/']\n"]}],"source":["# ===== HYBRID RETRIEVAL (BM25 + FAISS) + optional reranker =====\n","from rank_bm25 import BM25Okapi\n","from sentence_transformers import CrossEncoder\n","import os, pickle\n","from typing import List\n","from collections import OrderedDict\n","\n","# ---to match your environment ---\n","FAISS_PATH = \"/content/drive/MyDrive/RAG_demo/faiss_index\"   # saved FAISS\n","USE_RERANKER = True           # set False if you don't want Cross-Encoder reranking\n","RERANKER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"  # small & fast\n","BM25_TOP_K = 10               # initial BM25 candidates\n","FAISS_TOP_K = 10              # initial FAISS candidates\n","FINAL_TOP_K = 3               # final docs to pass to LLM\n","# ----------------------------------------------------------------\n","\n","\n","# Prompt you to enter API key securely\n","os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API key: \")\n","\n","# ---Load FAISS index ---\n","embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","vectorstore = FAISS.load_local(FAISS_PATH, embedding_model, allow_dangerous_deserialization=True)\n","\n","# ---Setup LLM ---\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-1.5-flash\",\n","    temperature=0,\n","    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",")\n","\n","# ---Create prompt template ---\n","prompt_template = \"\"\"\n","Use the provided context to answer the question.\n","If the answer is not in the context, say: I couldn't find anything in my knowledge base about that topic. I can only answer questions related to AI, RAG, and the documents you provided.\n","\n","Context:\n","{context}\n","\n","Question:\n","{question}\n","\n","Answer:\n","\"\"\"\n","prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n","\n","# 1) Build BM25 corpus from your FAISS docstore (texts and metadata)\n","def build_bm25_from_vectorstore(vectorstore):\n","    docs = []\n","    sources = []\n","    # vectorstore.docstore._dict values are Document objects for many LangChain stores\n","    for doc_id, doc in vectorstore.docstore._dict.items():\n","        text = getattr(doc, \"page_content\", None) or doc.page_content\n","        docs.append(text)\n","        sources.append(doc.metadata.get(\"source\", \"Unknown\"))\n","    # simple tokenization: whitespace split (you can improve using nltk/spacy if needed)\n","    tokenized = [d.split() for d in docs]\n","    bm25 = BM25Okapi(tokenized)\n","    return bm25, docs, tokenized, sources\n","\n","print(\"Building BM25 index from vectorstore (this may take a sec)...\")\n","bm25, bm25_docs, bm25_tokenized, bm25_sources = build_bm25_from_vectorstore(vectorstore)\n","print(f\"BM25 built over {len(bm25_docs)} chunks.\")\n","\n","# Optionally persist BM25 for faster reload\n","BM25_PICKLE = os.path.join(FAISS_PATH, \"bm25.pkl\")\n","with open(BM25_PICKLE, \"wb\") as f:\n","    pickle.dump({\"bm25_docs\": bm25_docs, \"bm25_sources\": bm25_sources}, f)\n","\n","# 2) Optional: load cross-encoder reranker\n","if USE_RERANKER:\n","    print(\"Loading cross-encoder reranker (may take memory/time)...\")\n","    reranker = CrossEncoder(RERANKER_MODEL)\n","else:\n","    reranker = None\n","\n","# 3) Helper: map doc text -> Document object(s) from vectorstore\n","# We'll build a quick map from text to the stored Document instance(s)\n","text_to_docs = {}\n","for doc in vectorstore.docstore._dict.values():\n","    text = doc.page_content\n","    text_to_docs.setdefault(text, []).append(doc)\n","\n","# 4) Hybrid search function\n","def hybrid_search(query: str, bm_k:int=BM25_TOP_K, faiss_k:int=FAISS_TOP_K, top_k:int=FINAL_TOP_K) -> List:\n","    # 4a) BM25 candidates (by index of bm25_docs)\n","    tokenized_q = query.split()\n","    bm25_scores = bm25.get_scores(tokenized_q)\n","    bm25_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:bm_k]\n","    bm25_candidates = []\n","    for idx in bm25_indices:\n","        txt = bm25_docs[idx]\n","        src = bm25_sources[idx]\n","        bm25_candidates.append((txt, src, bm25_scores[idx]))\n","\n","    # 4b) FAISS candidates (semantic)\n","    faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": faiss_k})\n","    faiss_docs = faiss_retriever.get_relevant_documents(query)  # returns Document objects\n","    faiss_candidates = [(d.page_content, d.metadata.get(\"source\",\"Unknown\"), None) for d in faiss_docs]\n","\n","    # 4c) Merge candidates (keep order by source of score: BM25 first then FAISS)\n","    merged = OrderedDict()  # preserve first appearance\n","    for txt, src, score in bm25_candidates + faiss_candidates:\n","        key = txt.strip()\n","        if key not in merged:\n","            merged[key] = {\"text\": txt, \"source\": src, \"bm25_score\": score}\n","\n","    candidates = list(merged.values())  # list of dicts\n","\n","    # 4d) (Optional) Rerank candidates with cross-encoder: produce scores for (query, text)\n","    if reranker and candidates:\n","        pairs = [(query, c[\"text\"]) for c in candidates]\n","        scores = reranker.predict(pairs)\n","        for c, s in zip(candidates, scores):\n","            c[\"rerank_score\"] = float(s)\n","        # Sort by rerank_score desc\n","        candidates = sorted(candidates, key=lambda x: x[\"rerank_score\"], reverse=True)\n","    else:\n","        # fallback: keep bm25_score non-None then no particular order, or try simple heuristic:\n","        # prefer BM25 hits first (where bm25_score not None), then FAISS\n","        candidates = sorted(candidates, key=lambda x: (0 if x[\"bm25_score\"] is not None else 1, -(x[\"bm25_score\"] or 0)))\n","\n","    # 4e) Return top_k Document objects (use text_to_docs map to return actual Document objs)\n","    final_docs = []\n","    for c in candidates[:top_k]:\n","        text = c[\"text\"]\n","        docs_list = text_to_docs.get(text, [])\n","        if docs_list:\n","            # there may be multiple Doc objects with same text; pick first\n","            final_docs.append(docs_list[0])\n","        else:\n","            # Shouldn't happen if bm25 built from same corpus; but fallback: create pseudo doc\n","            from langchain.docstore.document import Document\n","            final_docs.append(Document(page_content=text, metadata={\"source\": c.get(\"source\",\"Unknown\")}))\n","    return final_docs\n","\n","# 5) Integrate into your query_with_citations\n","import os\n","source_url_map = {\n","    \"/content/drive/MyDrive/RAG_demo/data/genai-platform.txt\": \"https://huyenchip.com/2024/07/25/genai-platform.html\",\n","    \"/content/drive/MyDrive/RAG_demo/data/hallucination.txt\": \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n","    \"/content/drive/MyDrive/RAG_demo/data/quora_engineering.txt\": \"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\"\n","}\n","def format_sources(sources):\n","    return [source_url_map.get(s, s) for s in sources]\n","\n","# Make sure prompt, llm exist in your notebook\n","def query_with_citations_hybrid(question: str):\n","    # Get hybrid top docs\n","    docs = hybrid_search(question, bm_k=BM25_TOP_K, faiss_k=FAISS_TOP_K, top_k=FINAL_TOP_K)\n","\n","    # Create context and ask LLM\n","    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n","    formatted_prompt = prompt.format(context=context, question=question)\n","    response = llm.invoke(formatted_prompt)\n","    answer_text = response.content.strip()\n","\n","    # fallback detection (no sources shown for out-of-scope)\n","    fallback_msg = \"i couldn't find anything in my knowledge base about that topic\"\n","    if fallback_msg.lower() in answer_text.lower():\n","        sources = []\n","    else:\n","        sources = list(OrderedDict.fromkeys(doc.metadata.get(\"source\",\"Unknown\") for doc in docs))  # dedupe keep order\n","        sources = format_sources(sources)\n","    return {\"answer\": answer_text, \"sources\": sources}\n","\n","# 6) Quick test\n","print(\"Running quick hybrid test...\")\n","q = \"What is ColBERT and why late interaction matters?\"\n","res = query_with_citations_hybrid(q)\n","print(\"\\nAnswer:\", res[\"answer\"][:400])\n","print(\"Sources:\", res[\"sources\"])\n"]},{"cell_type":"markdown","metadata":{"id":"B1arqvdk56go"},"source":["# EVALUATION METRICS"]},{"cell_type":"markdown","metadata":{"id":"NVNRC86054ZE"},"source":["##  LLM-as-a-judge"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10467,"status":"ok","timestamp":1755012408924,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"saYe56Yi4KbT","outputId":"0d226b5b-d630-4af9-f073-e6fa5d3d2556"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Google API key: ··········\n","\n","Q: What is ColBERT and why late interaction matters?\n","Answer: ColBERT (Contextualized Late Interaction over BERT) is a model stemming from Stanford University that uses BERT's deep language understanding but with a novel \"late interaction\" mechanism.  This means query and document representations are processed separately until the final stages of retrieval.  Late interaction matters because it allows for efficient and precise retrieval, unlike \"early interaction\" models which are computationally expensive due to considering all query-document pairs.  This efficiency makes ColBERT particularly well-suited for large-scale applications.\n","Citations: ['https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/']\n","Judge Scores: ```json\n","{ \"accuracy\": 0.95, \"coverage\": 0.9, \"citation_match\": 1.0 }\n","```\n"]}],"source":["# --- LLM Judge Setup ---\n","# Prompt you to enter API key securely\n","os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API key: \")\n","\n","# Initialize a separate LLM for judging\n","judge_llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-1.5-flash\",  # You can choose a different model if needed\n","    temperature=0,\n","    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",")\n","\n","\n","# Example ground truth set\n","gold_data = [\n","    {\n","        \"question\": \"What is ColBERT and why late interaction matters?\",\n","        \"ground_truth\": \"ColBERT is a retrieval model developed at Stanford that uses BERT embeddings with a late interaction mechanism. Late interaction improves efficiency by separating query and document processing until the final scoring step, balancing accuracy with scalability.\",\n","        \"expected_citations\": [\n","            \"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/\"\n","        ]\n","    }\n","    # Add more entries here...\n","]\n","\n","def llm_judge(question, system_answer, citations, ground_truth, expected_citations, judge_llm):\n","    judge_prompt = f\"\"\"\n","    You are evaluating an AI system's answer.\n","\n","    Question: {question}\n","    System Answer: {system_answer}\n","    Ground Truth Answer: {ground_truth}\n","    System Citations: {citations}\n","    Expected Citations: {expected_citations}\n","\n","    Evaluate on:\n","    1. Accuracy (0 to 1): factual correctness compared to ground truth.\n","    2. Coverage (0 to 1): completeness of answer.\n","    3. Citation Match (0 to 1): citation relevance.\n","\n","    Respond ONLY in JSON:\n","    {{ \"accuracy\": float, \"coverage\": float, \"citation_match\": float }}\n","    \"\"\"\n","\n","    response = judge_llm.invoke(judge_prompt) # Use judge_llm here\n","    return response.content\n","\n","# --- Loop through gold dataset with hybrid retriever + judge ---\n","for item in gold_data:\n","    question = item[\"question\"]\n","    ground_truth = item[\"ground_truth\"]\n","    expected_citations = item[\"expected_citations\"]\n","\n","    # Run your hybrid retriever (make sure query_with_citations_hybrid is defined)\n","    result = query_with_citations_hybrid(question)\n","    answer = result[\"answer\"]\n","    citations = result[\"sources\"]\n","\n","    # Judge evaluation\n","    scores = llm_judge(question, answer, citations, ground_truth, expected_citations, judge_llm)\n","\n","    # Display results\n","    print(f\"\\nQ: {question}\")\n","    print(f\"Answer: {answer}\")\n","    print(f\"Citations: {citations}\")\n","    print(f\"Judge Scores: {scores}\")"]},{"cell_type":"markdown","metadata":{"id":"vh2jO16770E6"},"source":["## LLM-as-a-Judge Evaluation\n","\n","To assess the quality of answers generated by the hybrid retriever (BM25 + FAISS + Cross-Encoder Reranker), I integrated an LLM-as-a-judge evaluation layer. In this approach, a large language model reviews each retrieved answer against the cited sources and produces quantitative scores:\n","\n","Accuracy – Measures factual correctness of the answer relative to the source (0 to 1).\n","\n","Coverage – Evaluates how completely the answer addresses relevant information from the source (0 to 1).\n","\n","Citation Match – Checks whether the cited references align with the actual content used (0 to 1).\n","\n","For example, for the query \"What is ColBERT and why late interaction matters?\", the system generated the following metrics:\n","\n","Metric\tScore\n","Accuracy\t0.95\n","Coverage\t0.90\n","Citation Match\t1.00\n","\n","These scores indicate the system produced an accurate, well-covered, and perfectly cited answer. Running this evaluation across multiple queries provides a quantitative measure of retrieval and generation quality, making the system more robust."]},{"cell_type":"markdown","metadata":{"id":"BhQmgHYyJG_v"},"source":["## For testing only the retriever part before LLM answering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pw3nyUiR91ql"},"outputs":[],"source":["test_queries = [\n","    {\n","        \"question\": \"What is embedding based retieval?\",\n","        \"relevant_sources\": [\n","            \"https://huyenchip.com/2024/07/25/genai-platform.html\"\n","        ]\n","    },\n","    {\n","        \"question\": \"Explain ColBERT model.\",\n","        \"relevant_sources\": [\n","            \"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/\"\n","        ]\n","    },\n","    {\n","        \"question\": \"What causes hallucination?\",\n","        \"relevant_sources\": [\n","            \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\"\n","        ]\n","    },\n","    {\n","        \"question\": \"why qdrant\",\n","        \"relevant_sources\": [\n","            \"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\"\n","        ]\n","    }\n","]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":299,"status":"ok","timestamp":1754982949170,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"adKfwv5NZixy","outputId":"dc37d58a-fed7-4fa1-892a-dcbf9c0bdd55"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision@5: 0.71\n","Average Recall@5: 1.00\n"]}],"source":["def evaluate_retrieval(vectorstore, test_queries, k=5):\n","    # Mapping local file paths to canonical URLs\n","    source_mapping = {\n","        \"/content/drive/MyDrive/RAG_demo/data/genai-platform.txt\": \"https://huyenchip.com/2024/07/25/genai-platform.html\",\n","        \"/content/drive/MyDrive/RAG_demo/data/hallucination.txt\": \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n","        \"/content/drive/MyDrive/RAG_demo/data/quora_engineering.txt\": \"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\"\n","    }\n","\n","    def normalize_source(source):\n","        return source_mapping.get(source, source)  # Replace if in mapping\n","\n","    retriever = vectorstore.as_retriever(search_kwargs={\"k\": k})\n","\n","    all_precisions = []\n","    all_recalls = []\n","\n","    for tq in test_queries:\n","        docs = retriever.get_relevant_documents(tq[\"question\"])\n","\n","        # Normalize retrieved sources\n","        retrieved_sources = list(set(normalize_source(doc.metadata.get(\"source\", \"\")) for doc in docs))\n","\n","        # Convert to binary relevance\n","        y_true = [1 if src in tq[\"relevant_sources\"] else 0 for src in retrieved_sources]\n","\n","        if len(y_true) > 0:\n","            precision = sum(y_true) / len(y_true)  # TP / (TP+FP)\n","            recall = sum(y_true) / len(tq[\"relevant_sources\"])  # TP / (TP+FN)\n","        else:\n","            precision, recall = 0, 0\n","\n","        all_precisions.append(precision)\n","        all_recalls.append(recall)\n","\n","    avg_precision = sum(all_precisions) / len(all_precisions)\n","    avg_recall = sum(all_recalls) / len(all_recalls)\n","\n","    return avg_precision, avg_recall\n","\n","\n","# Example usage:\n","avg_p, avg_r = evaluate_retrieval(vectorstore, test_queries, k=5)\n","print(f\"Average Precision@5: {avg_p:.2f}\")\n","print(f\"Average Recall@5: {avg_r:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74,"status":"ok","timestamp":1754983565781,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"FK7W3pYDJf5e","outputId":"7e6edcd2-c438-421b-a44e-773029fb5e24"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","=== Per-query Retrieval Evaluation (Normalized) ===\n","Q: What is embedding based retieval?\n","  Retrieved: ['https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/', 'https://huyenchip.com/2024/07/25/genai-platform.html', 'https://quoraengineering.quora.com/building-embedding-search-at-quora']\n","  Relevant : ['https://huyenchip.com/2024/07/25/genai-platform.html']\n","  Precision@5: 0.33, Recall@5: 1.00\n","\n","Q: Explain ColBERT model.\n","  Retrieved: ['https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/']\n","  Relevant : ['https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/']\n","  Precision@5: 1.00, Recall@5: 1.00\n","\n","Q: What causes hallucination?\n","  Retrieved: ['https://lilianweng.github.io/posts/2024-07-07-hallucination/', 'https://huyenchip.com/2024/07/25/genai-platform.html']\n","  Relevant : ['https://lilianweng.github.io/posts/2024-07-07-hallucination/']\n","  Precision@5: 0.50, Recall@5: 1.00\n","\n","Q: why qdrant\n","  Retrieved: ['https://quoraengineering.quora.com/building-embedding-search-at-quora']\n","  Relevant : ['https://quoraengineering.quora.com/building-embedding-search-at-quora']\n","  Precision@5: 1.00, Recall@5: 1.00\n","\n","=== Overall Averages ===\n","Average Precision@5: 0.71\n","Average Recall@5: 1.00\n"]}],"source":["def normalize_source(src):\n","    \"\"\"\n","    Normalizes source paths/URLs for matching.\n","    - Strips whitespace\n","    - Converts local file paths to their corresponding URLs if mapping exists\n","    - Lowercases for case-insensitive match\n","    \"\"\"\n","    mapping = {\n","        \"/content/drive/MyDrive/RAG_demo/data/genai-platform.txt\": \"https://huyenchip.com/2024/07/25/genai-platform.html\",\n","        \"/content/drive/MyDrive/RAG_demo/data/hallucination.txt\": \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n","        \"/content/drive/MyDrive/RAG_demo/data/quora_engineering.txt\": \"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\"\n","    }\n","    src = src.strip()\n","    return mapping.get(src, src).lower()\n","\n","\n","def evaluate_retrieval_with_per_query(vectorstore, test_queries, k=5):\n","    retriever = vectorstore.as_retriever(search_kwargs={\"k\": k})\n","\n","    all_precisions = []\n","    all_recalls = []\n","\n","    print(\"\\n=== Per-query Retrieval Evaluation (Normalized) ===\")\n","    for tq in test_queries:\n","        docs = retriever.get_relevant_documents(tq[\"question\"])\n","\n","        retrieved_sources = list(set(normalize_source(doc.metadata.get(\"source\", \"\")) for doc in docs))\n","        relevant_sources = [normalize_source(src) for src in tq[\"relevant_sources\"]]\n","\n","        # Compute precision & recall\n","        if retrieved_sources:\n","            tp = sum(1 for src in retrieved_sources if src in relevant_sources)\n","            precision = tp / len(retrieved_sources)\n","            recall = tp / len(relevant_sources)\n","        else:\n","            precision, recall = 0, 0\n","\n","        all_precisions.append(precision)\n","        all_recalls.append(recall)\n","\n","        print(f\"Q: {tq['question']}\")\n","        print(f\"  Retrieved: {retrieved_sources}\")\n","        print(f\"  Relevant : {relevant_sources}\")\n","        print(f\"  Precision@{k}: {precision:.2f}, Recall@{k}: {recall:.2f}\\n\")\n","\n","    avg_precision = sum(all_precisions) / len(all_precisions)\n","    avg_recall = sum(all_recalls) / len(all_recalls)\n","\n","    print(\"=== Overall Averages ===\")\n","    print(f\"Average Precision@{k}: {avg_precision:.2f}\")\n","    print(f\"Average Recall@{k}: {avg_recall:.2f}\")\n","\n","    return avg_precision, avg_recall\n","\n","\n","# Example usage:\n","avg_p, avg_r = evaluate_retrieval_with_per_query(vectorstore, test_queries, k=5)\n"]},{"cell_type":"markdown","metadata":{"id":"fCD-W67fLzUp"},"source":["# Evaluation Summary\n","\n","To ensure the quality and reliability of the RAG-powered question-answering system, two complementary evaluation approaches were implemented:\n","\n","1. Quantitative Metrics (Precision & Recall)\n","Method: Evaluated using normalized source URLs against a ground-truth mapping for each query.\n","\n","Metrics:\n","\n","Average Precision@5: 0.71\n","\n","Average Recall@5: 1.00\n","\n","Interpretation: The system retrieved relevant documents with high completeness (100% recall) and strong precision, indicating that almost all relevant sources were captured within the top-5 results.\n","\n","2. Qualitative Judgment (LLM-as-a-Judge)\n","\n","Method: Integrated a Large Language Model to automatically assess answers based on:\n","\n","Accuracy – factual correctness of the generated answer.\n","\n","Coverage – completeness of the answer with respect to the question.\n","\n","Citation Match – alignment of the cited sources with the retrieved documents.\n","\n","Example Result:\n","\n","Accuracy: 0.95\n","\n","Coverage: 0.90\n","\n","Citation Match: 1.00\n","\n","Interpretation: The hybrid retrieval pipeline (BM25 + FAISS + reranker) produced highly accurate, complete, and source-grounded answers.\n","\n","Overall Conclusion:\n","\n","The system achieves strong performance in both retrieval relevance (quantitative) and answer quality (qualitative), making it suitable for real-world deployment where trustworthy and well-sourced responses are required."]},{"cell_type":"markdown","metadata":{"id":"mA7EaOdxFU2l"},"source":["# RAG API for single query with Dynamic Indexing\n","\n","Hybrid Retrieval-Augmented Generation API with BM25 + FAISS and Dynamic Web Indexing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":134662,"status":"ok","timestamp":1755225604574,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"lltj6lpnEcdp","outputId":"9461231c-8481-4ae4-f6c9-bec7f5a04efa"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m139.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# Install packages\n","!pip install fastapi uvicorn pyngrok nest-asyncio --quiet\n","!pip install rank-bm25 sentence-transformers langchain-community langchain-google-genai faiss-cpu --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1331678,"status":"ok","timestamp":1755231171120,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"kNuKu6y3lsIe","outputId":"fa33c69c-96c7-4b9b-94e9-2abcfcd2cd81"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ All imports successful!\n","Enter your ngrok token (get free at https://dashboard.ngrok.com/get-started/your-authtoken): ··········\n","✅ API keys configured!\n","✅ FastAPI app configured!\n","✅ Helper functions defined!\n","🔄 Loading models...\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-2026482930.py:109: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n","  @validator('url')\n"]},{"name":"stdout","output_type":"stream","text":["✅ Embedding model loaded\n","✅ Text splitter initialized\n","✅ Static FAISS vectorstore loaded\n","✅ Dynamic FAISS vectorstore loaded\n","✅ LLM initialized\n","✅ Prompt template created\n","✅ Reranker loaded\n","🎉 All models initialized successfully!\n","✅ API endpoints defined!\n","🌐 Public URL: NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"\n","📚 API Documentation: NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/docs\n","🔑 API Key: demo-api-key-123\n","\n","📋 Available Endpoints:\n","  • POST NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/index - Index new URLs\n","  • POST NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/query - Query the RAG system\n","  • GET  NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/sources - List all sources\n","  • GET  NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/index/status - Get index status\n","  • DELETE NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/index/{url_hash} - Remove indexed URL\n","  • POST NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/index/reindex - Reindex all URLs\n","  • GET  NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/health - Health check\n","==================================================\n","💡 Example Usage:\n","\n","# Index a URL:\n","curl -X POST \"NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/index\" \\\n","  -H \"Authorization: Bearer demo-api-key-123\" \\\n","  -H \"Content-Type: application/json\" \\\n","  -d '{\"url\": [\"https://example.com\"]}'\n","\n","# Query the system:\n","curl -X POST \"NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/query\" \\\n","  -H \"Authorization: Bearer demo-api-key-123\" \\\n","  -H \"Content-Type: application/json\" \\\n","  -d '{\"question\": \"What is RAG?\", \"use_dynamic_index\": true}'\n","\n","# Check index status:\n","curl -X GET \"NgrokTunnel: \"https://0134d072aba6.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/index/status\" \\\n","  -H \"Authorization: Bearer demo-api-key-123\"\n","    \n","==================================================\n"]},{"name":"stderr","output_type":"stream","text":["INFO:     Started server process [164]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:     2409:40f4:211a:e929:f47f:ed08:b352:6ee7:0 - \"GET /docs HTTP/1.1\" 200 OK\n","INFO:     2409:40f4:211a:e929:f47f:ed08:b352:6ee7:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n","WARNING:__main__:Attempt 1 failed for https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf: No content extracted\n","WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n","WARNING:__main__:Attempt 2 failed for https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf: No content extracted\n","WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n","WARNING:__main__:Attempt 3 failed for https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf: No content extracted\n"]},{"name":"stdout","output_type":"stream","text":["INFO:     2409:40f4:211a:e929:f47f:ed08:b352:6ee7:0 - \"POST /api/v1/index HTTP/1.1\" 200 OK\n","INFO:     2409:40f4:211a:e929:f47f:ed08:b352:6ee7:0 - \"GET /api/v1/index/status HTTP/1.1\" 200 OK\n","INFO:     2409:40f4:211a:e929:f47f:ed08:b352:6ee7:0 - \"DELETE /api/v1/index/https%3A//proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf HTTP/1.1\" 404 Not Found\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n","WARNING:__main__:Attempt 1 failed for https://7987165.fs1.hubspotusercontent-na1.net/hubfs/7987165/Downloadable%20PDF%20articles/AI%20for%20Blog%20Writing.pdf?hsCtaTracking=b242d2ee-9b17-47e6-9ad8-694758601b21%7Cca694cdb-45de-40d0-914f-40b33c527797: No content extracted\n","WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n","WARNING:__main__:Attempt 2 failed for https://7987165.fs1.hubspotusercontent-na1.net/hubfs/7987165/Downloadable%20PDF%20articles/AI%20for%20Blog%20Writing.pdf?hsCtaTracking=b242d2ee-9b17-47e6-9ad8-694758601b21%7Cca694cdb-45de-40d0-914f-40b33c527797: No content extracted\n","WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n","WARNING:__main__:Attempt 3 failed for https://7987165.fs1.hubspotusercontent-na1.net/hubfs/7987165/Downloadable%20PDF%20articles/AI%20for%20Blog%20Writing.pdf?hsCtaTracking=b242d2ee-9b17-47e6-9ad8-694758601b21%7Cca694cdb-45de-40d0-914f-40b33c527797: No content extracted\n"]},{"name":"stdout","output_type":"stream","text":["INFO:     2409:40f4:211a:e929:f47f:ed08:b352:6ee7:0 - \"POST /api/v1/index HTTP/1.1\" 200 OK\n","INFO:     2409:40f4:211a:e929:f47f:ed08:b352:6ee7:0 - \"GET /health HTTP/1.1\" 200 OK\n","INFO:     2409:40f4:211a:e929:f47f:ed08:b352:6ee7:0 - \"GET /api/v1/sources HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["INFO:     Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:     Finished server process [164]\n"]}],"source":["# Setup imports and basic configuration\n","import os\n","import json\n","import time\n","import shutil\n","from datetime import datetime, timedelta\n","from typing import List, Optional, Dict, Any\n","from urllib.parse import urlparse, urljoin\n","import requests\n","from bs4 import BeautifulSoup\n","import nest_asyncio\n","from pyngrok import ngrok\n","import uvicorn\n","from fastapi import FastAPI, HTTPException, Depends, status, Body\n","from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n","from fastapi.middleware.cors import CORSMiddleware\n","from pydantic import BaseModel, Field, validator\n","import logging\n","from getpass import getpass\n","from collections import OrderedDict\n","import hashlib\n","import re\n","\n","# Import the RAG components\n","from rank_bm25 import BM25Okapi\n","from sentence_transformers import CrossEncoder\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_community.vectorstores import FAISS\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain.prompts import PromptTemplate\n","from langchain.docstore.document import Document\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# Enable asyncio in Colab\n","nest_asyncio.apply()\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","print(\"✅ All imports successful!\")\n","\n","# Set up API keys\n","# Set Google API key\n","if \"GOOGLE_API_KEY\" not in os.environ:\n","    os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API key: \")\n","\n","# Set ngrok token\n","ngrok_token = getpass(\"Enter your ngrok token (get free at https://dashboard.ngrok.com/get-started/your-authtoken): \")\n","ngrok.set_auth_token(ngrok_token)\n","\n","print(\"✅ API keys configured!\")\n","\n","# Define the FastAPI app\n","app = FastAPI(\n","    title=\"RAG API with Dynamic Indexing\",\n","    description=\"Hybrid Retrieval-Augmented Generation API with BM25 + FAISS and Dynamic Web Indexing\",\n","    version=\"2.0.0\"\n",")\n","\n","app.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=[\"*\"],\n","    allow_credentials=True,\n","    allow_methods=[\"*\"],\n","    allow_headers=[\"*\"],\n",")\n","\n","security = HTTPBearer()\n","\n","# Configuration\n","class Config:\n","    # Static index (existing)\n","    STATIC_FAISS_PATH = \"/content/drive/MyDrive/RAG_demo/faiss_index\"\n","\n","    # Dynamic index (new)\n","    DYNAMIC_BASE_PATH = \"/content/drive/MyDrive/RAG_demo/dynamic_index\"\n","    DYNAMIC_FAISS_PATH = \"/content/drive/MyDrive/RAG_demo/dynamic_index/faiss_index\"\n","    METADATA_PATH = \"/content/drive/MyDrive/RAG_demo/dynamic_index/metadata\"\n","    BACKUP_PATH = \"/content/drive/MyDrive/RAG_demo/dynamic_index/backups\"\n","\n","    # Indexing settings\n","    USE_RERANKER = True\n","    RERANKER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n","    BM25_TOP_K = 10\n","    FAISS_TOP_K = 10\n","    FINAL_TOP_K = 3\n","\n","    # Web scraping settings\n","    REQUEST_TIMEOUT = 30\n","    MAX_RETRIES = 3\n","    RETRY_DELAY = 2\n","    CHUNK_SIZE = 1000\n","    CHUNK_OVERLAP = 100\n","    RE_INDEX_DAYS = 7\n","    MAX_VERSIONS = 3\n","\n","    # Authentication\n","    VALID_API_KEYS = {\n","        \"demo-api-key-123\": {\"user\": \"demo_user\", \"permissions\": [\"read\", \"query\", \"index\"]},\n","    }\n","\n","config = Config()\n","\n","# Pydantic models\n","class IndexRequest(BaseModel):\n","    url: List[str] = Field(..., min_items=1, max_items=10, description=\"URLs to index\")\n","\n","    @validator('url')\n","    def validate_urls(cls, v):\n","        for url in v:\n","            parsed = urlparse(url)\n","            if not parsed.scheme or not parsed.netloc:\n","                raise ValueError(f\"Invalid URL format: {url}\")\n","        return v\n","\n","class IndexResponse(BaseModel):\n","    status: str\n","    indexed_url: List[str]\n","    failed_url: Optional[List[Dict[str, str]]] = None\n","    metadata: Dict[str, Any] = Field(default_factory=dict)\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","\n","class QueryRequest(BaseModel):\n","    question: str = Field(..., min_length=1, max_length=1000, description=\"The question to ask\")\n","    top_k: Optional[int] = Field(default=3, ge=1, le=10, description=\"Number of results to return\")\n","    use_reranker: Optional[bool] = Field(default=True, description=\"Whether to use cross-encoder reranking\")\n","    use_dynamic_index: Optional[bool] = Field(default=True, description=\"Whether to search dynamic index\")\n","\n","class QueryResponse(BaseModel):\n","    answer: str\n","    sources: List[str]\n","    metadata: dict = Field(default_factory=dict)\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","\n","class HealthResponse(BaseModel):\n","    status: str\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","    components: dict\n","\n","# Global variables\n","embedding_model = None\n","static_vectorstore = None\n","dynamic_vectorstore = None\n","llm = None\n","bm25_static = None\n","bm25_dynamic = None\n","bm25_docs_static = None\n","bm25_docs_dynamic = None\n","bm25_sources_static = None\n","bm25_sources_dynamic = None\n","reranker = None\n","text_to_docs_static = None\n","text_to_docs_dynamic = None\n","prompt = None\n","text_splitter = None\n","\n","print(\"✅ FastAPI app configured!\")\n","\n","# Authentication\n","async def verify_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)):\n","    \"\"\"Verify API key from Authorization header\"\"\"\n","    api_key = credentials.credentials\n","    if api_key not in config.VALID_API_KEYS:\n","        logger.warning(f\"Invalid API key attempted: {api_key[:10]}...\")\n","        raise HTTPException(\n","            status_code=status.HTTP_401_UNAUTHORIZED,\n","            detail=\"Invalid API key\",\n","            headers={\"WWW-Authenticate\": \"Bearer\"},\n","        )\n","    return config.VALID_API_KEYS[api_key]\n","\n","# Utility functions\n","def ensure_directories():\n","    \"\"\"Ensure all required directories exist\"\"\"\n","    directories = [\n","        config.DYNAMIC_BASE_PATH,\n","        config.DYNAMIC_FAISS_PATH,\n","        config.METADATA_PATH,\n","        config.BACKUP_PATH\n","    ]\n","    for directory in directories:\n","        os.makedirs(directory, exist_ok=True)\n","    logger.info(\"✅ Directory structure created\")\n","\n","def get_url_hash(url: str) -> str:\n","    \"\"\"Generate a hash for URL to use as unique identifier\"\"\"\n","    return hashlib.md5(url.encode()).hexdigest()\n","\n","def load_metadata(file_path: str) -> Dict:\n","    \"\"\"Load metadata from JSON file\"\"\"\n","    if os.path.exists(file_path):\n","        try:\n","            with open(file_path, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        except Exception as e:\n","            logger.error(f\"Error loading metadata from {file_path}: {str(e)}\")\n","    return {}\n","\n","def save_metadata(data: Dict, file_path: str):\n","    \"\"\"Save metadata to JSON file\"\"\"\n","    try:\n","        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n","        with open(file_path, 'w', encoding='utf-8') as f:\n","            json.dump(data, f, indent=2, default=str)\n","    except Exception as e:\n","        logger.error(f\"Error saving metadata to {file_path}: {str(e)}\")\n","        raise\n","\n","def should_reindex_url(url: str, metadata: Dict) -> bool:\n","    \"\"\"Check if URL should be re-indexed\"\"\"\n","    url_hash = get_url_hash(url)\n","    if url_hash not in metadata:\n","        return True\n","\n","    last_indexed = datetime.fromisoformat(metadata[url_hash]['timestamp'])\n","    age_days = (datetime.now() - last_indexed).days\n","\n","    return age_days >= config.RE_INDEX_DAYS\n","\n","# Web scraping functions\n","class WebScraper:\n","    def __init__(self):\n","        self.session = requests.Session()\n","        self.session.headers.update({\n","            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n","        })\n","\n","    def extract_content(self, url: str) -> Dict[str, Any]:\n","        \"\"\"Extract content from URL with retry logic\"\"\"\n","        for attempt in range(config.MAX_RETRIES):\n","            try:\n","                response = self.session.get(url, timeout=config.REQUEST_TIMEOUT)\n","                response.raise_for_status()\n","\n","                soup = BeautifulSoup(response.content, 'html.parser')\n","\n","                # Remove unwanted elements\n","                for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'advertisement']):\n","                    element.decompose()\n","\n","                # Extract title\n","                title = soup.find('title')\n","                title_text = title.get_text().strip() if title else url\n","\n","                # Extract main content\n","                content_selectors = [\n","                    'article', 'main', '[role=\"main\"]',\n","                    '.content', '.post', '.article',\n","                    'div.container', 'div.wrapper'\n","                ]\n","\n","                content_text = \"\"\n","                for selector in content_selectors:\n","                    content = soup.select_one(selector)\n","                    if content:\n","                        content_text = content.get_text()\n","                        break\n","\n","                if not content_text:\n","                    # Fallback to body\n","                    body = soup.find('body')\n","                    content_text = body.get_text() if body else \"\"\n","\n","                # Clean text\n","                content_text = re.sub(r'\\s+', ' ', content_text).strip()\n","\n","                if not content_text:\n","                    raise ValueError(\"No content extracted\")\n","\n","                return {\n","                    'title': title_text,\n","                    'content': content_text,\n","                    'url': url,\n","                    'success': True,\n","                    'error': None\n","                }\n","\n","            except Exception as e:\n","                logger.warning(f\"Attempt {attempt + 1} failed for {url}: {str(e)}\")\n","                if attempt < config.MAX_RETRIES - 1:\n","                    time.sleep(config.RETRY_DELAY * (2 ** attempt))\n","                else:\n","                    return {\n","                        'title': None,\n","                        'content': None,\n","                        'url': url,\n","                        'success': False,\n","                        'error': str(e)\n","                    }\n","\n","# FAISS management functions\n","def create_version_backup():\n","    \"\"\"Create a backup of current version\"\"\"\n","    if not os.path.exists(config.DYNAMIC_FAISS_PATH):\n","        return\n","\n","    versions_file = os.path.join(config.METADATA_PATH, 'versions.json')\n","    versions = load_metadata(versions_file)\n","\n","    current_version = versions.get('current_version', 0)\n","    backup_dir = os.path.join(config.BACKUP_PATH, f'v{current_version}_backup')\n","\n","    if os.path.exists(config.DYNAMIC_FAISS_PATH):\n","        if os.path.exists(backup_dir):\n","            shutil.rmtree(backup_dir)\n","        shutil.copytree(config.DYNAMIC_FAISS_PATH, backup_dir)\n","        logger.info(f\"✅ Created backup: v{current_version}\")\n","\n","def cleanup_old_backups():\n","    \"\"\"Remove old backup versions\"\"\"\n","    versions_file = os.path.join(config.METADATA_PATH, 'versions.json')\n","    versions = load_metadata(versions_file)\n","    current_version = versions.get('current_version', 0)\n","\n","    for i in range(max(0, current_version - config.MAX_VERSIONS)):\n","        old_backup = os.path.join(config.BACKUP_PATH, f'v{i}_backup')\n","        if os.path.exists(old_backup):\n","            shutil.rmtree(old_backup)\n","            logger.info(f\"🗑️ Removed old backup: v{i}\")\n","\n","def update_version():\n","    \"\"\"Update version metadata\"\"\"\n","    versions_file = os.path.join(config.METADATA_PATH, 'versions.json')\n","    versions = load_metadata(versions_file)\n","\n","    new_version = versions.get('current_version', 0) + 1\n","    versions.update({\n","        'current_version': new_version,\n","        'last_updated': datetime.now().isoformat(),\n","        'total_updates': versions.get('total_updates', 0) + 1\n","    })\n","\n","    save_metadata(versions, versions_file)\n","    return new_version\n","\n","def build_bm25_from_vectorstore(vectorstore):\n","    \"\"\"Build BM25 index from FAISS vectorstore\"\"\"\n","    try:\n","        docs = []\n","        sources = []\n","        for doc_id, doc in vectorstore.docstore._dict.items():\n","            text = getattr(doc, \"page_content\", None) or doc.page_content\n","            docs.append(text)\n","            sources.append(doc.metadata.get(\"source\", \"Unknown\"))\n","\n","        tokenized = [d.split() for d in docs]\n","        bm25 = BM25Okapi(tokenized)\n","\n","        # Build text to docs mapping\n","        text_to_docs = {}\n","        for doc in vectorstore.docstore._dict.values():\n","            text = doc.page_content\n","            text_to_docs.setdefault(text, []).append(doc)\n","\n","        logger.info(f\"BM25 built over {len(docs)} chunks\")\n","        return bm25, docs, sources, text_to_docs\n","    except Exception as e:\n","        logger.error(f\"Error building BM25: {str(e)}\")\n","        raise\n","\n","# Source URL mapping\n","source_url_map = {\n","    \"/content/drive/MyDrive/RAG_demo/data/genai-platform.txt\": \"https://huyenchip.com/2024/07/25/genai-platform.html\",\n","    \"/content/drive/MyDrive/RAG_demo/data/hallucination.txt\": \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n","    \"/content/drive/MyDrive/RAG_demo/data/quora_engineering.txt\": \"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\"\n","}\n","\n","def format_sources(sources):\n","    \"\"\"Convert file paths to URLs\"\"\"\n","    formatted = []\n","    for source in sources:\n","        if source.startswith('http'):\n","            formatted.append(source)\n","        else:\n","            formatted.append(source_url_map.get(source, source))\n","    return formatted\n","\n","def hybrid_search(query: str, use_dynamic: bool = True, bm_k: int = 10, faiss_k: int = 10, top_k: int = 3, use_reranker: bool = True):\n","    \"\"\"Perform hybrid search on static and/or dynamic indices\"\"\"\n","    try:\n","        all_candidates = []\n","\n","        # Search static index\n","        if static_vectorstore:\n","            candidates_static = _search_single_index(\n","                query, static_vectorstore, bm25_static, bm25_docs_static,\n","                bm25_sources_static, text_to_docs_static, bm_k, faiss_k\n","            )\n","            all_candidates.extend(candidates_static)\n","\n","        # Search dynamic index\n","        if use_dynamic and dynamic_vectorstore:\n","            candidates_dynamic = _search_single_index(\n","                query, dynamic_vectorstore, bm25_dynamic, bm25_docs_dynamic,\n","                bm25_sources_dynamic, text_to_docs_dynamic, bm_k, faiss_k\n","            )\n","            all_candidates.extend(candidates_dynamic)\n","\n","        if not all_candidates:\n","            return []\n","\n","        # Merge and deduplicate candidates\n","        merged = OrderedDict()\n","        for candidate in all_candidates:\n","            key = candidate[\"text\"].strip()\n","            if key not in merged or (candidate.get(\"bm25_score\") or 0) > (merged[key].get(\"bm25_score\") or 0):\n","                merged[key] = candidate\n","\n","        candidates = list(merged.values())\n","\n","        # Optional reranking\n","        if use_reranker and reranker and candidates:\n","            pairs = [(query, c[\"text\"]) for c in candidates]\n","            scores = reranker.predict(pairs)\n","            for c, s in zip(candidates, scores):\n","                c[\"rerank_score\"] = float(s)\n","            candidates = sorted(candidates, key=lambda x: x[\"rerank_score\"], reverse=True)\n","        else:\n","            candidates = sorted(candidates, key=lambda x: (0 if x[\"bm25_score\"] is not None else 1, -(x[\"bm25_score\"] or 0)))\n","\n","        # Return top_k Document objects\n","        final_docs = []\n","        for c in candidates[:top_k]:\n","            text = c[\"text\"]\n","            # Try to find in both mappings\n","            docs_list = text_to_docs_static.get(text, []) if text_to_docs_static else []\n","            if not docs_list and text_to_docs_dynamic:\n","                docs_list = text_to_docs_dynamic.get(text, [])\n","\n","            if docs_list:\n","                final_docs.append(docs_list[0])\n","            else:\n","                final_docs.append(Document(page_content=text, metadata={\"source\": c.get(\"source\", \"Unknown\")}))\n","\n","        return final_docs\n","\n","    except Exception as e:\n","        logger.error(f\"Error in hybrid search: {str(e)}\")\n","        raise\n","\n","def _search_single_index(query: str, vectorstore, bm25, bm25_docs, bm25_sources, text_to_docs, bm_k: int, faiss_k: int):\n","    \"\"\"Search a single index (static or dynamic)\"\"\"\n","    candidates = []\n","\n","    # BM25 candidates\n","    if bm25 and bm25_docs:\n","        tokenized_q = query.split()\n","        bm25_scores = bm25.get_scores(tokenized_q)\n","        bm25_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:bm_k]\n","        for idx in bm25_indices:\n","            txt = bm25_docs[idx]\n","            src = bm25_sources[idx]\n","            candidates.append({\"text\": txt, \"source\": src, \"bm25_score\": bm25_scores[idx]})\n","\n","    # FAISS candidates\n","    if vectorstore:\n","        faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": faiss_k})\n","        faiss_docs = faiss_retriever.get_relevant_documents(query)\n","        for d in faiss_docs:\n","            candidates.append({\"text\": d.page_content, \"source\": d.metadata.get(\"source\", \"Unknown\"), \"bm25_score\": None})\n","\n","    return candidates\n","\n","print(\"✅ Helper functions defined!\")\n","\n","# Initialize models\n","def initialize_models():\n","    \"\"\"Initialize all models and components\"\"\"\n","    global embedding_model, static_vectorstore, dynamic_vectorstore, llm\n","    global bm25_static, bm25_dynamic, bm25_docs_static, bm25_docs_dynamic\n","    global bm25_sources_static, bm25_sources_dynamic, reranker\n","    global text_to_docs_static, text_to_docs_dynamic, prompt, text_splitter\n","\n","    try:\n","        print(\"🔄 Loading models...\")\n","        ensure_directories()\n","\n","        # Load embedding model\n","        embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","        print(\"✅ Embedding model loaded\")\n","\n","        # Initialize text splitter\n","        text_splitter = RecursiveCharacterTextSplitter(\n","            chunk_size=config.CHUNK_SIZE,\n","            chunk_overlap=config.CHUNK_OVERLAP,\n","            length_function=len,\n","            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n","        )\n","        print(\"✅ Text splitter initialized\")\n","\n","        # Load static FAISS vectorstore\n","        try:\n","            static_vectorstore = FAISS.load_local(\n","                config.STATIC_FAISS_PATH,\n","                embedding_model,\n","                allow_dangerous_deserialization=True\n","            )\n","            bm25_static, bm25_docs_static, bm25_sources_static, text_to_docs_static = build_bm25_from_vectorstore(static_vectorstore)\n","            print(\"✅ Static FAISS vectorstore loaded\")\n","        except Exception as e:\n","            print(f\"⚠️ Static FAISS not found: {str(e)}\")\n","\n","        # Load dynamic FAISS vectorstore (if exists)\n","        try:\n","            dynamic_vectorstore = FAISS.load_local(\n","                config.DYNAMIC_FAISS_PATH,\n","                embedding_model,\n","                allow_dangerous_deserialization=True\n","            )\n","            bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic = build_bm25_from_vectorstore(dynamic_vectorstore)\n","            print(\"✅ Dynamic FAISS vectorstore loaded\")\n","        except Exception as e:\n","            print(f\"ℹ️ Dynamic FAISS not found (will create on first index): {str(e)}\")\n","\n","        # Initialize LLM\n","        llm = ChatGoogleGenerativeAI(\n","            model=\"gemini-1.5-flash\",\n","            temperature=0,\n","            google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n","        )\n","        print(\"✅ LLM initialized\")\n","\n","        # Create prompt template\n","        prompt_template = \"\"\"\n","        Use the provided context to answer the question.\n","        If the answer is not in the context, say: I couldn't find anything in my knowledge base about that topic. I can only answer questions related to AI, RAG, and the documents you provided.\n","\n","        Context:\n","        {context}\n","\n","        Question:\n","        {question}\n","\n","        Answer:\n","        \"\"\"\n","        prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n","        print(\"✅ Prompt template created\")\n","\n","        # Load reranker\n","        if config.USE_RERANKER:\n","            reranker = CrossEncoder(config.RERANKER_MODEL)\n","            print(\"✅ Reranker loaded\")\n","\n","        print(\"🎉 All models initialized successfully!\")\n","\n","    except Exception as e:\n","        print(f\"❌ Error initializing models: {str(e)}\")\n","        raise\n","\n","# Run the initialization\n","initialize_models()\n","\n","# API Endpoints\n","@app.get(\"/health\", response_model=HealthResponse)\n","async def health_check():\n","    \"\"\"Health check endpoint\"\"\"\n","    components = {\n","        \"static_vectorstore\": static_vectorstore is not None,\n","        \"dynamic_vectorstore\": dynamic_vectorstore is not None,\n","        \"llm\": llm is not None,\n","        \"bm25_static\": bm25_static is not None,\n","        \"bm25_dynamic\": bm25_dynamic is not None,\n","        \"reranker\": reranker is not None if config.USE_RERANKER else \"disabled\"\n","    }\n","    status = \"healthy\" if llm is not None else \"unhealthy\"\n","    return HealthResponse(status=status, components=components)\n","\n","@app.post(\"/api/v1/index\", response_model=IndexResponse)\n","async def index_urls(\n","    request: IndexRequest,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Index URLs into the dynamic vector database\"\"\"\n","    global dynamic_vectorstore, bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic\n","\n","    # Check permissions\n","    if \"index\" not in user_info.get(\"permissions\", []):\n","        raise HTTPException(\n","            status_code=status.HTTP_403_FORBIDDEN,\n","            detail=\"Insufficient permissions for indexing\"\n","        )\n","\n","    logger.info(f\"Indexing request from {user_info['user']}: {len(request.url)} URLs\")\n","\n","    scraper = WebScraper()\n","    indexed_urls = []\n","    failed_urls = []\n","\n","    # Load existing metadata\n","    urls_metadata_file = os.path.join(config.METADATA_PATH, 'indexed_urls.json')\n","    urls_metadata = load_metadata(urls_metadata_file)\n","\n","    try:\n","        # Create backup before major changes\n","        create_version_backup()\n","\n","        new_documents = []\n","\n","        for url in request.url:\n","            try:\n","                # Check if we should reindex\n","                if not should_reindex_url(url, urls_metadata):\n","                    logger.info(f\"Skipping {url} - recently indexed\")\n","                    continue\n","\n","                logger.info(f\"Processing URL: {url}\")\n","\n","                # Extract content\n","                result = scraper.extract_content(url)\n","\n","                if not result['success']:\n","                    failed_urls.append({\n","                        \"url\": url,\n","                        \"error\": result['error'],\n","                        \"error_type\": \"EXTRACTION_FAILED\"\n","                    })\n","                    continue\n","\n","                # Split content into chunks\n","                chunks = text_splitter.split_text(result['content'])\n","\n","                # Create documents\n","                for i, chunk in enumerate(chunks):\n","                    doc = Document(\n","                        page_content=chunk,\n","                        metadata={\n","                            \"source\": url,\n","                            \"title\": result['title'],\n","                            \"chunk_id\": i,\n","                            \"total_chunks\": len(chunks),\n","                            \"indexed_at\": datetime.now().isoformat(),\n","                            \"url_hash\": get_url_hash(url)\n","                        }\n","                    )\n","                    new_documents.append(doc)\n","\n","                # Update URL metadata\n","                url_hash = get_url_hash(url)\n","                urls_metadata[url_hash] = {\n","                    \"url\": url,\n","                    \"title\": result['title'],\n","                    \"timestamp\": datetime.now().isoformat(),\n","                    \"chunk_count\": len(chunks),\n","                    \"status\": \"indexed\"\n","                }\n","\n","                indexed_urls.append(url)\n","                logger.info(f\"✅ Successfully processed {url} - {len(chunks)} chunks\")\n","\n","            except Exception as e:\n","                logger.error(f\"Error processing {url}: {str(e)}\")\n","                failed_urls.append({\n","                    \"url\": url,\n","                    \"error\": str(e),\n","                    \"error_type\": \"PROCESSING_ERROR\"\n","                })\n","\n","        # Update vector database if we have new documents\n","        if new_documents:\n","            try:\n","                if dynamic_vectorstore is None:\n","                    # Create new FAISS index\n","                    dynamic_vectorstore = FAISS.from_documents(new_documents, embedding_model)\n","                    logger.info(\"✅ Created new dynamic FAISS index\")\n","                else:\n","                    # Add to existing index\n","                    dynamic_vectorstore.add_documents(new_documents)\n","                    logger.info(f\"✅ Added {len(new_documents)} documents to existing index\")\n","\n","                # Save updated index\n","                dynamic_vectorstore.save_local(config.DYNAMIC_FAISS_PATH)\n","\n","                # Rebuild BM25 and mappings\n","                bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic = build_bm25_from_vectorstore(dynamic_vectorstore)\n","\n","                # Update version\n","                new_version = update_version()\n","\n","                # Cleanup old backups\n","                cleanup_old_backups()\n","\n","                logger.info(f\"✅ Dynamic index updated to version {new_version}\")\n","\n","            except Exception as e:\n","                logger.error(f\"Error updating vector database: {str(e)}\")\n","                raise HTTPException(\n","                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","                    detail=f\"Failed to update vector database: {str(e)}\"\n","                )\n","\n","        # Save URL metadata\n","        save_metadata(urls_metadata, urls_metadata_file)\n","\n","        # Prepare response\n","        response_status = \"success\" if indexed_urls else \"failed\"\n","        if indexed_urls and failed_urls:\n","            response_status = \"partial_success\"\n","\n","        metadata = {\n","            \"total_requested\": len(request.url),\n","            \"successfully_indexed\": len(indexed_urls),\n","            \"failed\": len(failed_urls),\n","            \"new_documents_added\": len(new_documents),\n","            \"user\": user_info[\"user\"]\n","        }\n","\n","        return IndexResponse(\n","            status=response_status,\n","            indexed_url=indexed_urls,\n","            failed_url=failed_urls if failed_urls else None,\n","            metadata=metadata\n","        )\n","\n","    except Exception as e:\n","        logger.error(f\"Critical error in indexing: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Indexing failed: {str(e)}\"\n","        )\n","\n","@app.post(\"/query\", response_model=QueryResponse)\n","async def query_rag(\n","    request: QueryRequest,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Main RAG query endpoint\"\"\"\n","    try:\n","        logger.info(f\"Query from user {user_info['user']}: {request.question[:50]}...\")\n","\n","        # Perform hybrid search\n","        docs = hybrid_search(\n","            request.question,\n","            use_dynamic=request.use_dynamic_index,\n","            bm_k=config.BM25_TOP_K,\n","            faiss_k=config.FAISS_TOP_K,\n","            top_k=request.top_k,\n","            use_reranker=request.use_reranker and config.USE_RERANKER\n","        )\n","\n","        if not docs:\n","            raise HTTPException(\n","                status_code=status.HTTP_404_NOT_FOUND,\n","                detail=\"No relevant documents found\"\n","            )\n","\n","        # Create context and query LLM\n","        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n","        formatted_prompt = prompt.format(context=context, question=request.question)\n","        response = llm.invoke(formatted_prompt)\n","        answer_text = response.content.strip()\n","\n","        # Check for out-of-scope responses\n","        fallback_msg = \"i couldn't find anything in my knowledge base about that topic\"\n","        if fallback_msg.lower() in answer_text.lower():\n","            sources = []\n","            logger.info(f\"Out-of-scope query: {request.question}\")\n","        else:\n","            sources = list(OrderedDict.fromkeys(doc.metadata.get(\"source\", \"Unknown\") for doc in docs))\n","            sources = format_sources(sources)\n","\n","        metadata = {\n","            \"query_length\": len(request.question),\n","            \"num_docs_retrieved\": len(docs),\n","            \"reranker_used\": request.use_reranker and config.USE_RERANKER,\n","            \"dynamic_index_used\": request.use_dynamic_index,\n","            \"static_index_available\": static_vectorstore is not None,\n","            \"dynamic_index_available\": dynamic_vectorstore is not None,\n","            \"user\": user_info[\"user\"]\n","        }\n","\n","        return QueryResponse(\n","            answer=answer_text,\n","            sources=sources,\n","            metadata=metadata\n","        )\n","\n","    except HTTPException:\n","        raise\n","    except Exception as e:\n","        logger.error(f\"Error processing query: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Internal server error: {str(e)}\"\n","        )\n","\n","@app.get(\"/api/v1/sources\")\n","async def list_sources(user_info: dict = Depends(verify_api_key)):\n","    \"\"\"List available sources in both static and dynamic knowledge bases\"\"\"\n","    static_sources = set()\n","    dynamic_sources = set()\n","\n","    # Get static sources\n","    if static_vectorstore:\n","        for doc in static_vectorstore.docstore._dict.values():\n","            source = doc.metadata.get(\"source\", \"Unknown\")\n","            static_sources.add(source)\n","\n","    # Get dynamic sources\n","    if dynamic_vectorstore:\n","        for doc in dynamic_vectorstore.docstore._dict.values():\n","            source = doc.metadata.get(\"source\", \"Unknown\")\n","            dynamic_sources.add(source)\n","\n","    # Load indexed URLs metadata\n","    urls_metadata_file = os.path.join(config.METADATA_PATH, 'indexed_urls.json')\n","    urls_metadata = load_metadata(urls_metadata_file)\n","\n","    # Load versions metadata\n","    versions_file = os.path.join(config.METADATA_PATH, 'versions.json')\n","    versions = load_metadata(versions_file)\n","\n","    return {\n","        \"static_sources\": {\n","            \"sources\": format_sources(list(static_sources)),\n","            \"total_documents\": len(static_vectorstore.docstore._dict) if static_vectorstore else 0\n","        },\n","        \"dynamic_sources\": {\n","            \"sources\": list(dynamic_sources),\n","            \"total_documents\": len(dynamic_vectorstore.docstore._dict) if dynamic_vectorstore else 0,\n","            \"indexed_urls_count\": len(urls_metadata),\n","            \"current_version\": versions.get(\"current_version\", 0),\n","            \"last_updated\": versions.get(\"last_updated\")\n","        },\n","        \"metadata\": {\n","            \"total_urls_indexed\": len(urls_metadata),\n","            \"total_documents\": (len(static_vectorstore.docstore._dict) if static_vectorstore else 0) +\n","                             (len(dynamic_vectorstore.docstore._dict) if dynamic_vectorstore else 0)\n","        },\n","        \"timestamp\": datetime.now()\n","    }\n","\n","@app.get(\"/api/v1/index/status\")\n","async def get_index_status(user_info: dict = Depends(verify_api_key)):\n","    \"\"\"Get detailed status of the dynamic indexing system\"\"\"\n","\n","    # Load metadata files\n","    urls_metadata_file = os.path.join(config.METADATA_PATH, 'indexed_urls.json')\n","    urls_metadata = load_metadata(urls_metadata_file)\n","\n","    versions_file = os.path.join(config.METADATA_PATH, 'versions.json')\n","    versions = load_metadata(versions_file)\n","\n","    # Calculate statistics\n","    recent_urls = []\n","    old_urls = []\n","    now = datetime.now()\n","\n","    for url_hash, url_data in urls_metadata.items():\n","        indexed_time = datetime.fromisoformat(url_data['timestamp'])\n","        age_days = (now - indexed_time).days\n","\n","        url_info = {\n","            \"url\": url_data['url'],\n","            \"title\": url_data.get('title', ''),\n","            \"indexed_at\": url_data['timestamp'],\n","            \"age_days\": age_days,\n","            \"chunk_count\": url_data.get('chunk_count', 0)\n","        }\n","\n","        if age_days < config.RE_INDEX_DAYS:\n","            recent_urls.append(url_info)\n","        else:\n","            old_urls.append(url_info)\n","\n","    # Get backup information\n","    backup_versions = []\n","    if os.path.exists(config.BACKUP_PATH):\n","        for item in os.listdir(config.BACKUP_PATH):\n","            if item.endswith('_backup'):\n","                version_num = item.replace('_backup', '').replace('v', '')\n","                backup_path = os.path.join(config.BACKUP_PATH, item)\n","                backup_size = sum(os.path.getsize(os.path.join(backup_path, f))\n","                                for f in os.listdir(backup_path) if os.path.isfile(os.path.join(backup_path, f)))\n","                backup_versions.append({\n","                    \"version\": version_num,\n","                    \"size_bytes\": backup_size,\n","                    \"created\": datetime.fromtimestamp(os.path.getctime(backup_path)).isoformat()\n","                })\n","\n","    return {\n","        \"system_status\": {\n","            \"dynamic_index_exists\": dynamic_vectorstore is not None,\n","            \"current_version\": versions.get(\"current_version\", 0),\n","            \"total_updates\": versions.get(\"total_updates\", 0),\n","            \"last_updated\": versions.get(\"last_updated\")\n","        },\n","        \"url_statistics\": {\n","            \"total_indexed\": len(urls_metadata),\n","            \"recent_urls\": len(recent_urls),\n","            \"outdated_urls\": len(old_urls),\n","            \"re_index_threshold_days\": config.RE_INDEX_DAYS\n","        },\n","        \"recent_urls\": recent_urls[:10],  # Show last 10 recent URLs\n","        \"outdated_urls\": old_urls[:5],    # Show first 5 outdated URLs\n","        \"backup_info\": {\n","            \"available_backups\": backup_versions,\n","            \"max_versions_kept\": config.MAX_VERSIONS\n","        },\n","        \"configuration\": {\n","            \"chunk_size\": config.CHUNK_SIZE,\n","            \"chunk_overlap\": config.CHUNK_OVERLAP,\n","            \"max_retries\": config.MAX_RETRIES,\n","            \"request_timeout\": config.REQUEST_TIMEOUT\n","        },\n","        \"timestamp\": datetime.now()\n","    }\n","\n","@app.delete(\"/api/v1/index/{url_hash}\")\n","async def remove_indexed_url(\n","    url_hash: str,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Remove a specific indexed URL from the dynamic database\"\"\"\n","    global dynamic_vectorstore, bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic\n","\n","    # Check permissions\n","    if \"index\" not in user_info.get(\"permissions\", []):\n","        raise HTTPException(\n","            status_code=status.HTTP_403_FORBIDDEN,\n","            detail=\"Insufficient permissions for index modification\"\n","        )\n","\n","    # Load URL metadata\n","    urls_metadata_file = os.path.join(config.METADATA_PATH, 'indexed_urls.json')\n","    urls_metadata = load_metadata(urls_metadata_file)\n","\n","    if url_hash not in urls_metadata:\n","        raise HTTPException(\n","            status_code=status.HTTP_404_NOT_FOUND,\n","            detail=\"URL hash not found in index\"\n","        )\n","\n","    try:\n","        # Create backup before modification\n","        create_version_backup()\n","\n","        # Find and remove documents with this URL hash\n","        if dynamic_vectorstore:\n","            # This is a complex operation - FAISS doesn't support direct deletion\n","            # We need to rebuild the index without the target documents\n","            remaining_docs = []\n","            removed_count = 0\n","\n","            for doc_id, doc in dynamic_vectorstore.docstore._dict.items():\n","                if doc.metadata.get(\"url_hash\") != url_hash:\n","                    remaining_docs.append(doc)\n","                else:\n","                    removed_count += 1\n","\n","            if remaining_docs:\n","                # Rebuild the vectorstore with remaining documents\n","                dynamic_vectorstore = FAISS.from_documents(remaining_docs, embedding_model)\n","                dynamic_vectorstore.save_local(config.DYNAMIC_FAISS_PATH)\n","\n","                # Rebuild BM25 and mappings\n","                bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic = build_bm25_from_vectorstore(dynamic_vectorstore)\n","            else:\n","                # No documents left, remove the vectorstore\n","                dynamic_vectorstore = None\n","                bm25_dynamic = None\n","                bm25_docs_dynamic = None\n","                bm25_sources_dynamic = None\n","                text_to_docs_dynamic = None\n","\n","                # Remove the directory\n","                if os.path.exists(config.DYNAMIC_FAISS_PATH):\n","                    shutil.rmtree(config.DYNAMIC_FAISS_PATH)\n","                    os.makedirs(config.DYNAMIC_FAISS_PATH)\n","\n","        # Remove from URL metadata\n","        url_info = urls_metadata.pop(url_hash)\n","        save_metadata(urls_metadata, urls_metadata_file)\n","\n","        # Update version\n","        new_version = update_version()\n","        cleanup_old_backups()\n","\n","        logger.info(f\"✅ Removed URL {url_info['url']} from index\")\n","\n","        return {\n","            \"status\": \"success\",\n","            \"removed_url\": url_info['url'],\n","            \"documents_removed\": removed_count,\n","            \"new_version\": new_version,\n","            \"timestamp\": datetime.now()\n","        }\n","\n","    except Exception as e:\n","        logger.error(f\"Error removing URL: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Failed to remove URL: {str(e)}\"\n","        )\n","\n","@app.post(\"/api/v1/index/reindex\")\n","async def reindex_all_urls(user_info: dict = Depends(verify_api_key)):\n","    \"\"\"Force reindex all URLs in the metadata\"\"\"\n","    # Check permissions\n","    if \"index\" not in user_info.get(\"permissions\", []):\n","        raise HTTPException(\n","            status_code=status.HTTP_403_FORBIDDEN,\n","            detail=\"Insufficient permissions for reindexing\"\n","        )\n","\n","    # Load URL metadata\n","    urls_metadata_file = os.path.join(config.METADATA_PATH, 'indexed_urls.json')\n","    urls_metadata = load_metadata(urls_metadata_file)\n","\n","    if not urls_metadata:\n","        raise HTTPException(\n","            status_code=status.HTTP_404_NOT_FOUND,\n","            detail=\"No URLs found to reindex\"\n","        )\n","\n","    # Extract URLs and create reindex request\n","    urls_to_reindex = [data['url'] for data in urls_metadata.values()]\n","\n","    # Clear existing metadata to force reindexing\n","    save_metadata({}, urls_metadata_file)\n","\n","    # Create index request\n","    reindex_request = IndexRequest(url=urls_to_reindex)\n","\n","    # Call the index endpoint\n","    return await index_urls(reindex_request, user_info)\n","\n","print(\"✅ API endpoints defined!\")\n","\n","# Start the server\n","def start_server():\n","    \"\"\"Start the FastAPI server with ngrok\"\"\"\n","    # Create ngrok tunnel\n","    public_url = ngrok.connect(8000)\n","\n","    print(f\"🌐 Public URL: {public_url}\")\n","    print(f\"📚 API Documentation: {public_url}/docs\")\n","    print(f\"🔑 API Key: demo-api-key-123\")\n","    print(\"\\n📋 Available Endpoints:\")\n","    print(f\"  • POST {public_url}/api/v1/index - Index new URLs\")\n","    print(f\"  • POST {public_url}/query - Query the RAG system\")\n","    print(f\"  • GET  {public_url}/api/v1/sources - List all sources\")\n","    print(f\"  • GET  {public_url}/api/v1/index/status - Get index status\")\n","    print(f\"  • DELETE {public_url}/api/v1/index/{{url_hash}} - Remove indexed URL\")\n","    print(f\"  • POST {public_url}/api/v1/index/reindex - Reindex all URLs\")\n","    print(f\"  • GET  {public_url}/health - Health check\")\n","    print(\"=\" * 50)\n","\n","    # Example curl commands\n","    print(\"💡 Example Usage:\")\n","    print(f\"\"\"\n","# Index a URL:\n","curl -X POST \"{public_url}/api/v1/index\" \\\\\n","  -H \"Authorization: Bearer demo-api-key-123\" \\\\\n","  -H \"Content-Type: application/json\" \\\\\n","  -d '{{\"url\": [\"https://example.com\"]}}'\n","\n","# Query the system:\n","curl -X POST \"{public_url}/query\" \\\\\n","  -H \"Authorization: Bearer demo-api-key-123\" \\\\\n","  -H \"Content-Type: application/json\" \\\\\n","  -d '{{\"question\": \"What is RAG?\", \"use_dynamic_index\": true}}'\n","\n","# Check index status:\n","curl -X GET \"{public_url}/api/v1/index/status\" \\\\\n","  -H \"Authorization: Bearer demo-api-key-123\"\n","    \"\"\")\n","    print(\"=\" * 50)\n","\n","    # Start the server\n","    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n","\n","# Run the server\n","start_server()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":29641,"status":"ok","timestamp":1755849998200,"user":{"displayName":"Balaji K","userId":"06165258946999670925"},"user_tz":-330},"id":"F-KBotpclweD"},"outputs":[],"source":["# ========================================\n","# STEP 1: SETUP AND IMPORTS\n","# ========================================\n","\n","!pip install -q fastapi uvicorn pyngrok nest-asyncio --quiet\n","!pip install -q rank-bm25 sentence-transformers langchain-community langchain-google-genai --quiet\n","!pip install -q faiss-cpu beautifulsoup4 requests pydantic --quiet\n","!pip install -q langchain scikit-learn pandas numpy  --quiet\n"]},{"cell_type":"markdown","metadata":{"id":"A-fmZsWvh9KH"},"source":["# Conversational RAG API with Dynamic Indexing and Sources"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e5080609b39e4ff9a3bd20bae2347126","e836a7beee85433ebdc2a896fe4b3ca4","2dbd8323f4c245199b5402bd81382bf4","52c2fa68b6c74b0f9a58df7b0f82e1fa","cba2d71af7aa41d390a9674a8612b188","b4ff940199924007bd8a77b58d8c1f03","dc98714e6cc14f0aa0680b551b93a660","4c5da1397c3d4d9496253482648f5cbb","eb32e6ae4f55415fa15e3637fe0bcbbe","9295985b250642fc85943e27784751f6","e3a113a5bacb417fb34a8683a2666e7e","d33668328ed34224ba372365b65edeb1","d37dc10cbb1c40d2bedb804b1b9ae645","eb535af16ce9493fa8dea754f5675599","3591d06ab5f1400096c1bbe48f9897a2","793bd6da3ced4cb0a06a57b2a91d8242","6be7eb99915643d7951ac281b1e8b365","9b22bff7015d47f0a7b77f5cbb72ee85","dfcdecb68cd44e8b8a950e47c5ca2ebc","8921f1754cbb442db29d19e6b6d2ce63","faf5cd0d577e42ad93ccff39042b5fcd","2921be2fe7044b5d8409a71be3160df6","536983a8c5a54b3cab3b233761245837","8a8ea87253db41bdb9312a337e509fd2","884552d755644bfd85cf290e370d76d7","eed22dfc29bf4db39f9518c2ae55ccfc","a414a478cde74942b2605a992a3599c0","a48dedb3078d493b920c6f79eda9cbbf","5c7683de9b574a4297819dc8b78cab58","6e83b005a5e544d6b6ca30134936365c","1ad8eab90bcf4406bdeadc042b9d07a6","66aab399efcc42939299802d3853cc7d","e8948019129240a68e803829cc3c9e17","d842eca30b1a4cf6a2ce2f1a68e01509","1e8145e3e8674ac1b3cead063169e5c7","43dbece4033c4149830ad329b33e0a01","7ab6025a96a947f4834bea2b925aa6ce","c3b8541027364377aef8f2534beec592","6b3ff548d2f0499e9b561ca570d976fe","8eb3447fac8e4702b4f780552403b4fd","8c21ab3aee934241ad3b571a3b572b65","2fb4b5e77ffa488aaa30a9fae6b9b6b7","83518cd2b0bf4f03af1892fcea6db259","b031d42457de4c1091896dc9ba762cff","0b4710e02340428faee8e13e3ad14d36","79b6c9b5be9e4b83a7109e64fd58b130","66ea787eb5dd4616b2091daf21faaa1d","d9e1368524e248e1b4b3332fe17ec0f5","707ee970053545eabe2d20b1b6eb6dc0","2c7792d4201a46d5ab3e9e1213ab771a","0452546088934d918fee58c18e53a42a","c8e585a2a1434c7e8976b9b3ce012cda","e81d69b433b44281b07f5732c687da9b","a52b4d648aa0471cb27fd2887e076ceb","33f473a00b5846629868aaa6867384aa","3e46abfbd1dd4b429f1720fb50f03624","ca13102344d745449327b2778f2c9994","0936b6f84d41438db2d59521616eb111","7426018c73f9462db4eb9d5da46c5ace","b8d6d3a359cc4430a1c7e27942cb1137","6877f43997bb461f97f10b04698f6d19","84f3743b67cc42f0bc8a547e1347f2c0","bc9a786f345d45299c4dd8e74e2a6dff","4e2efd46146d4e508efb760f7bc76d83","aaeb73fc742d43d6a53ec7be27cb6b38","5152966c0af346bf87c424c73ecae010","cdecca07237445a4b9025514cf462816","8c55b80693104542adddcb860f3e31f5","e1e98839e1cc420cbb7e1da4f4325c9b","a1c6b2c1d2c04f268ae969239786ec24","7dd52bc4e7954b95b5fc0263731cd42d","a27500cfbe454e83915ea07df22020df","9672e3df91df45b594039698a7b54408","c26af8c96463423e85fcfb17ce55c4a0","72c75a9a3c43463b80e678b05c620cf4","3c99f6e1e7f7465e86c34f57f076da76","96a2ce6a2ebb4eb480b3c4af60adec7d","027fe5448b3a494ebe0a475630dca320","2f6b28bfa35549d3aa384591cdb9d969","04e49d1bf12d474faed565246d33583e","689672ad7c074a90b4ec1f4986510234","e2f58570c43348918db67fe2ab1df318","d53624f68555420baf0f0d86fad0fb9f","4d0833bdd26e431f89c360555495a2bb","699aa604457344bd8b6a79f28e2b5cfe","11ecbf75d9c64211ac719abb0ed87090","b2a1877ed9b04b7fbf6b7b1216f86100","40fc3faa0db0495ba2524c9f32372ef0","49af321e62554bb3b01989d299382f8f","98df43a121794c0e9ce34472d41b52bc","2010886561dc4fe7812e563ae2fc7b50","0cf8e8eaa7be4829aa0bd7e047a35a7c","3c3477dc9dd1437b93aea8414d80af0d","d8b49c066ef345528c881dc9e2893a29","558f03fa306a4c0abb0c75769ab1ea2a","b2aae9b0454346edb5ca507beb395544","a41d710b4e88463197aa1ef8db14eb58","384d2a564d0f4f678c7311ff15bca1ea","d0e053c6aaf84fcd94114fc412c3c721","a4d6c32eb478484da7943a9211cd54bb","863a2b2420ef4933b6d548d319508f1d","8fb0e4d1599c44d9a252ada8bd2f087f","f80322ef0e36424bb991015eab3e09bf","c440012f520641c59bdd60e3af6c31a0","2f915cbee0ca4df1a522ec641e65557d","46af01b6418242f5bb69d365472f8bfe","8c2f18395a8f439c92e57594c6a75582","c7e97b82002940a28f319acef93ca029","115f1eec2d2645a1832771e4a9bb5f05","577b9161067349e9a3d52add550e4905","316628db0e4b4c1cb42b64e1b882698a","aa7b107841c14c71af37d671c0e47c92","c75a24b86ce64a11be23d0c810c73721","b6f78813effa4bf08292dd09270ba2c6","df4cec9c4f344f1ea4135f11a00b015c","4f6e223b00d14f348d4d7c5bcc310464","3baf3ee1d9e0441ba59ce2ba4a35c5d9","280a1fc2709242998c178f7e39303bdf","adea9ec407114e01b11333339dabb183","23159f16cf53407c99851b9147b41a7b","810f3cc2d32645bc827f48cbc9261a2f","49c4d6c7ac59449f8a281a4e556b3599","b03837f2824e413d8628c5c880c65ff1","390ee2d551f44ec1afe3245eedef5605","30803759b88f45cd89e972a8c65438a0","973939450a604b11814657aa6b87896b","91221915f629449aaddcd6e0737bf7a1","21e8dd6c0c63417da3d3922b8f22ca62","c707bfc96cc144ef84bb9e44f549f355","c657f06cd0f24ac8b616c476ce2835de","f5f877f3212747a48419ee3768e59732","e2c11c24b1d54e8d899883a4f7341d25","01698688b9564a2cad47d46ec33f9818","71df578ded3943d8a1b6e01003f74de8","9fb63ba1021f4ed3b941bbc2a4644965","b8f217dceacc4bf1a573a148638635fc","9562360ae28c47179f0d4805a1e55010","08d7bebe9e244980814346a045634234","998530fbc77b4d43aafa36f60172ae9a","6d40490dbc9f431b8ddad5f6855dd2b3","805a997cfcdd4d01be01af1bf6ca6499","6fd8ff8e93844f5b88f8372ffdbb4774","e3912d2e5d944dba8dd26e3fe82a299d","cc9aca68aae940a6ad9d9adc692e46bc","0a87956263fe4e3bad8a562ec9b80ff6","39338c83bc07410e9f764ad2a440bd5b","a108d5ed7400424da90debebe2161f7a","e01cb4ef7a004b13a4b45df0004f4e33","8105af9e0a94459cb5cc9420d608d3cc","72acddf30c004fbfa8716fedae8ca43a","cebd7689b672469bb7332577d735524f","bc34b52c5c3241d0a35081092c485366","ac0246572ab04cae954c2eb5801e664b","bf70eccc23ba4269b7d2d13901e15c61","40359639360a43b197556edd41110188","7363a0ba63cd40d384504a1af5b3253c","7dd8bcfc14474fd6a7874fc8c40d04f1","404c49b2c1084722b2bb407fb7d678d4","07729278440a47c8b050a79bb2859360","d31a2821d0a34a8589ea745575f2e782","4b23eb0af8024fb9aaab03d1f1152ecd","51f51033869747b9bd0adbf970fc2a30","c490e3bb81dc49cb9a6d3c7ab8e82fd1","c40852fb47d049ce82d846c4489173df","c6af4323688844b58cf7c9336708248a","29389ce93a1e4550bc02ad07e0a81a95","aef1a9a1446b476e95a7ddd4e390a564","a6dcc38f48174a4796fe67729c51b6c9","ae479e805f8448fd871f2299abf7383c","4f697e3a2aaf49b2a102ba74e420bf5a","385897c94028481d80b9e4a3a2fc704b","8f8d5becbc1d43e89793be1317433e86","143fbe895b3c417ca789d4f6e7274645","f101adcd262d452d886c722ed6e9b489","68dca70ac9734cc88a61740eddcbe371","37c6dfb7671b47b191e688cf0bbda54d","6d5f687cb3e54f3b8eb533a0a10988f9","193103746d2c4bf19438105fd9d5cbb8","1998fc7ee068466c90d8c840bf98e315","d2ac96714e604d76b99cffd0a29d77c0","df104bcae27e414ebc33acd6628b56b8","8a2ecd187cd44a809dc2975d2177bac2","92b40202a42e4bdf8e0722f6f8db8184","536ee2f14c7b473b873fc4c2b45f194f","92ec5337b5fa4f0587cf96ddb627c2d7","8986eb158cf44ab98697c440b2b4d971","d979d8baa7be40f282a565b6bca45bab","610cfc723c974ee5832454bee61d4e61","3169a440a7ea43818eecb37ad779d3aa","53a9cc27dd47418eac0420d435f4a2e7","927fac3c4231465f8fcafc4b9b4331bb","d9f55e3fec374c7bb16b46334d7a1534","ec878925cd814566abcd4a590e146c70","f5a55ad7d68b4540803c193309c8679b","3b51c6c1d1a041a38334cd8e95d89d11","d58e49da203349ef849295556bed7a04","6f8a83028cea4967a7213b4d4e02b883","9aefa4d856764e3194dfe13f753dccce"]},"id":"qIZPNVupD2AG","executionInfo":{"status":"ok","timestamp":1755850122429,"user_tz":-330,"elapsed":84441,"user":{"displayName":"Balaji K","userId":"06165258946999670925"}},"outputId":"522298b8-6b64-4ba2-d1f2-2acdee53c907"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ All imports successful!\n","Enter your Google API key: ··········\n","Enter your ngrok token (get free at https://dashboard.ngrok.com/get-started/your-authtoken): ··········\n","✅ Configuration loaded!\n","✅ Pydantic models defined!\n","✅ Utility functions defined!\n","✅ Conversation manager initialized!\n","✅ Web scraping and indexing functions defined!\n","✅ Hybrid search system defined!\n","✅ Evaluation system initialized!\n","✅ API endpoints defined!\n","🔄 Initializing models and components...\n","🔄 Loading models...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-269029941.py:133: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n","  @validator('url')\n","/tmp/ipython-input-269029941.py:794: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n","  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5080609b39e4ff9a3bd20bae2347126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d33668328ed34224ba372365b65edeb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"536983a8c5a54b3cab3b233761245837"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d842eca30b1a4cf6a2ce2f1a68e01509"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b4710e02340428faee8e13e3ad14d36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e46abfbd1dd4b429f1720fb50f03624"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdecca07237445a4b9025514cf462816"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"027fe5448b3a494ebe0a475630dca320"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49af321e62554bb3b01989d299382f8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4d6c32eb478484da7943a9211cd54bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"316628db0e4b4c1cb42b64e1b882698a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Embedding model loaded\n","✅ Text splitter initialized\n","✅ Static FAISS vectorstore loaded\n","✅ Dynamic FAISS vectorstore loaded\n","✅ LLM initialized\n","✅ Chat prompt template created\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49c4d6c7ac59449f8a281a4e556b3599"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01698688b9564a2cad47d46ec33f9818"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc9aca68aae940a6ad9d9adc692e46bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40359639360a43b197556edd41110188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29389ce93a1e4550bc02ad07e0a81a95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d5f687cb3e54f3b8eb533a0a10988f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"610cfc723c974ee5832454bee61d4e61"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ Reranker loaded\n","🎉 All models initialized successfully!\n","\n","📝 Creating demo test cases...\n","✅ Demo test cases created!\n","📁 Location: /content/drive/MyDrive/RAG_demo/evaluation/demo_test_cases.json\n","\n","🚀 Starting the conversational RAG system...\n","⏳ This will open ngrok tunnel and start the FastAPI server...\n","============================================================\n","🚀 CONVERSATIONAL RAG SYSTEM WITH SOURCES API LAUNCHED!\n","============================================================\n","🌐 Public URL: NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"\n","📚 API Documentation: NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/docs\n","🔑 API Keys:\n","   • demo-api-key-123 (full access)\n","   • eval-key-456 (evaluation access)\n","\n","🎯 MAIN ENDPOINTS:\n","  • POST NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/chat - Chat with the system\n","  • POST NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/index - Index new URLs\n","  • GET  NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/sources - List all sources\n","  • GET  NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/sources/{hash} - Get source details\n","  • POST NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/evaluate - Run automated evaluation\n","  • GET  NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/conversations - List conversations\n","  • GET  NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/health - Health check\n","\n","💡 EXAMPLE USAGE:\n","\n","# Start a conversation:\n","curl -X POST \"NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/chat\" \\\n","  -H \"Authorization: Bearer demo-api-key-123\" \\\n","  -H \"Content-Type: application/json\" \\\n","  -d '{\n","    \"messages\": [\n","      {\"role\": \"user\", \"content\": \"What is attention mechanism?\"}\n","    ]\n","  }'\n","\n","# Get all sources:\n","curl -X GET \"NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/sources\" \\\n","  -H \"Authorization: Bearer demo-api-key-123\"\n","\n","# Index new content:\n","curl -X POST \"NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/index\" \\\n","  -H \"Authorization: Bearer demo-api-key-123\" \\\n","  -H \"Content-Type: application/json\" \\\n","  -d '{\"url\": [\"https://example.com/ai-article\"]}'\n","\n","# Run evaluation:\n","curl -X POST \"NgrokTunnel: \"https://4aabf66b0c35.ngrok-free.app\" -> \"http://localhost:8000\"/api/v1/evaluate\" \\\n","  -H \"Authorization: Bearer eval-key-456\" \\\n","  -H \"Content-Type: application/json\" \\\n","  -d '{\"test_cases\": []}'\n","    \n","============================================================\n","🔥 Your conversational RAG system with sources API is ready!\n","✨ New Features: Complete source management and tracking\n","🎓 Perfect for your final data science project!\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Started server process [592]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n","INFO:     Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:     Finished server process [592]\n"]}],"source":["# Setup imports and basic configuration\n","import os\n","import json\n","import time\n","import shutil\n","from datetime import datetime, timedelta\n","from typing import List, Optional, Dict, Any, Union\n","from urllib.parse import urlparse, urljoin\n","import requests\n","from bs4 import BeautifulSoup\n","import nest_asyncio\n","from pyngrok import ngrok\n","import uvicorn\n","from fastapi import FastAPI, HTTPException, Depends, status, Body\n","from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n","from fastapi.middleware.cors import CORSMiddleware\n","from pydantic import BaseModel, Field, validator\n","import logging\n","from getpass import getpass\n","from collections import OrderedDict\n","import hashlib\n","import re\n","import uuid\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","import asyncio\n","from threading import Thread\n","\n","# Import the RAG components\n","from rank_bm25 import BM25Okapi\n","from sentence_transformers import CrossEncoder\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_community.vectorstores import FAISS\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain.prompts import PromptTemplate\n","from langchain.docstore.document import Document\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# Enable asyncio in Colab\n","nest_asyncio.apply()\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","print(\"✅ All imports successful!\")\n","\n","# ========================================\n","# STEP 2: CONFIGURATION AND API KEYS\n","# ========================================\n","\n","# Set up API keys\n","if \"GOOGLE_API_KEY\" not in os.environ:\n","    os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google API key: \")\n","\n","# Set ngrok token\n","ngrok_token = getpass(\"Enter your ngrok token (get free at https://dashboard.ngrok.com/get-started/your-authtoken): \")\n","ngrok.set_auth_token(ngrok_token)\n","\n","# Configuration\n","class Config:\n","    # Static index (existing)\n","    STATIC_FAISS_PATH = \"/content/drive/MyDrive/RAG_demo/faiss_index\"\n","\n","    # Dynamic index (new)\n","    DYNAMIC_BASE_PATH = \"/content/drive/MyDrive/RAG_demo/dynamic_index\"\n","    DYNAMIC_FAISS_PATH = \"/content/drive/MyDrive/RAG_demo/dynamic_index/faiss_index\"\n","    METADATA_PATH = \"/content/drive/MyDrive/RAG_demo/dynamic_index/metadata\"\n","    BACKUP_PATH = \"/content/drive/MyDrive/RAG_demo/dynamic_index/backups\"\n","\n","    # Conversation settings\n","    CONVERSATIONS_PATH = \"/content/drive/MyDrive/RAG_demo/conversations\"\n","    MAX_CONVERSATION_LENGTH = 10  # Maximum number of message pairs\n","    CONVERSATION_TIMEOUT = 1800   # 30 minutes in seconds\n","    MAX_CONTEXT_LENGTH = 3        # Last N message pairs to include in context\n","\n","    # Indexing settings\n","    USE_RERANKER = True\n","    RERANKER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n","    BM25_TOP_K = 10\n","    FAISS_TOP_K = 10\n","    FINAL_TOP_K = 3\n","\n","    # Web scraping settings\n","    REQUEST_TIMEOUT = 30\n","    MAX_RETRIES = 3\n","    RETRY_DELAY = 2\n","    CHUNK_SIZE = 1000\n","    CHUNK_OVERLAP = 100\n","    RE_INDEX_DAYS = 7\n","    MAX_VERSIONS = 3\n","\n","    # Evaluation settings\n","    EVALUATION_DATASET_PATH = \"/content/drive/MyDrive/RAG_demo/evaluation\"\n","\n","    # Authentication\n","    VALID_API_KEYS = {\n","        \"demo-api-key-123\": {\"user\": \"demo_user\", \"permissions\": [\"read\", \"query\", \"index\", \"chat\"]},\n","        \"eval-key-456\": {\"user\": \"evaluator\", \"permissions\": [\"read\", \"query\", \"chat\", \"eval\"]},\n","    }\n","\n","config = Config()\n","print(\"✅ Configuration loaded!\")\n","\n","# ========================================\n","# STEP 3: PYDANTIC MODELS\n","# ========================================\n","\n","# Chat-specific models\n","class ChatMessage(BaseModel):\n","    role: str = Field(..., pattern=\"^(user|assistant)$\")\n","    content: str = Field(..., min_length=1, max_length=2000)\n","    timestamp: Optional[datetime] = Field(default_factory=datetime.now)\n","\n","class ChatRequest(BaseModel):\n","    messages: List[ChatMessage] = Field(..., min_items=1, max_items=20)\n","    session_id: Optional[str] = Field(default=None)\n","    use_dynamic_index: Optional[bool] = Field(default=True)\n","    use_reranker: Optional[bool] = Field(default=True)\n","    top_k: Optional[int] = Field(default=3, ge=1, le=5)\n","\n","class ChatResponse(BaseModel):\n","    session_id: str\n","    response: Dict[str, Any]\n","    conversation_length: int\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","\n","# Original models (updated)\n","class IndexRequest(BaseModel):\n","    url: List[str] = Field(..., min_items=1, max_items=5, description=\"URLs to index\")\n","\n","    @validator('url')\n","    def validate_urls(cls, v):\n","        for url in v:\n","            parsed = urlparse(url)\n","            if not parsed.scheme or not parsed.netloc:\n","                raise ValueError(f\"Invalid URL format: {url}\")\n","        return v\n","\n","class IndexResponse(BaseModel):\n","    status: str\n","    indexed_url: List[str]\n","    failed_url: Optional[List[Dict[str, str]]] = None\n","    metadata: Dict[str, Any] = Field(default_factory=dict)\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","\n","class HealthResponse(BaseModel):\n","    status: str\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","    components: dict\n","    conversations_active: int\n","\n","# NEW: Sources models\n","class SourceInfo(BaseModel):\n","    source_url: str\n","    title: Optional[str] = None\n","    indexed_at: Optional[datetime] = None\n","    document_count: int = 0\n","    source_type: str = Field(..., description=\"static or dynamic\")\n","    last_updated: Optional[datetime] = None\n","\n","class SourcesResponse(BaseModel):\n","    total_sources: int\n","    static_sources: List[SourceInfo]\n","    dynamic_sources: List[SourceInfo]\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","\n","# Evaluation models\n","class EvaluationRequest(BaseModel):\n","    test_cases: List[Dict[str, Any]]\n","    session_id: Optional[str] = None\n","\n","class EvaluationResponse(BaseModel):\n","    overall_score: float\n","    detailed_results: List[Dict[str, Any]]\n","    metrics: Dict[str, float]\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","\n","print(\"✅ Pydantic models defined!\")\n","\n","# ========================================\n","# STEP 4: GLOBAL VARIABLES AND UTILITIES\n","# ========================================\n","\n","# Global variables\n","embedding_model = None\n","static_vectorstore = None\n","dynamic_vectorstore = None\n","llm = None\n","bm25_static = None\n","bm25_dynamic = None\n","bm25_docs_static = None\n","bm25_docs_dynamic = None\n","bm25_sources_static = None\n","bm25_sources_dynamic = None\n","reranker = None\n","text_to_docs_static = None\n","text_to_docs_dynamic = None\n","chat_prompt = None\n","text_splitter = None\n","\n","# In-memory conversation storage\n","active_conversations = {}\n","\n","# Source URL mapping for static content\n","source_url_map = {\n","    \"/content/drive/MyDrive/RAG_demo/data/genai-platform.txt\": \"https://huyenchip.com/2024/07/25/genai-platform.html\",\n","    \"/content/drive/MyDrive/RAG_demo/data/hallucination.txt\": \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n","    \"/content/drive/MyDrive/RAG_demo/data/quora_engineering.txt\": \"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\"\n","}\n","\n","# Utility functions\n","def ensure_directories():\n","    \"\"\"Ensure all required directories exist\"\"\"\n","    directories = [\n","        config.DYNAMIC_BASE_PATH,\n","        config.DYNAMIC_FAISS_PATH,\n","        config.METADATA_PATH,\n","        config.BACKUP_PATH,\n","        config.CONVERSATIONS_PATH,\n","        config.EVALUATION_DATASET_PATH\n","    ]\n","    for directory in directories:\n","        os.makedirs(directory, exist_ok=True)\n","    logger.info(\"✅ Directory structure created\")\n","\n","def get_url_hash(url: str) -> str:\n","    \"\"\"Generate a hash for URL to use as unique identifier\"\"\"\n","    return hashlib.md5(url.encode()).hexdigest()\n","\n","def load_metadata(file_path: str) -> Dict:\n","    \"\"\"Load metadata from JSON file\"\"\"\n","    if os.path.exists(file_path):\n","        try:\n","            with open(file_path, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        except Exception as e:\n","            logger.error(f\"Error loading metadata from {file_path}: {str(e)}\")\n","    return {}\n","\n","def save_metadata(data: Dict, file_path: str):\n","    \"\"\"Save metadata to JSON file\"\"\"\n","    try:\n","        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n","        with open(file_path, 'w', encoding='utf-8') as f:\n","            json.dump(data, f, indent=2, default=str)\n","    except Exception as e:\n","        logger.error(f\"Error saving metadata to {file_path}: {str(e)}\")\n","        raise\n","\n","def format_sources(sources):\n","    \"\"\"Convert file paths to URLs\"\"\"\n","    formatted = []\n","    for source in sources:\n","        if source.startswith('http'):\n","            formatted.append(source)\n","        else:\n","            formatted.append(source_url_map.get(source, source))\n","    return formatted\n","\n","def generate_session_id() -> str:\n","    \"\"\"Generate a unique session ID\"\"\"\n","    return str(uuid.uuid4())\n","\n","def clean_old_conversations():\n","    \"\"\"Remove old conversations from memory\"\"\"\n","    current_time = datetime.now()\n","    expired_sessions = []\n","\n","    for session_id, conv_data in active_conversations.items():\n","        last_active = conv_data.get('last_active', current_time)\n","        if isinstance(last_active, str):\n","            last_active = datetime.fromisoformat(last_active)\n","\n","        if (current_time - last_active).seconds > config.CONVERSATION_TIMEOUT:\n","            expired_sessions.append(session_id)\n","\n","    for session_id in expired_sessions:\n","        del active_conversations[session_id]\n","        logger.info(f\"Cleaned expired conversation: {session_id}\")\n","\n","print(\"✅ Utility functions defined!\")\n","\n","# ========================================\n","# STEP 5: CONVERSATION MANAGEMENT\n","# ========================================\n","\n","class ConversationManager:\n","    def __init__(self):\n","        self.conversations = active_conversations\n","\n","    def get_or_create_session(self, session_id: Optional[str] = None) -> str:\n","        \"\"\"Get existing session or create new one\"\"\"\n","        if session_id and session_id in self.conversations:\n","            # Update last active time\n","            self.conversations[session_id]['last_active'] = datetime.now()\n","            return session_id\n","\n","        # Create new session\n","        new_session_id = generate_session_id()\n","        self.conversations[new_session_id] = {\n","            'messages': [],\n","            'created_at': datetime.now(),\n","            'last_active': datetime.now(),\n","            'metadata': {}\n","        }\n","        logger.info(f\"Created new conversation session: {new_session_id}\")\n","        return new_session_id\n","\n","    def add_message(self, session_id: str, message: ChatMessage):\n","        \"\"\"Add message to conversation\"\"\"\n","        if session_id not in self.conversations:\n","            raise ValueError(f\"Session {session_id} not found\")\n","\n","        self.conversations[session_id]['messages'].append({\n","            'role': message.role,\n","            'content': message.content,\n","            'timestamp': message.timestamp.isoformat() if message.timestamp else datetime.now().isoformat()\n","        })\n","        self.conversations[session_id]['last_active'] = datetime.now()\n","\n","        # Trim conversation if too long\n","        messages = self.conversations[session_id]['messages']\n","        if len(messages) > config.MAX_CONVERSATION_LENGTH * 2:  # *2 for user+assistant pairs\n","            self.conversations[session_id]['messages'] = messages[-config.MAX_CONVERSATION_LENGTH * 2:]\n","\n","    def get_conversation_context(self, session_id: str, max_pairs: int = None) -> str:\n","        \"\"\"Get conversation context for LLM\"\"\"\n","        if session_id not in self.conversations:\n","            return \"\"\n","\n","        messages = self.conversations[session_id]['messages']\n","        if not messages:\n","            return \"\"\n","\n","        # Get last N pairs (user + assistant messages)\n","        max_pairs = max_pairs or config.MAX_CONTEXT_LENGTH\n","        recent_messages = messages[-(max_pairs * 2):]\n","\n","        context_parts = []\n","        for msg in recent_messages:\n","            role = \"Human\" if msg['role'] == 'user' else \"Assistant\"\n","            context_parts.append(f\"{role}: {msg['content']}\")\n","\n","        return \"\\n\".join(context_parts)\n","\n","    def get_conversation_length(self, session_id: str) -> int:\n","        \"\"\"Get number of message exchanges\"\"\"\n","        if session_id not in self.conversations:\n","            return 0\n","        return len(self.conversations[session_id]['messages'])\n","\n","    def save_conversation(self, session_id: str):\n","        \"\"\"Save conversation to disk\"\"\"\n","        if session_id not in self.conversations:\n","            return\n","\n","        conv_file = os.path.join(config.CONVERSATIONS_PATH, f\"{session_id}.json\")\n","        save_metadata(self.conversations[session_id], conv_file)\n","\n","conversation_manager = ConversationManager()\n","print(\"✅ Conversation manager initialized!\")\n","\n","# ========================================\n","# STEP 6: WEB SCRAPING AND INDEXING\n","# ========================================\n","\n","class WebScraper:\n","    def __init__(self):\n","        self.session = requests.Session()\n","        self.session.headers.update({\n","            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n","        })\n","\n","    def extract_content(self, url: str) -> Dict[str, Any]:\n","        \"\"\"Extract content from URL with retry logic\"\"\"\n","        for attempt in range(config.MAX_RETRIES):\n","            try:\n","                response = self.session.get(url, timeout=config.REQUEST_TIMEOUT)\n","                response.raise_for_status()\n","\n","                soup = BeautifulSoup(response.content, 'html.parser')\n","\n","                # Remove unwanted elements\n","                for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'advertisement']):\n","                    element.decompose()\n","\n","                # Extract title\n","                title = soup.find('title')\n","                title_text = title.get_text().strip() if title else url\n","\n","                # Extract main content\n","                content_selectors = [\n","                    'article', 'main', '[role=\"main\"]',\n","                    '.content', '.post', '.article',\n","                    'div.container', 'div.wrapper'\n","                ]\n","\n","                content_text = \"\"\n","                for selector in content_selectors:\n","                    content = soup.select_one(selector)\n","                    if content:\n","                        content_text = content.get_text()\n","                        break\n","\n","                if not content_text:\n","                    # Fallback to body\n","                    body = soup.find('body')\n","                    content_text = body.get_text() if body else \"\"\n","\n","                # Clean text\n","                content_text = re.sub(r'\\s+', ' ', content_text).strip()\n","\n","                if not content_text:\n","                    raise ValueError(\"No content extracted\")\n","\n","                return {\n","                    'title': title_text,\n","                    'content': content_text,\n","                    'url': url,\n","                    'success': True,\n","                    'error': None\n","                }\n","\n","            except Exception as e:\n","                logger.warning(f\"Attempt {attempt + 1} failed for {url}: {str(e)}\")\n","                if attempt < config.MAX_RETRIES - 1:\n","                    time.sleep(config.RETRY_DELAY * (2 ** attempt))\n","                else:\n","                    return {\n","                        'title': None,\n","                        'content': None,\n","                        'url': url,\n","                        'success': False,\n","                        'error': str(e)\n","                    }\n","\n","def build_bm25_from_vectorstore(vectorstore):\n","    \"\"\"Build BM25 index from FAISS vectorstore\"\"\"\n","    try:\n","        docs = []\n","        sources = []\n","        for doc_id, doc in vectorstore.docstore._dict.items():\n","            text = getattr(doc, \"page_content\", None) or doc.page_content\n","            docs.append(text)\n","            sources.append(doc.metadata.get(\"source\", \"Unknown\"))\n","\n","        tokenized = [d.split() for d in docs]\n","        bm25 = BM25Okapi(tokenized)\n","\n","        # Build text to docs mapping\n","        text_to_docs = {}\n","        for doc in vectorstore.docstore._dict.values():\n","            text = doc.page_content\n","            text_to_docs.setdefault(text, []).append(doc)\n","\n","        logger.info(f\"BM25 built over {len(docs)} chunks\")\n","        return bm25, docs, sources, text_to_docs\n","    except Exception as e:\n","        logger.error(f\"Error building BM25: {str(e)}\")\n","        raise\n","\n","print(\"✅ Web scraping and indexing functions defined!\")\n","\n","# ========================================\n","# STEP 7: HYBRID SEARCH SYSTEM\n","# ========================================\n","\n","def hybrid_search(query: str, use_dynamic: bool = True, bm_k: int = 10, faiss_k: int = 10, top_k: int = 3, use_reranker: bool = True, conversation_context: str = \"\"):\n","    \"\"\"Perform hybrid search on static and/or dynamic indices with conversation context\"\"\"\n","    try:\n","        # Enhanced query with context\n","        enhanced_query = query\n","        if conversation_context:\n","            # Add context to help with pronouns and references\n","            enhanced_query = f\"Context: {conversation_context}\\n\\nCurrent question: {query}\"\n","\n","        all_candidates = []\n","\n","        # Search static index\n","        if static_vectorstore:\n","            candidates_static = _search_single_index(\n","                enhanced_query, static_vectorstore, bm25_static, bm25_docs_static,\n","                bm25_sources_static, text_to_docs_static, bm_k, faiss_k\n","            )\n","            all_candidates.extend(candidates_static)\n","\n","        # Search dynamic index\n","        if use_dynamic and dynamic_vectorstore:\n","            candidates_dynamic = _search_single_index(\n","                enhanced_query, dynamic_vectorstore, bm25_dynamic, bm25_docs_dynamic,\n","                bm25_sources_dynamic, text_to_docs_dynamic, bm_k, faiss_k\n","            )\n","            all_candidates.extend(candidates_dynamic)\n","\n","        if not all_candidates:\n","            return []\n","\n","        # Merge and deduplicate candidates\n","        merged = OrderedDict()\n","        for candidate in all_candidates:\n","            key = candidate[\"text\"].strip()[:100]  # Use first 100 chars as key\n","            if key not in merged or (candidate.get(\"bm25_score\") or 0) > (merged[key].get(\"bm25_score\") or 0):\n","                merged[key] = candidate\n","\n","        candidates = list(merged.values())\n","\n","        # Optional reranking - use original query for reranking\n","        if use_reranker and reranker and candidates:\n","            pairs = [(query, c[\"text\"]) for c in candidates]  # Use original query for reranking\n","            scores = reranker.predict(pairs)\n","            for c, s in zip(candidates, scores):\n","                c[\"rerank_score\"] = float(s)\n","            candidates = sorted(candidates, key=lambda x: x[\"rerank_score\"], reverse=True)\n","        else:\n","            candidates = sorted(candidates, key=lambda x: (0 if x[\"bm25_score\"] is not None else 1, -(x[\"bm25_score\"] or 0)))\n","\n","        # Return top_k Document objects\n","        final_docs = []\n","        for c in candidates[:top_k]:\n","            text = c[\"text\"]\n","            # Try to find in both mappings\n","            docs_list = text_to_docs_static.get(text, []) if text_to_docs_static else []\n","            if not docs_list and text_to_docs_dynamic:\n","                docs_list = text_to_docs_dynamic.get(text, [])\n","\n","            if docs_list:\n","                final_docs.append(docs_list[0])\n","            else:\n","                final_docs.append(Document(page_content=text, metadata={\"source\": c.get(\"source\", \"Unknown\")}))\n","\n","        return final_docs\n","\n","    except Exception as e:\n","        logger.error(f\"Error in hybrid search: {str(e)}\")\n","        raise\n","\n","def _search_single_index(query: str, vectorstore, bm25, bm25_docs, bm25_sources, text_to_docs, bm_k: int, faiss_k: int):\n","    \"\"\"Search a single index (static or dynamic)\"\"\"\n","    candidates = []\n","\n","    # BM25 candidates\n","    if bm25 and bm25_docs:\n","        tokenized_q = query.split()\n","        bm25_scores = bm25.get_scores(tokenized_q)\n","        bm25_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:bm_k]\n","        for idx in bm25_indices:\n","            txt = bm25_docs[idx]\n","            src = bm25_sources[idx]\n","            candidates.append({\"text\": txt, \"source\": src, \"bm25_score\": bm25_scores[idx]})\n","\n","    # FAISS candidates\n","    if vectorstore:\n","        faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": faiss_k})\n","        faiss_docs = faiss_retriever.get_relevant_documents(query)\n","        for d in faiss_docs:\n","            candidates.append({\"text\": d.page_content, \"source\": d.metadata.get(\"source\", \"Unknown\"), \"bm25_score\": None})\n","\n","    return candidates\n","\n","print(\"✅ Hybrid search system defined!\")\n","\n","# ========================================\n","# STEP 8: EVALUATION SYSTEM\n","# ========================================\n","\n","class RAGEvaluator:\n","    def __init__(self):\n","        self.test_cases = []\n","        self.results = []\n","\n","    def create_test_dataset(self):\n","        \"\"\"Create evaluation test cases\"\"\"\n","        test_cases = [\n","            # Context retention tests\n","            {\n","                \"conversation\": [\n","                    {\"role\": \"user\", \"content\": \"What is attention mechanism in transformers?\"},\n","                    {\"role\": \"user\", \"content\": \"How does it help with long sequences?\"}\n","                ],\n","                \"expected_context\": \"attention mechanism\",\n","                \"test_type\": \"context_retention\"\n","            },\n","\n","            # Citation accuracy tests\n","            {\n","                \"conversation\": [\n","                    {\"role\": \"user\", \"content\": \"Tell me about RAG systems\"}\n","                ],\n","                \"expected_citations\": True,\n","                \"test_type\": \"citation_accuracy\"\n","            },\n","\n","            # Topic switching tests\n","            {\n","                \"conversation\": [\n","                    {\"role\": \"user\", \"content\": \"Explain neural networks\"},\n","                    {\"role\": \"user\", \"content\": \"Now tell me about cooking recipes\"}\n","                ],\n","                \"expected_behavior\": \"topic_switch\",\n","                \"test_type\": \"topic_switching\"\n","            },\n","\n","            # Multi-source tests\n","            {\n","                \"conversation\": [\n","                    {\"role\": \"user\", \"content\": \"What are the latest trends in AI?\"}\n","                ],\n","                \"expected_sources\": \"mixed\",\n","                \"test_type\": \"multi_source\"\n","            }\n","        ]\n","\n","        # Save test cases\n","        test_file = os.path.join(config.EVALUATION_DATASET_PATH, \"test_cases.json\")\n","        save_metadata(test_cases, test_file)\n","        return test_cases\n","\n","    def evaluate_response_relevance(self, question: str, answer: str, context_docs: List[Document]) -> float:\n","        \"\"\"Evaluate how relevant the answer is to the question\"\"\"\n","        try:\n","            # Simple keyword overlap score\n","            question_words = set(question.lower().split())\n","            answer_words = set(answer.lower().split())\n","\n","            overlap = len(question_words.intersection(answer_words))\n","            relevance_score = overlap / len(question_words) if question_words else 0.0\n","\n","            # Bonus for using context\n","            context_text = \" \".join([doc.page_content for doc in context_docs])\n","            context_words = set(context_text.lower().split())\n","            context_usage = len(answer_words.intersection(context_words)) / len(context_words) if context_words else 0.0\n","\n","            final_score = min(1.0, (relevance_score + context_usage) / 2)\n","            return final_score\n","\n","        except Exception as e:\n","            logger.error(f\"Error evaluating relevance: {str(e)}\")\n","            return 0.0\n","\n","    def evaluate_citation_accuracy(self, answer: str, sources: List[str]) -> float:\n","        \"\"\"Evaluate citation accuracy\"\"\"\n","        if not sources:\n","            return 0.0\n","\n","        # Check if answer contains factual claims (simple heuristic)\n","        factual_indicators = [\"according to\", \"research shows\", \"studies indicate\", \"data reveals\", \"analysis found\"]\n","        has_factual_claims = any(indicator in answer.lower() for indicator in factual_indicators)\n","\n","        if has_factual_claims and sources:\n","            return 1.0\n","        elif not has_factual_claims:\n","            return 0.8  # No factual claims, so no citations needed\n","        else:\n","            return 0.0  # Factual claims but no citations\n","\n","    def evaluate_context_retention(self, conversation_history: List[Dict], current_answer: str) -> float:\n","        \"\"\"Evaluate how well context from previous messages is retained\"\"\"\n","        if len(conversation_history) <= 1:\n","            return 1.0  # No previous context to retain\n","\n","        # Look for references to previous topics\n","        previous_content = \" \".join([msg[\"content\"] for msg in conversation_history[:-1]])\n","        previous_words = set(previous_content.lower().split())\n","        answer_words = set(current_answer.lower().split())\n","\n","        # Check for pronouns and references\n","        references = [\"this\", \"that\", \"it\", \"they\", \"these\", \"those\"]\n","        has_references = any(ref in current_answer.lower() for ref in references)\n","\n","        # Calculate context retention score\n","        word_overlap = len(previous_words.intersection(answer_words)) / len(previous_words) if previous_words else 0.0\n","        reference_bonus = 0.3 if has_references else 0.0\n","\n","        context_score = min(1.0, word_overlap + reference_bonus)\n","        return context_score\n","\n","    async def run_evaluation(self, test_cases: List[Dict]) -> Dict[str, Any]:\n","        \"\"\"Run comprehensive evaluation\"\"\"\n","        results = []\n","        total_scores = {\"relevance\": [], \"citation\": [], \"context\": []}\n","\n","        for i, test_case in enumerate(test_cases):\n","            try:\n","                logger.info(f\"Running test case {i+1}/{len(test_cases)}\")\n","\n","                # Simulate conversation\n","                session_id = generate_session_id()\n","                conversation_history = []\n","\n","                for message in test_case[\"conversation\"]:\n","                    # Add user message\n","                    user_msg = ChatMessage(role=\"user\", content=message[\"content\"])\n","                    conversation_manager.add_message(session_id, user_msg)\n","                    conversation_history.append({\"role\": \"user\", \"content\": message[\"content\"]})\n","\n","                    # Get bot response\n","                    context = conversation_manager.get_conversation_context(session_id)\n","                    docs = hybrid_search(\n","                        message[\"content\"],\n","                        use_dynamic=True,\n","                        conversation_context=context\n","                    )\n","\n","                    if docs:\n","                        doc_context = \"\\n\\n\".join([doc.page_content for doc in docs])\n","                        formatted_prompt = chat_prompt.format(\n","                            conversation_context=context,\n","                            context=doc_context,\n","                            question=message[\"content\"]\n","                        )\n","                        response = llm.invoke(formatted_prompt)\n","                        answer = response.content.strip()\n","                        sources = list(set([doc.metadata.get(\"source\", \"Unknown\") for doc in docs]))\n","                        sources = format_sources(sources)\n","                    else:\n","                        answer = \"I couldn't find specific information about that in my knowledge base.\"\n","                        sources = []\n","\n","                    # Add assistant message\n","                    assistant_message = ChatMessage(role=\"assistant\", content=answer)\n","                    conversation_manager.add_message(session_id, assistant_message)\n","                    conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n","\n","                # Evaluate the last response\n","                last_question = test_case[\"conversation\"][-1][\"content\"]\n","                last_answer = conversation_history[-1][\"content\"]\n","\n","                # Calculate scores\n","                relevance_score = self.evaluate_response_relevance(last_question, last_answer, docs if docs else [])\n","                citation_score = self.evaluate_citation_accuracy(last_answer, sources if sources else [])\n","                context_score = self.evaluate_context_retention(conversation_history[:-1], last_answer)\n","\n","                result = {\n","                    \"test_case_id\": i,\n","                    \"test_type\": test_case.get(\"test_type\", \"general\"),\n","                    \"question\": last_question,\n","                    \"answer\": last_answer,\n","                    \"sources\": sources if sources else [],\n","                    \"scores\": {\n","                        \"relevance\": relevance_score,\n","                        \"citation\": citation_score,\n","                        \"context_retention\": context_score\n","                    },\n","                    \"overall_score\": (relevance_score + citation_score + context_score) / 3\n","                }\n","\n","                results.append(result)\n","                total_scores[\"relevance\"].append(relevance_score)\n","                total_scores[\"citation\"].append(citation_score)\n","                total_scores[\"context\"].append(context_score)\n","\n","            except Exception as e:\n","                logger.error(f\"Error in test case {i}: {str(e)}\")\n","                continue\n","\n","        # Calculate overall metrics\n","        metrics = {\n","            \"average_relevance\": np.mean(total_scores[\"relevance\"]) if total_scores[\"relevance\"] else 0.0,\n","            \"average_citation\": np.mean(total_scores[\"citation\"]) if total_scores[\"citation\"] else 0.0,\n","            \"average_context\": np.mean(total_scores[\"context\"]) if total_scores[\"context\"] else 0.0,\n","            \"overall_average\": np.mean([np.mean(scores) for scores in total_scores.values()]) if any(total_scores.values()) else 0.0,\n","            \"test_cases_completed\": len(results),\n","            \"test_cases_failed\": len(test_cases) - len(results)\n","        }\n","\n","        return {\n","            \"overall_score\": metrics[\"overall_average\"],\n","            \"detailed_results\": results,\n","            \"metrics\": metrics\n","        }\n","\n","evaluator = RAGEvaluator()\n","print(\"✅ Evaluation system initialized!\")\n","\n","# ========================================\n","# STEP 9: MODEL INITIALIZATION\n","# ========================================\n","\n","def initialize_models():\n","    \"\"\"Initialize all models and components\"\"\"\n","    global embedding_model, static_vectorstore, dynamic_vectorstore, llm\n","    global bm25_static, bm25_dynamic, bm25_docs_static, bm25_docs_dynamic\n","    global bm25_sources_static, bm25_sources_dynamic, reranker\n","    global text_to_docs_static, text_to_docs_dynamic, chat_prompt, text_splitter\n","\n","    try:\n","        print(\"🔄 Loading models...\")\n","        ensure_directories()\n","        clean_old_conversations()\n","\n","        # Load embedding model\n","        embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","        print(\"✅ Embedding model loaded\")\n","\n","        # Initialize text splitter\n","        text_splitter = RecursiveCharacterTextSplitter(\n","            chunk_size=config.CHUNK_SIZE,\n","            chunk_overlap=config.CHUNK_OVERLAP,\n","            length_function=len,\n","            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n","        )\n","        print(\"✅ Text splitter initialized\")\n","\n","        # Load static FAISS vectorstore\n","        try:\n","            static_vectorstore = FAISS.load_local(\n","                config.STATIC_FAISS_PATH,\n","                embedding_model,\n","                allow_dangerous_deserialization=True\n","            )\n","            bm25_static, bm25_docs_static, bm25_sources_static, text_to_docs_static = build_bm25_from_vectorstore(static_vectorstore)\n","            print(\"✅ Static FAISS vectorstore loaded\")\n","        except Exception as e:\n","            print(f\"⚠️ Static FAISS not found: {str(e)}\")\n","\n","        # Load dynamic FAISS vectorstore (if exists)\n","        try:\n","            dynamic_vectorstore = FAISS.load_local(\n","                config.DYNAMIC_FAISS_PATH,\n","                embedding_model,\n","                allow_dangerous_deserialization=True\n","            )\n","            bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic = build_bm25_from_vectorstore(dynamic_vectorstore)\n","            print(\"✅ Dynamic FAISS vectorstore loaded\")\n","        except Exception as e:\n","            print(f\"ℹ️ Dynamic FAISS not found (will create on first index): {str(e)}\")\n","\n","        # Initialize LLM\n","        llm = ChatGoogleGenerativeAI(\n","            model=\"gemini-1.5-flash\",\n","            temperature=0,\n","            google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n","        )\n","        print(\"✅ LLM initialized\")\n","\n","        # Create chat prompt template\n","        chat_prompt_template = \"\"\"\n","You are a helpful AI assistant with access to multiple knowledge sources. You can maintain context across conversations and provide accurate citations.\n","\n","Previous conversation context:\n","{conversation_context}\n","\n","Current context from knowledge base:\n","{context}\n","\n","Current question:\n","{question}\n","\n","Instructions:\n","1. Use the conversation context to understand references like \"it\", \"this\", \"that\", etc.\n","2. Provide accurate answers based on the knowledge base context\n","3. If you reference specific information, it should be from the provided context\n","4. If the answer is not in the knowledge base, say: \"I couldn't find specific information about that in my knowledge base.\"\n","5. Be conversational and natural in your responses\n","6. Handle follow-up questions by connecting them to previous context when appropriate\n","\n","Answer:\n","        \"\"\"\n","        chat_prompt = PromptTemplate(\n","            input_variables=[\"conversation_context\", \"context\", \"question\"],\n","            template=chat_prompt_template\n","        )\n","        print(\"✅ Chat prompt template created\")\n","\n","        # Load reranker\n","        if config.USE_RERANKER:\n","            reranker = CrossEncoder(config.RERANKER_MODEL)\n","            print(\"✅ Reranker loaded\")\n","\n","        print(\"🎉 All models initialized successfully!\")\n","\n","    except Exception as e:\n","        print(f\"❌ Error initializing models: {str(e)}\")\n","        raise\n","\n","# ========================================\n","# STEP 10: FASTAPI APPLICATION\n","# ========================================\n","\n","app = FastAPI(\n","    title=\"Conversational RAG API with Dynamic Indexing and Sources\",\n","    description=\"Hybrid Retrieval-Augmented Generation API with Conversation Support, BM25 + FAISS, Dynamic Web Indexing, and Source Management\",\n","    version=\"3.1.0\"\n",")\n","\n","app.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=[\"*\"],\n","    allow_credentials=True,\n","    allow_methods=[\"*\"],\n","    allow_headers=[\"*\"],\n",")\n","\n","security = HTTPBearer()\n","\n","# Authentication\n","async def verify_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)):\n","    \"\"\"Verify API key from Authorization header\"\"\"\n","    api_key = credentials.credentials\n","    if api_key not in config.VALID_API_KEYS:\n","        logger.warning(f\"Invalid API key attempted: {api_key[:10]}...\")\n","        raise HTTPException(\n","            status_code=status.HTTP_401_UNAUTHORIZED,\n","            detail=\"Invalid API key\",\n","            headers={\"WWW-Authenticate\": \"Bearer\"},\n","        )\n","    return config.VALID_API_KEYS[api_key]\n","\n","# ========================================\n","# STEP 11: API ENDPOINTS\n","# ========================================\n","\n","@app.get(\"/health\", response_model=HealthResponse)\n","async def health_check():\n","    \"\"\"Health check endpoint\"\"\"\n","    clean_old_conversations()  # Cleanup old conversations on health check\n","\n","    components = {\n","        \"static_vectorstore\": static_vectorstore is not None,\n","        \"dynamic_vectorstore\": dynamic_vectorstore is not None,\n","        \"llm\": llm is not None,\n","        \"bm25_static\": bm25_static is not None,\n","        \"bm25_dynamic\": bm25_dynamic is not None,\n","        \"reranker\": reranker is not None if config.USE_RERANKER else \"disabled\",\n","        \"conversation_manager\": True\n","    }\n","    status = \"healthy\" if llm is not None else \"unhealthy\"\n","    return HealthResponse(\n","        status=status,\n","        components=components,\n","        conversations_active=len(active_conversations)\n","    )\n","\n","@app.post(\"/api/v1/chat\", response_model=ChatResponse)\n","async def chat_with_rag(\n","    request: ChatRequest,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Main conversational RAG endpoint\"\"\"\n","    try:\n","        # Check permissions\n","        if \"chat\" not in user_info.get(\"permissions\", []):\n","            raise HTTPException(\n","                status_code=status.HTTP_403_FORBIDDEN,\n","                detail=\"Insufficient permissions for chat\"\n","            )\n","\n","        logger.info(f\"Chat request from user {user_info['user']}\")\n","\n","        # Get or create session\n","        session_id = conversation_manager.get_or_create_session(request.session_id)\n","\n","        # Add conversation history to session (except the last message which is the current question)\n","        for message in request.messages[:-1]:\n","            conversation_manager.add_message(session_id, message)\n","\n","        # Get current question\n","        current_message = request.messages[-1]\n","        if current_message.role != \"user\":\n","            raise HTTPException(\n","                status_code=status.HTTP_400_BAD_REQUEST,\n","                detail=\"Last message must be from user\"\n","            )\n","\n","        # Add current question to conversation\n","        conversation_manager.add_message(session_id, current_message)\n","\n","        # Get conversation context for retrieval and generation\n","        conversation_context = conversation_manager.get_conversation_context(session_id)\n","\n","        # Perform hybrid search with conversation context\n","        docs = hybrid_search(\n","            current_message.content,\n","            use_dynamic=request.use_dynamic_index,\n","            bm_k=config.BM25_TOP_K,\n","            faiss_k=config.FAISS_TOP_K,\n","            top_k=request.top_k,\n","            use_reranker=request.use_reranker and config.USE_RERANKER,\n","            conversation_context=conversation_context\n","        )\n","\n","        if not docs:\n","            answer = \"I couldn't find specific information about that in my knowledge base.\"\n","            sources = []\n","        else:\n","            # Create context and query LLM\n","            doc_context = \"\\n\\n\".join([doc.page_content for doc in docs])\n","            formatted_prompt = chat_prompt.format(\n","                conversation_context=conversation_context,\n","                context=doc_context,\n","                question=current_message.content\n","            )\n","\n","            response = llm.invoke(formatted_prompt)\n","            answer = response.content.strip()\n","\n","            # Get unique sources\n","            sources = list(OrderedDict.fromkeys(doc.metadata.get(\"source\", \"Unknown\") for doc in docs))\n","            sources = format_sources(sources)\n","\n","        # Add assistant response to conversation\n","        assistant_message = ChatMessage(role=\"assistant\", content=answer)\n","        conversation_manager.add_message(session_id, assistant_message)\n","\n","        # Save conversation periodically\n","        if conversation_manager.get_conversation_length(session_id) % 4 == 0:  # Every 4 messages\n","            conversation_manager.save_conversation(session_id)\n","\n","        # UPDATED RESPONSE STRUCTURE WITH ENHANCED SOURCES\n","        response_data = {\n","            \"answer\": {\n","                \"content\": answer,\n","                \"role\": \"assistant\"\n","            },\n","            \"sources\": sources,  # Make sources more prominent\n","            \"citations\": sources,  # Keep backward compatibility\n","            \"retrieved_documents\": [\n","                {\n","                    \"content\": doc.page_content[:200] + \"...\" if len(doc.page_content) > 200 else doc.page_content,\n","                    \"source\": doc.metadata.get(\"source\", \"Unknown\"),\n","                    \"title\": doc.metadata.get(\"title\", \"\"),\n","                    \"chunk_id\": doc.metadata.get(\"chunk_id\", 0)\n","                } for doc in docs\n","            ] if docs else [],\n","            \"metadata\": {\n","                \"num_docs_retrieved\": len(docs),\n","                \"num_sources\": len(sources),\n","                \"reranker_used\": request.use_reranker and config.USE_RERANKER,\n","                \"dynamic_index_used\": request.use_dynamic_index,\n","                \"conversation_length\": conversation_manager.get_conversation_length(session_id),\n","                \"user\": user_info[\"user\"]\n","            }\n","        }\n","\n","        return ChatResponse(\n","            session_id=session_id,\n","            response=response_data,\n","            conversation_length=conversation_manager.get_conversation_length(session_id)\n","        )\n","\n","    except HTTPException:\n","        raise\n","    except Exception as e:\n","        logger.error(f\"Error processing chat: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Internal server error: {str(e)}\"\n","        )\n","\n","# NEW: Sources management endpoints\n","@app.get(\"/api/v1/sources\", response_model=SourcesResponse)\n","async def get_sources(user_info: dict = Depends(verify_api_key)):\n","    \"\"\"Get all available sources in the system\"\"\"\n","    try:\n","        # Check permissions\n","        if \"read\" not in user_info.get(\"permissions\", []):\n","            raise HTTPException(\n","                status_code=status.HTTP_403_FORBIDDEN,\n","                detail=\"Insufficient permissions to view sources\"\n","            )\n","\n","        static_sources = []\n","        dynamic_sources = []\n","\n","        # Get static sources\n","        if static_vectorstore:\n","            static_source_map = {}\n","            for doc_id, doc in static_vectorstore.docstore._dict.items():\n","                source = doc.metadata.get(\"source\", \"Unknown\")\n","                title = doc.metadata.get(\"title\", \"\")\n","\n","                if source not in static_source_map:\n","                    static_source_map[source] = {\n","                        \"count\": 0,\n","                        \"title\": title\n","                    }\n","                static_source_map[source][\"count\"] += 1\n","\n","            for source, info in static_source_map.items():\n","                # Convert file paths to URLs using source_url_map\n","                display_source = source_url_map.get(source, source)\n","                static_sources.append(SourceInfo(\n","                    source_url=display_source,\n","                    title=info[\"title\"],\n","                    document_count=info[\"count\"],\n","                    source_type=\"static\",\n","                    indexed_at=None,  # Static sources don't have index timestamp\n","                    last_updated=None\n","                ))\n","\n","        # Get dynamic sources\n","        if dynamic_vectorstore:\n","            dynamic_source_map = {}\n","            for doc_id, doc in dynamic_vectorstore.docstore._dict.items():\n","                source = doc.metadata.get(\"source\", \"Unknown\")\n","                title = doc.metadata.get(\"title\", \"\")\n","                indexed_at = doc.metadata.get(\"indexed_at\")\n","\n","                if source not in dynamic_source_map:\n","                    dynamic_source_map[source] = {\n","                        \"count\": 0,\n","                        \"title\": title,\n","                        \"indexed_at\": indexed_at\n","                    }\n","                dynamic_source_map[source][\"count\"] += 1\n","\n","                # Keep the most recent indexed_at\n","                if indexed_at and (not dynamic_source_map[source][\"indexed_at\"] or indexed_at > dynamic_source_map[source][\"indexed_at\"]):\n","                    dynamic_source_map[source][\"indexed_at\"] = indexed_at\n","\n","            for source, info in dynamic_source_map.items():\n","                indexed_datetime = None\n","                if info[\"indexed_at\"]:\n","                    try:\n","                        indexed_datetime = datetime.fromisoformat(info[\"indexed_at\"]) if isinstance(info[\"indexed_at\"], str) else info[\"indexed_at\"]\n","                    except:\n","                        indexed_datetime = None\n","\n","                dynamic_sources.append(SourceInfo(\n","                    source_url=source,\n","                    title=info[\"title\"],\n","                    document_count=info[\"count\"],\n","                    source_type=\"dynamic\",\n","                    indexed_at=indexed_datetime,\n","                    last_updated=indexed_datetime\n","                ))\n","\n","        # Sort sources by document count (descending)\n","        static_sources.sort(key=lambda x: x.document_count, reverse=True)\n","        dynamic_sources.sort(key=lambda x: x.document_count, reverse=True)\n","\n","        return SourcesResponse(\n","            total_sources=len(static_sources) + len(dynamic_sources),\n","            static_sources=static_sources,\n","            dynamic_sources=dynamic_sources\n","        )\n","\n","    except Exception as e:\n","        logger.error(f\"Error retrieving sources: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Failed to retrieve sources: {str(e)}\"\n","        )\n","\n","@app.get(\"/api/v1/sources/{source_hash}\")\n","async def get_source_details(\n","    source_hash: str,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Get detailed information about a specific source\"\"\"\n","    # Check permissions\n","    if \"read\" not in user_info.get(\"permissions\", []):\n","        raise HTTPException(\n","            status_code=status.HTTP_403_FORBIDDEN,\n","            detail=\"Insufficient permissions to view source details\"\n","        )\n","\n","    # Find source by hash or URL\n","    source_found = False\n","    source_details = {\n","        \"source_url\": None,\n","        \"title\": None,\n","        \"chunks\": [],\n","        \"source_type\": None,\n","        \"indexed_at\": None\n","    }\n","\n","    # Search in both vectorstores\n","    for vectorstore, source_type in [(static_vectorstore, \"static\"), (dynamic_vectorstore, \"dynamic\")]:\n","        if vectorstore:\n","            for doc_id, doc in vectorstore.docstore._dict.items():\n","                source = doc.metadata.get(\"source\", \"\")\n","                url_hash = get_url_hash(source)\n","\n","                if url_hash == source_hash or source.endswith(source_hash):\n","                    source_found = True\n","                    source_details.update({\n","                        \"source_url\": source_url_map.get(source, source),\n","                        \"title\": doc.metadata.get(\"title\", \"\"),\n","                        \"source_type\": source_type,\n","                        \"indexed_at\": doc.metadata.get(\"indexed_at\")\n","                    })\n","\n","                    source_details[\"chunks\"].append({\n","                        \"chunk_id\": doc.metadata.get(\"chunk_id\", 0),\n","                        \"content_preview\": doc.page_content[:300] + \"...\" if len(doc.page_content) > 300 else doc.page_content,\n","                        \"content_length\": len(doc.page_content)\n","                    })\n","\n","    if not source_found:\n","        raise HTTPException(\n","            status_code=status.HTTP_404_NOT_FOUND,\n","            detail=\"Source not found\"\n","        )\n","\n","    return source_details\n","\n","@app.post(\"/api/v1/index\", response_model=IndexResponse)\n","async def index_urls(\n","    request: IndexRequest,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Index URLs into the dynamic vector database\"\"\"\n","    global dynamic_vectorstore, bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic\n","\n","    # Check permissions\n","    if \"index\" not in user_info.get(\"permissions\", []):\n","        raise HTTPException(\n","            status_code=status.HTTP_403_FORBIDDEN,\n","            detail=\"Insufficient permissions for indexing\"\n","        )\n","\n","    logger.info(f\"Indexing request from {user_info['user']}: {len(request.url)} URLs\")\n","\n","    scraper = WebScraper()\n","    indexed_urls = []\n","    failed_urls = []\n","\n","    try:\n","        new_documents = []\n","\n","        for url in request.url:\n","            try:\n","                logger.info(f\"Processing URL: {url}\")\n","\n","                # Extract content\n","                result = scraper.extract_content(url)\n","\n","                if not result['success']:\n","                    failed_urls.append({\n","                        \"url\": url,\n","                        \"error\": result['error'],\n","                        \"error_type\": \"EXTRACTION_FAILED\"\n","                    })\n","                    continue\n","\n","                # Split content into chunks\n","                chunks = text_splitter.split_text(result['content'])\n","\n","                # Create documents\n","                for i, chunk in enumerate(chunks):\n","                    doc = Document(\n","                        page_content=chunk,\n","                        metadata={\n","                            \"source\": url,\n","                            \"title\": result['title'],\n","                            \"chunk_id\": i,\n","                            \"total_chunks\": len(chunks),\n","                            \"indexed_at\": datetime.now().isoformat(),\n","                            \"url_hash\": get_url_hash(url)\n","                        }\n","                    )\n","                    new_documents.append(doc)\n","\n","                indexed_urls.append(url)\n","                logger.info(f\"✅ Successfully processed {url} - {len(chunks)} chunks\")\n","\n","            except Exception as e:\n","                logger.error(f\"Error processing {url}: {str(e)}\")\n","                failed_urls.append({\n","                    \"url\": url,\n","                    \"error\": str(e),\n","                    \"error_type\": \"PROCESSING_ERROR\"\n","                })\n","\n","        # Update vector database if we have new documents\n","        if new_documents:\n","            try:\n","                if dynamic_vectorstore is None:\n","                    # Create new FAISS index\n","                    dynamic_vectorstore = FAISS.from_documents(new_documents, embedding_model)\n","                    logger.info(\"✅ Created new dynamic FAISS index\")\n","                else:\n","                    # Add to existing index\n","                    dynamic_vectorstore.add_documents(new_documents)\n","                    logger.info(f\"✅ Added {len(new_documents)} documents to existing index\")\n","\n","                # Save updated index\n","                dynamic_vectorstore.save_local(config.DYNAMIC_FAISS_PATH)\n","\n","                # Rebuild BM25 and mappings\n","                bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic = build_bm25_from_vectorstore(dynamic_vectorstore)\n","\n","                logger.info(f\"✅ Dynamic index updated\")\n","\n","            except Exception as e:\n","                logger.error(f\"Error updating vector database: {str(e)}\")\n","                raise HTTPException(\n","                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","                    detail=f\"Failed to update vector database: {str(e)}\"\n","                )\n","\n","        # Prepare response\n","        response_status = \"success\" if indexed_urls else \"failed\"\n","        if indexed_urls and failed_urls:\n","            response_status = \"partial_success\"\n","\n","        metadata = {\n","            \"total_requested\": len(request.url),\n","            \"successfully_indexed\": len(indexed_urls),\n","            \"failed\": len(failed_urls),\n","            \"new_documents_added\": len(new_documents),\n","            \"user\": user_info[\"user\"]\n","        }\n","\n","        return IndexResponse(\n","            status=response_status,\n","            indexed_url=indexed_urls,\n","            failed_url=failed_urls if failed_urls else None,\n","            metadata=metadata\n","        )\n","\n","    except Exception as e:\n","        logger.error(f\"Critical error in indexing: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Indexing failed: {str(e)}\"\n","        )\n","\n","@app.post(\"/api/v1/evaluate\", response_model=EvaluationResponse)\n","async def evaluate_system(\n","    request: EvaluationRequest,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Run automated evaluation of the RAG system\"\"\"\n","    # Check permissions\n","    if \"eval\" not in user_info.get(\"permissions\", []):\n","        raise HTTPException(\n","            status_code=status.HTTP_403_FORBIDDEN,\n","            detail=\"Insufficient permissions for evaluation\"\n","        )\n","\n","    logger.info(f\"Evaluation request from user {user_info['user']}\")\n","\n","    try:\n","        # Use provided test cases or create default ones\n","        test_cases = request.test_cases if request.test_cases else evaluator.create_test_dataset()\n","\n","        # Run evaluation\n","        evaluation_results = await evaluator.run_evaluation(test_cases)\n","\n","        return EvaluationResponse(\n","            overall_score=evaluation_results[\"overall_score\"],\n","            detailed_results=evaluation_results[\"detailed_results\"],\n","            metrics=evaluation_results[\"metrics\"]\n","        )\n","\n","    except Exception as e:\n","        logger.error(f\"Error running evaluation: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Evaluation failed: {str(e)}\"\n","        )\n","\n","@app.get(\"/api/v1/conversations/{session_id}\")\n","async def get_conversation(\n","    session_id: str,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Get conversation history\"\"\"\n","    if session_id not in active_conversations:\n","        raise HTTPException(\n","            status_code=status.HTTP_404_NOT_FOUND,\n","            detail=\"Conversation not found\"\n","        )\n","\n","    conversation_data = active_conversations[session_id]\n","    return {\n","        \"session_id\": session_id,\n","        \"messages\": conversation_data[\"messages\"],\n","        \"created_at\": conversation_data[\"created_at\"],\n","        \"last_active\": conversation_data[\"last_active\"],\n","        \"message_count\": len(conversation_data[\"messages\"])\n","    }\n","\n","@app.delete(\"/api/v1/conversations/{session_id}\")\n","async def delete_conversation(\n","    session_id: str,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Delete a conversation\"\"\"\n","    if session_id not in active_conversations:\n","        raise HTTPException(\n","            status_code=status.HTTP_404_NOT_FOUND,\n","            detail=\"Conversation not found\"\n","        )\n","\n","    del active_conversations[session_id]\n","    return {\"status\": \"deleted\", \"session_id\": session_id}\n","\n","@app.get(\"/api/v1/conversations\")\n","async def list_conversations(user_info: dict = Depends(verify_api_key)):\n","    \"\"\"List active conversations\"\"\"\n","    clean_old_conversations()\n","\n","    conversations_summary = []\n","    for session_id, conv_data in active_conversations.items():\n","        conversations_summary.append({\n","            \"session_id\": session_id,\n","            \"message_count\": len(conv_data[\"messages\"]),\n","            \"created_at\": conv_data[\"created_at\"],\n","            \"last_active\": conv_data[\"last_active\"],\n","            \"last_message_preview\": conv_data[\"messages\"][-1][\"content\"][:100] if conv_data[\"messages\"] else \"\"\n","        })\n","\n","    return {\n","        \"active_conversations\": len(conversations_summary),\n","        \"conversations\": conversations_summary\n","    }\n","\n","print(\"✅ API endpoints defined!\")\n","\n","# ========================================\n","# STEP 12: DEMO AND TESTING FUNCTIONS\n","# ========================================\n","\n","def create_demo_test_cases():\n","    \"\"\"Create demonstration test cases for your project\"\"\"\n","    demo_cases = [\n","        {\n","            \"name\": \"Context Retention Test\",\n","            \"conversation\": [\n","                {\"role\": \"user\", \"content\": \"What is a transformer in machine learning?\"},\n","                {\"role\": \"user\", \"content\": \"How does its attention mechanism work?\"},\n","                {\"role\": \"user\", \"content\": \"What are the advantages of this approach?\"}\n","            ],\n","            \"expected_behavior\": \"Should understand that 'its' refers to transformer and 'this approach' refers to attention mechanism\"\n","        },\n","        {\n","            \"name\": \"Multi-Source Retrieval Test\",\n","            \"conversation\": [\n","                {\"role\": \"user\", \"content\": \"Tell me about recent developments in AI and their impact on software engineering\"}\n","            ],\n","            \"expected_behavior\": \"Should pull from both static and dynamic sources, provide citations\"\n","        },\n","        {\n","            \"name\": \"Topic Switching Test\",\n","            \"conversation\": [\n","                {\"role\": \"user\", \"content\": \"Explain neural networks\"},\n","                {\"role\": \"user\", \"content\": \"Actually, let's talk about database indexing instead\"}\n","            ],\n","            \"expected_behavior\": \"Should cleanly switch topics without carrying over irrelevant context\"\n","        },\n","        {\n","            \"name\": \"Citation Accuracy Test\",\n","            \"conversation\": [\n","                {\"role\": \"user\", \"content\": \"What does research say about hallucinations in language models?\"}\n","            ],\n","            \"expected_behavior\": \"Should provide specific citations for research claims\"\n","        }\n","    ]\n","\n","    # Save demo test cases\n","    demo_file = os.path.join(config.EVALUATION_DATASET_PATH, \"demo_test_cases.json\")\n","    save_metadata(demo_cases, demo_file)\n","\n","    print(\"✅ Demo test cases created!\")\n","    print(\"📁 Location:\", demo_file)\n","    return demo_cases\n","\n","# ========================================\n","# STEP 13: SERVER STARTUP\n","# ========================================\n","\n","def start_server():\n","    \"\"\"Start the FastAPI server with ngrok\"\"\"\n","    # Create ngrok tunnel\n","    public_url = ngrok.connect(8000)\n","\n","    print(\"=\" * 60)\n","    print(\"🚀 CONVERSATIONAL RAG SYSTEM WITH SOURCES API LAUNCHED!\")\n","    print(\"=\" * 60)\n","    print(f\"🌐 Public URL: {public_url}\")\n","    print(f\"📚 API Documentation: {public_url}/docs\")\n","    print(f\"🔑 API Keys:\")\n","    print(f\"   • demo-api-key-123 (full access)\")\n","    print(f\"   • eval-key-456 (evaluation access)\")\n","    print(\"\")\n","    print(\"🎯 MAIN ENDPOINTS:\")\n","    print(f\"  • POST {public_url}/api/v1/chat - Chat with the system\")\n","    print(f\"  • POST {public_url}/api/v1/index - Index new URLs\")\n","    print(f\"  • GET  {public_url}/api/v1/sources - List all sources\")\n","    print(f\"  • GET  {public_url}/api/v1/sources/{{hash}} - Get source details\")\n","    print(f\"  • POST {public_url}/api/v1/evaluate - Run automated evaluation\")\n","    print(f\"  • GET  {public_url}/api/v1/conversations - List conversations\")\n","    print(f\"  • GET  {public_url}/health - Health check\")\n","    print(\"\")\n","    print(\"💡 EXAMPLE USAGE:\")\n","    print(f\"\"\"\n","# Start a conversation:\n","curl -X POST \"{public_url}/api/v1/chat\" \\\\\n","  -H \"Authorization: Bearer demo-api-key-123\" \\\\\n","  -H \"Content-Type: application/json\" \\\\\n","  -d '{{\n","    \"messages\": [\n","      {{\"role\": \"user\", \"content\": \"What is attention mechanism?\"}}\n","    ]\n","  }}'\n","\n","# Get all sources:\n","curl -X GET \"{public_url}/api/v1/sources\" \\\\\n","  -H \"Authorization: Bearer demo-api-key-123\"\n","\n","# Index new content:\n","curl -X POST \"{public_url}/api/v1/index\" \\\\\n","  -H \"Authorization: Bearer demo-api-key-123\" \\\\\n","  -H \"Content-Type: application/json\" \\\\\n","  -d '{{\"url\": [\"https://example.com/ai-article\"]}}'\n","\n","# Run evaluation:\n","curl -X POST \"{public_url}/api/v1/evaluate\" \\\\\n","  -H \"Authorization: Bearer eval-key-456\" \\\\\n","  -H \"Content-Type: application/json\" \\\\\n","  -d '{{\"test_cases\": []}}'\n","    \"\"\")\n","    print(\"=\" * 60)\n","    print(\"🔥 Your conversational RAG system with sources API is ready!\")\n","    print(\"✨ New Features: Complete source management and tracking\")\n","    print(\"🎓 Perfect for your final data science project!\")\n","    print(\"=\" * 60)\n","\n","    # Start the server\n","    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n","\n","# ========================================\n","# STEP 14: LAUNCH THE SYSTEM\n","# ========================================\n","\n","# Initialize models first\n","print(\"🔄 Initializing models and components...\")\n","initialize_models()\n","\n","# Create demo test cases for your project\n","print(\"\\n📝 Creating demo test cases...\")\n","create_demo_test_cases()\n","\n","\n","# Launch the server\n","print(\"\\n🚀 Starting the conversational RAG system...\")\n","print(\"⏳ This will open ngrok tunnel and start the FastAPI server...\")\n","\n","# Start the server\n","start_server()"]},{"cell_type":"markdown","source":["## AWS Deployment RAG pipeline"],"metadata":{"id":"DyjhowT311_X"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhwDqatlCrVu"},"outputs":[],"source":["# Setup imports and basic configuration\n","import os\n","import json\n","import time\n","import shutil\n","from datetime import datetime, timedelta\n","from typing import List, Optional, Dict, Any, Union\n","from urllib.parse import urlparse, urljoin\n","import requests\n","from bs4 import BeautifulSoup\n","import uvicorn\n","from fastapi import FastAPI, HTTPException, Depends, status, Body\n","from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n","from fastapi.middleware.cors import CORSMiddleware\n","from pydantic import BaseModel, Field, validator\n","import logging\n","from collections import OrderedDict\n","import hashlib\n","import re\n","import uuid\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","import asyncio\n","from threading import Thread\n","\n","# Import the RAG components\n","from rank_bm25 import BM25Okapi\n","from sentence_transformers import CrossEncoder\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_community.vectorstores import FAISS\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain.prompts import PromptTemplate\n","from langchain.docstore.document import Document\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","print(\"✅ All imports successful!\")\n","\n","# ========================================\n","# STEP 2: CONFIGURATION AND API KEYS\n","# ========================================\n","\n","# Configuration for AWS deployment\n","class Config:\n","    # Base path for AWS EC2\n","    BASE_PATH = \"/home/ubuntu/rag-knowledge-base/rag_demo\"\n","\n","    # Static index (existing)\n","    STATIC_FAISS_PATH = \"/home/ubuntu/rag-knowledge-base/rag_demo/faiss_index\"\n","\n","    # Dynamic index (new)\n","    DYNAMIC_BASE_PATH = \"/home/ubuntu/rag-knowledge-base/rag_demo/dynamic_index\"\n","    DYNAMIC_FAISS_PATH = \"/home/ubuntu/rag-knowledge-base/rag_demo/dynamic_index/faiss_index\"\n","    METADATA_PATH = \"/home/ubuntu/rag-knowledge-base/rag_demo/dynamic_index/metadata\"\n","    BACKUP_PATH = \"/home/ubuntu/rag-knowledge-base/rag_demo/dynamic_index/backups\"\n","\n","    # Conversation settings\n","    CONVERSATIONS_PATH = \"/home/ubuntu/rag-knowledge-base/rag_demo/conversations\"\n","    MAX_CONVERSATION_LENGTH = 10  # Maximum number of message pairs\n","    CONVERSATION_TIMEOUT = 1800   # 30 minutes in seconds\n","    MAX_CONTEXT_LENGTH = 3        # Last N message pairs to include in context\n","\n","    # Indexing settings\n","    USE_RERANKER = True\n","    RERANKER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n","    BM25_TOP_K = 10\n","    FAISS_TOP_K = 10\n","    FINAL_TOP_K = 3\n","\n","    # Web scraping settings\n","    REQUEST_TIMEOUT = 30\n","    MAX_RETRIES = 3\n","    RETRY_DELAY = 2\n","    CHUNK_SIZE = 1000\n","    CHUNK_OVERLAP = 100\n","    RE_INDEX_DAYS = 7\n","    MAX_VERSIONS = 3\n","\n","    # Evaluation settings\n","    EVALUATION_DATASET_PATH = \"/home/ubuntu/rag-knowledge-base/rag_demo/evaluation\"\n","\n","    # Authentication - YOU CAN CHANGE THESE KEYS\n","    VALID_API_KEYS = {\n","        \"demo-api-key-123\": {\"user\": \"demo_user\", \"permissions\": [\"read\", \"query\", \"index\", \"chat\"]},\n","        \"eval-key-456\": {\"user\": \"evaluator\", \"permissions\": [\"read\", \"query\", \"chat\", \"eval\"]},\n","    }\n","\n","config = Config()\n","\n","# Get API keys from environment variables\n","GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n","if not GOOGLE_API_KEY:\n","    logger.error(\"GOOGLE_API_KEY environment variable not set!\")\n","    raise ValueError(\"Please set GOOGLE_API_KEY environment variable\")\n","\n","os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n","print(\"✅ Configuration loaded!\")\n","\n","# ========================================\n","# STEP 3: PYDANTIC MODELS (Same as before)\n","# ========================================\n","\n","# Chat-specific models\n","class ChatMessage(BaseModel):\n","    role: str = Field(..., pattern=\"^(user|assistant)$\")\n","    content: str = Field(..., min_length=1, max_length=2000)\n","    timestamp: Optional[datetime] = Field(default_factory=datetime.now)\n","\n","class ChatRequest(BaseModel):\n","    messages: List[ChatMessage] = Field(..., min_items=1, max_items=20)\n","    session_id: Optional[str] = Field(default=None)\n","    use_dynamic_index: Optional[bool] = Field(default=True)\n","    use_reranker: Optional[bool] = Field(default=True)\n","    top_k: Optional[int] = Field(default=3, ge=1, le=5)\n","\n","class ChatResponse(BaseModel):\n","    session_id: str\n","    response: Dict[str, Any]\n","    conversation_length: int\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","\n","# Original models (updated)\n","class IndexRequest(BaseModel):\n","    url: List[str] = Field(..., min_items=1, max_items=5, description=\"URLs to index\")\n","\n","    @validator('url')\n","    def validate_urls(cls, v):\n","        for url in v:\n","            parsed = urlparse(url)\n","            if not parsed.scheme or not parsed.netloc:\n","                raise ValueError(f\"Invalid URL format: {url}\")\n","        return v\n","\n","class IndexResponse(BaseModel):\n","    status: str\n","    indexed_url: List[str]\n","    failed_url: Optional[List[Dict[str, str]]] = None\n","    metadata: Dict[str, Any] = Field(default_factory=dict)\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","\n","class HealthResponse(BaseModel):\n","    status: str\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","    components: dict\n","    conversations_active: int\n","\n","# Sources models\n","class SourceInfo(BaseModel):\n","    source_url: str\n","    title: Optional[str] = None\n","    indexed_at: Optional[datetime] = None\n","    document_count: int = 0\n","    source_type: str = Field(..., description=\"static or dynamic\")\n","    last_updated: Optional[datetime] = None\n","\n","class SourcesResponse(BaseModel):\n","    total_sources: int\n","    static_sources: List[SourceInfo]\n","    dynamic_sources: List[SourceInfo]\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","\n","# Evaluation models\n","class EvaluationRequest(BaseModel):\n","    test_cases: List[Dict[str, Any]]\n","    session_id: Optional[str] = None\n","\n","class EvaluationResponse(BaseModel):\n","    overall_score: float\n","    detailed_results: List[Dict[str, Any]]\n","    metrics: Dict[str, float]\n","    timestamp: datetime = Field(default_factory=datetime.now)\n","\n","print(\"✅ Pydantic models defined!\")\n","\n","# ========================================\n","# STEP 4: GLOBAL VARIABLES AND UTILITIES\n","# ========================================\n","\n","# Global variables\n","embedding_model = None\n","static_vectorstore = None\n","dynamic_vectorstore = None\n","llm = None\n","bm25_static = None\n","bm25_dynamic = None\n","bm25_docs_static = None\n","bm25_docs_dynamic = None\n","bm25_sources_static = None\n","bm25_sources_dynamic = None\n","reranker = None\n","text_to_docs_static = None\n","text_to_docs_dynamic = None\n","chat_prompt = None\n","text_splitter = None\n","\n","# In-memory conversation storage (will use file-based backup)\n","active_conversations = {}\n","\n","# Updated source URL mapping for static content (AWS paths)\n","source_url_map = {\n","    \"/content/drive/MyDrive/RAG_demo/data/genai-platform.txt\": \"https://huyenchip.com/2024/07/25/genai-platform.html\",\n","    \"/content/drive/MyDrive/RAG_demo/data/hallucination.txt\": \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n","    \"/content/drive/MyDrive/RAG_demo/data/quora_engineering.txt\": \"https://quoraengineering.quora.com/Building-Embedding-Search-at-Quora\"\n","}\n","\n","# Utility functions\n","def ensure_directories():\n","    \"\"\"Ensure all required directories exist\"\"\"\n","    directories = [\n","        config.BASE_PATH,\n","        config.DYNAMIC_BASE_PATH,\n","        config.DYNAMIC_FAISS_PATH,\n","        config.METADATA_PATH,\n","        config.BACKUP_PATH,\n","        config.CONVERSATIONS_PATH,\n","        config.EVALUATION_DATASET_PATH\n","    ]\n","    for directory in directories:\n","        os.makedirs(directory, exist_ok=True)\n","    logger.info(\"✅ Directory structure created\")\n","\n","def get_url_hash(url: str) -> str:\n","    \"\"\"Generate a hash for URL to use as unique identifier\"\"\"\n","    return hashlib.md5(url.encode()).hexdigest()\n","\n","def load_metadata(file_path: str) -> Dict:\n","    \"\"\"Load metadata from JSON file\"\"\"\n","    if os.path.exists(file_path):\n","        try:\n","            with open(file_path, 'r', encoding='utf-8') as f:\n","                return json.load(f)\n","        except Exception as e:\n","            logger.error(f\"Error loading metadata from {file_path}: {str(e)}\")\n","    return {}\n","\n","def save_metadata(data: Dict, file_path: str):\n","    \"\"\"Save metadata to JSON file\"\"\"\n","    try:\n","        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n","        with open(file_path, 'w', encoding='utf-8') as f:\n","            json.dump(data, f, indent=2, default=str)\n","    except Exception as e:\n","        logger.error(f\"Error saving metadata to {file_path}: {str(e)}\")\n","        raise\n","\n","def format_sources(sources):\n","    \"\"\"Convert file paths to URLs\"\"\"\n","    formatted = []\n","    for source in sources:\n","        if source.startswith('http'):\n","            formatted.append(source)\n","        else:\n","            formatted.append(source_url_map.get(source, source))\n","    return formatted\n","\n","def generate_session_id() -> str:\n","    \"\"\"Generate a unique session ID\"\"\"\n","    return str(uuid.uuid4())\n","\n","def clean_old_conversations():\n","    \"\"\"Remove old conversations from memory and save important ones\"\"\"\n","    current_time = datetime.now()\n","    expired_sessions = []\n","\n","    for session_id, conv_data in active_conversations.items():\n","        last_active = conv_data.get('last_active', current_time)\n","        if isinstance(last_active, str):\n","            last_active = datetime.fromisoformat(last_active)\n","\n","        if (current_time - last_active).seconds > config.CONVERSATION_TIMEOUT:\n","            # Save conversation before deletion\n","            try:\n","                conv_file = os.path.join(config.CONVERSATIONS_PATH, f\"{session_id}.json\")\n","                save_metadata(conv_data, conv_file)\n","            except Exception as e:\n","                logger.error(f\"Error saving conversation {session_id}: {e}\")\n","\n","            expired_sessions.append(session_id)\n","\n","    for session_id in expired_sessions:\n","        del active_conversations[session_id]\n","        logger.info(f\"Cleaned expired conversation: {session_id}\")\n","\n","print(\"✅ Utility functions defined!\")\n","\n","# ========================================\n","# STEP 5: CONVERSATION MANAGEMENT\n","# ========================================\n","\n","class ConversationManager:\n","    def __init__(self):\n","        self.conversations = active_conversations\n","\n","    def get_or_create_session(self, session_id: Optional[str] = None) -> str:\n","        \"\"\"Get existing session or create new one\"\"\"\n","        if session_id and session_id in self.conversations:\n","            # Update last active time\n","            self.conversations[session_id]['last_active'] = datetime.now()\n","            return session_id\n","\n","        # Create new session\n","        new_session_id = generate_session_id()\n","        self.conversations[new_session_id] = {\n","            'messages': [],\n","            'created_at': datetime.now(),\n","            'last_active': datetime.now(),\n","            'metadata': {}\n","        }\n","        logger.info(f\"Created new conversation session: {new_session_id}\")\n","        return new_session_id\n","\n","    def add_message(self, session_id: str, message: ChatMessage):\n","        \"\"\"Add message to conversation\"\"\"\n","        if session_id not in self.conversations:\n","            raise ValueError(f\"Session {session_id} not found\")\n","\n","        self.conversations[session_id]['messages'].append({\n","            'role': message.role,\n","            'content': message.content,\n","            'timestamp': message.timestamp.isoformat() if message.timestamp else datetime.now().isoformat()\n","        })\n","        self.conversations[session_id]['last_active'] = datetime.now()\n","\n","        # Trim conversation if too long\n","        messages = self.conversations[session_id]['messages']\n","        if len(messages) > config.MAX_CONVERSATION_LENGTH * 2:  # *2 for user+assistant pairs\n","            self.conversations[session_id]['messages'] = messages[-config.MAX_CONVERSATION_LENGTH * 2:]\n","\n","    def get_conversation_context(self, session_id: str, max_pairs: int = None) -> str:\n","        \"\"\"Get conversation context for LLM\"\"\"\n","        if session_id not in self.conversations:\n","            return \"\"\n","\n","        messages = self.conversations[session_id]['messages']\n","        if not messages:\n","            return \"\"\n","\n","        # Get last N pairs (user + assistant messages)\n","        max_pairs = max_pairs or config.MAX_CONTEXT_LENGTH\n","        recent_messages = messages[-(max_pairs * 2):]\n","\n","        context_parts = []\n","        for msg in recent_messages:\n","            role = \"Human\" if msg['role'] == 'user' else \"Assistant\"\n","            context_parts.append(f\"{role}: {msg['content']}\")\n","\n","        return \"\\n\".join(context_parts)\n","\n","    def get_conversation_length(self, session_id: str) -> int:\n","        \"\"\"Get number of message exchanges\"\"\"\n","        if session_id not in self.conversations:\n","            return 0\n","        return len(self.conversations[session_id]['messages'])\n","\n","    def save_conversation(self, session_id: str):\n","        \"\"\"Save conversation to disk\"\"\"\n","        if session_id not in self.conversations:\n","            return\n","\n","        conv_file = os.path.join(config.CONVERSATIONS_PATH, f\"{session_id}.json\")\n","        save_metadata(self.conversations[session_id], conv_file)\n","\n","conversation_manager = ConversationManager()\n","print(\"✅ Conversation manager initialized!\")\n","\n","# ========================================\n","# STEP 6: WEB SCRAPING AND INDEXING\n","# ========================================\n","\n","class WebScraper:\n","    def __init__(self):\n","        self.session = requests.Session()\n","        self.session.headers.update({\n","            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n","        })\n","\n","    def extract_content(self, url: str) -> Dict[str, Any]:\n","        \"\"\"Extract content from URL with retry logic\"\"\"\n","        for attempt in range(config.MAX_RETRIES):\n","            try:\n","                response = self.session.get(url, timeout=config.REQUEST_TIMEOUT)\n","                response.raise_for_status()\n","\n","                soup = BeautifulSoup(response.content, 'html.parser')\n","\n","                # Remove unwanted elements\n","                for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'advertisement']):\n","                    element.decompose()\n","\n","                # Extract title\n","                title = soup.find('title')\n","                title_text = title.get_text().strip() if title else url\n","\n","                # Extract main content\n","                content_selectors = [\n","                    'article', 'main', '[role=\"main\"]',\n","                    '.content', '.post', '.article',\n","                    'div.container', 'div.wrapper'\n","                ]\n","\n","                content_text = \"\"\n","                for selector in content_selectors:\n","                    content = soup.select_one(selector)\n","                    if content:\n","                        content_text = content.get_text()\n","                        break\n","\n","                if not content_text:\n","                    # Fallback to body\n","                    body = soup.find('body')\n","                    content_text = body.get_text() if body else \"\"\n","\n","                # Clean text\n","                content_text = re.sub(r'\\s+', ' ', content_text).strip()\n","\n","                if not content_text:\n","                    raise ValueError(\"No content extracted\")\n","\n","                return {\n","                    'title': title_text,\n","                    'content': content_text,\n","                    'url': url,\n","                    'success': True,\n","                    'error': None\n","                }\n","\n","            except Exception as e:\n","                logger.warning(f\"Attempt {attempt + 1} failed for {url}: {str(e)}\")\n","                if attempt < config.MAX_RETRIES - 1:\n","                    time.sleep(config.RETRY_DELAY * (2 ** attempt))\n","                else:\n","                    return {\n","                        'title': None,\n","                        'content': None,\n","                        'url': url,\n","                        'success': False,\n","                        'error': str(e)\n","                    }\n","\n","def build_bm25_from_vectorstore(vectorstore):\n","    \"\"\"Build BM25 index from FAISS vectorstore\"\"\"\n","    try:\n","        docs = []\n","        sources = []\n","        for doc_id, doc in vectorstore.docstore._dict.items():\n","            text = getattr(doc, \"page_content\", None) or doc.page_content\n","            docs.append(text)\n","            sources.append(doc.metadata.get(\"source\", \"Unknown\"))\n","\n","        tokenized = [d.split() for d in docs]\n","        bm25 = BM25Okapi(tokenized)\n","\n","        # Build text to docs mapping\n","        text_to_docs = {}\n","        for doc in vectorstore.docstore._dict.values():\n","            text = doc.page_content\n","            text_to_docs.setdefault(text, []).append(doc)\n","\n","        logger.info(f\"BM25 built over {len(docs)} chunks\")\n","        return bm25, docs, sources, text_to_docs\n","    except Exception as e:\n","        logger.error(f\"Error building BM25: {str(e)}\")\n","        raise\n","\n","print(\"✅ Web scraping and indexing functions defined!\")\n","\n","# ========================================\n","# STEP 7: HYBRID SEARCH SYSTEM\n","# ========================================\n","\n","def hybrid_search(query: str, use_dynamic: bool = True, bm_k: int = 10, faiss_k: int = 10, top_k: int = 3, use_reranker: bool = True, conversation_context: str = \"\"):\n","    \"\"\"Perform hybrid search on static and/or dynamic indices with conversation context\"\"\"\n","    try:\n","        # Enhanced query with context\n","        enhanced_query = query\n","        if conversation_context:\n","            # Add context to help with pronouns and references\n","            enhanced_query = f\"Context: {conversation_context}\\n\\nCurrent question: {query}\"\n","\n","        all_candidates = []\n","\n","        # Search static index\n","        if static_vectorstore:\n","            candidates_static = _search_single_index(\n","                enhanced_query, static_vectorstore, bm25_static, bm25_docs_static,\n","                bm25_sources_static, text_to_docs_static, bm_k, faiss_k\n","            )\n","            all_candidates.extend(candidates_static)\n","\n","        # Search dynamic index\n","        if use_dynamic and dynamic_vectorstore:\n","            candidates_dynamic = _search_single_index(\n","                enhanced_query, dynamic_vectorstore, bm25_dynamic, bm25_docs_dynamic,\n","                bm25_sources_dynamic, text_to_docs_dynamic, bm_k, faiss_k\n","            )\n","            all_candidates.extend(candidates_dynamic)\n","\n","        if not all_candidates:\n","            return []\n","\n","        # Merge and deduplicate candidates\n","        merged = OrderedDict()\n","        for candidate in all_candidates:\n","            key = candidate[\"text\"].strip()[:100]  # Use first 100 chars as key\n","            if key not in merged or (candidate.get(\"bm25_score\") or 0) > (merged[key].get(\"bm25_score\") or 0):\n","                merged[key] = candidate\n","\n","        candidates = list(merged.values())\n","\n","        # Optional reranking - use original query for reranking\n","        if use_reranker and reranker and candidates:\n","            pairs = [(query, c[\"text\"]) for c in candidates]  # Use original query for reranking\n","            scores = reranker.predict(pairs)\n","            for c, s in zip(candidates, scores):\n","                c[\"rerank_score\"] = float(s)\n","            candidates = sorted(candidates, key=lambda x: x[\"rerank_score\"], reverse=True)\n","        else:\n","            candidates = sorted(candidates, key=lambda x: (0 if x[\"bm25_score\"] is not None else 1, -(x[\"bm25_score\"] or 0)))\n","\n","        # Return top_k Document objects\n","        final_docs = []\n","        for c in candidates[:top_k]:\n","            text = c[\"text\"]\n","            # Try to find in both mappings\n","            docs_list = text_to_docs_static.get(text, []) if text_to_docs_static else []\n","            if not docs_list and text_to_docs_dynamic:\n","                docs_list = text_to_docs_dynamic.get(text, [])\n","\n","            if docs_list:\n","                final_docs.append(docs_list[0])\n","            else:\n","                final_docs.append(Document(page_content=text, metadata={\"source\": c.get(\"source\", \"Unknown\")}))\n","\n","        return final_docs\n","\n","    except Exception as e:\n","        logger.error(f\"Error in hybrid search: {str(e)}\")\n","        raise\n","\n","def _search_single_index(query: str, vectorstore, bm25, bm25_docs, bm25_sources, text_to_docs, bm_k: int, faiss_k: int):\n","    \"\"\"Search a single index (static or dynamic)\"\"\"\n","    candidates = []\n","\n","    # BM25 candidates\n","    if bm25 and bm25_docs:\n","        tokenized_q = query.split()\n","        bm25_scores = bm25.get_scores(tokenized_q)\n","        bm25_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:bm_k]\n","        for idx in bm25_indices:\n","            txt = bm25_docs[idx]\n","            src = bm25_sources[idx]\n","            candidates.append({\"text\": txt, \"source\": src, \"bm25_score\": bm25_scores[idx]})\n","\n","    # FAISS candidates\n","    if vectorstore:\n","        faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": faiss_k})\n","        faiss_docs = faiss_retriever.get_relevant_documents(query)\n","        for d in faiss_docs:\n","            candidates.append({\"text\": d.page_content, \"source\": d.metadata.get(\"source\", \"Unknown\"), \"bm25_score\": None})\n","\n","    return candidates\n","\n","print(\"✅ Hybrid search system defined!\")\n","\n","# ========================================\n","# STEP 8: EVALUATION SYSTEM\n","# ========================================\n","\n","class RAGEvaluator:\n","    def __init__(self):\n","        self.test_cases = []\n","        self.results = []\n","\n","    def create_test_dataset(self):\n","        \"\"\"Create evaluation test cases\"\"\"\n","        test_cases = [\n","            # Context retention tests\n","            {\n","                \"conversation\": [\n","                    {\"role\": \"user\", \"content\": \"What is attention mechanism in transformers?\"},\n","                    {\"role\": \"user\", \"content\": \"How does it help with long sequences?\"}\n","                ],\n","                \"expected_context\": \"attention mechanism\",\n","                \"test_type\": \"context_retention\"\n","            },\n","\n","            # Citation accuracy tests\n","            {\n","                \"conversation\": [\n","                    {\"role\": \"user\", \"content\": \"Tell me about RAG systems\"}\n","                ],\n","                \"expected_citations\": True,\n","                \"test_type\": \"citation_accuracy\"\n","            },\n","\n","            # Topic switching tests\n","            {\n","                \"conversation\": [\n","                    {\"role\": \"user\", \"content\": \"Explain neural networks\"},\n","                    {\"role\": \"user\", \"content\": \"Now tell me about cooking recipes\"}\n","                ],\n","                \"expected_behavior\": \"topic_switch\",\n","                \"test_type\": \"topic_switching\"\n","            },\n","\n","            # Multi-source tests\n","            {\n","                \"conversation\": [\n","                    {\"role\": \"user\", \"content\": \"What are the latest trends in AI?\"}\n","                ],\n","                \"expected_sources\": \"mixed\",\n","                \"test_type\": \"multi_source\"\n","            }\n","        ]\n","\n","        # Save test cases\n","        test_file = os.path.join(config.EVALUATION_DATASET_PATH, \"test_cases.json\")\n","        save_metadata(test_cases, test_file)\n","        return test_cases\n","\n","    def evaluate_response_relevance(self, question: str, answer: str, context_docs: List[Document]) -> float:\n","        \"\"\"Evaluate how relevant the answer is to the question\"\"\"\n","        try:\n","            # Simple keyword overlap score\n","            question_words = set(question.lower().split())\n","            answer_words = set(answer.lower().split())\n","\n","            overlap = len(question_words.intersection(answer_words))\n","            relevance_score = overlap / len(question_words) if question_words else 0.0\n","\n","            # Bonus for using context\n","            context_text = \" \".join([doc.page_content for doc in context_docs])\n","            context_words = set(context_text.lower().split())\n","            context_usage = len(answer_words.intersection(context_words)) / len(context_words) if context_words else 0.0\n","\n","            final_score = min(1.0, (relevance_score + context_usage) / 2)\n","            return final_score\n","\n","        except Exception as e:\n","            logger.error(f\"Error evaluating relevance: {str(e)}\")\n","            return 0.0\n","\n","    def evaluate_citation_accuracy(self, answer: str, sources: List[str]) -> float:\n","        \"\"\"Evaluate citation accuracy\"\"\"\n","        if not sources:\n","            return 0.0\n","\n","        # Check if answer contains factual claims (simple heuristic)\n","        factual_indicators = [\"according to\", \"research shows\", \"studies indicate\", \"data reveals\", \"analysis found\"]\n","        has_factual_claims = any(indicator in answer.lower() for indicator in factual_indicators)\n","\n","        if has_factual_claims and sources:\n","            return 1.0\n","        elif not has_factual_claims:\n","            return 0.8  # No factual claims, so no citations needed\n","        else:\n","            return 0.0  # Factual claims but no citations\n","\n","    def evaluate_context_retention(self, conversation_history: List[Dict], current_answer: str) -> float:\n","        \"\"\"Evaluate how well context from previous messages is retained\"\"\"\n","        if len(conversation_history) <= 1:\n","            return 1.0  # No previous context to retain\n","\n","        # Look for references to previous topics\n","        previous_content = \" \".join([msg[\"content\"] for msg in conversation_history[:-1]])\n","        previous_words = set(previous_content.lower().split())\n","        answer_words = set(current_answer.lower().split())\n","\n","        # Check for pronouns and references\n","        references = [\"this\", \"that\", \"it\", \"they\", \"these\", \"those\"]\n","        has_references = any(ref in current_answer.lower() for ref in references)\n","\n","        # Calculate context retention score\n","        word_overlap = len(previous_words.intersection(answer_words)) / len(previous_words) if previous_words else 0.0\n","        reference_bonus = 0.3 if has_references else 0.0\n","\n","        context_score = min(1.0, word_overlap + reference_bonus)\n","        return context_score\n","\n","    async def run_evaluation(self, test_cases: List[Dict]) -> Dict[str, Any]:\n","        \"\"\"Run comprehensive evaluation\"\"\"\n","        results = []\n","        total_scores = {\"relevance\": [], \"citation\": [], \"context\": []}\n","\n","        for i, test_case in enumerate(test_cases):\n","            try:\n","                logger.info(f\"Running test case {i+1}/{len(test_cases)}\")\n","\n","                # Simulate conversation\n","                session_id = generate_session_id()\n","                conversation_history = []\n","\n","                for message in test_case[\"conversation\"]:\n","                    # Add user message\n","                    user_msg = ChatMessage(role=\"user\", content=message[\"content\"])\n","                    conversation_manager.add_message(session_id, user_msg)\n","                    conversation_history.append({\"role\": \"user\", \"content\": message[\"content\"]})\n","\n","                    # Get bot response\n","                    context = conversation_manager.get_conversation_context(session_id)\n","                    docs = hybrid_search(\n","                        message[\"content\"],\n","                        use_dynamic=True,\n","                        conversation_context=context\n","                    )\n","\n","                    if docs:\n","                        doc_context = \"\\n\\n\".join([doc.page_content for doc in docs])\n","                        formatted_prompt = chat_prompt.format(\n","                            conversation_context=context,\n","                            context=doc_context,\n","                            question=message[\"content\"]\n","                        )\n","                        response = llm.invoke(formatted_prompt)\n","                        answer = response.content.strip()\n","                        sources = list(set([doc.metadata.get(\"source\", \"Unknown\") for doc in docs]))\n","                        sources = format_sources(sources)\n","                    else:\n","                        answer = \"I couldn't find specific information about that in my knowledge base.\"\n","                        sources = []\n","\n","                    # Add assistant message\n","                    assistant_message = ChatMessage(role=\"assistant\", content=answer)\n","                    conversation_manager.add_message(session_id, assistant_message)\n","                    conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n","\n","                # Evaluate the last response\n","                last_question = test_case[\"conversation\"][-1][\"content\"]\n","                last_answer = conversation_history[-1][\"content\"]\n","\n","                # Calculate scores\n","                relevance_score = self.evaluate_response_relevance(last_question, last_answer, docs if docs else [])\n","                citation_score = self.evaluate_citation_accuracy(last_answer, sources if sources else [])\n","                context_score = self.evaluate_context_retention(conversation_history[:-1], last_answer)\n","\n","                result = {\n","                    \"test_case_id\": i,\n","                    \"test_type\": test_case.get(\"test_type\", \"general\"),\n","                    \"question\": last_question,\n","                    \"answer\": last_answer,\n","                    \"sources\": sources if sources else [],\n","                    \"scores\": {\n","                        \"relevance\": relevance_score,\n","                        \"citation\": citation_score,\n","                        \"context_retention\": context_score\n","                    },\n","                    \"overall_score\": (relevance_score + citation_score + context_score) / 3\n","                }\n","\n","                results.append(result)\n","                total_scores[\"relevance\"].append(relevance_score)\n","                total_scores[\"citation\"].append(citation_score)\n","                total_scores[\"context\"].append(context_score)\n","\n","            except Exception as e:\n","                logger.error(f\"Error in test case {i}: {str(e)}\")\n","                continue\n","\n","        # Calculate overall metrics\n","        metrics = {\n","            \"average_relevance\": np.mean(total_scores[\"relevance\"]) if total_scores[\"relevance\"] else 0.0,\n","            \"average_citation\": np.mean(total_scores[\"citation\"]) if total_scores[\"citation\"] else 0.0,\n","            \"average_context\": np.mean(total_scores[\"context\"]) if total_scores[\"context\"] else 0.0,\n","            \"overall_average\": np.mean([np.mean(scores) for scores in total_scores.values()]) if any(total_scores.values()) else 0.0,\n","            \"test_cases_completed\": len(results),\n","            \"test_cases_failed\": len(test_cases) - len(results)\n","        }\n","\n","        return {\n","            \"overall_score\": metrics[\"overall_average\"],\n","            \"detailed_results\": results,\n","            \"metrics\": metrics\n","        }\n","\n","evaluator = RAGEvaluator()\n","print(\"✅ Evaluation system initialized!\")\n","\n","# ========================================\n","# MODIFIED: MODEL INITIALIZATION\n","# ========================================\n","\n","def initialize_models():\n","    \"\"\"Initialize all models and components for AWS deployment\"\"\"\n","    global embedding_model, static_vectorstore, dynamic_vectorstore, llm\n","    global bm25_static, bm25_dynamic, bm25_docs_static, bm25_docs_dynamic\n","    global bm25_sources_static, bm25_sources_dynamic, reranker\n","    global text_to_docs_static, text_to_docs_dynamic, chat_prompt, text_splitter\n","\n","    try:\n","        print(\"🔄 Loading models for AWS deployment...\")\n","        ensure_directories()\n","        clean_old_conversations()\n","\n","        # Load embedding model\n","        embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","        print(\"✅ Embedding model loaded\")\n","\n","        # Initialize text splitter\n","        text_splitter = RecursiveCharacterTextSplitter(\n","            chunk_size=config.CHUNK_SIZE,\n","            chunk_overlap=config.CHUNK_OVERLAP,\n","            length_function=len,\n","            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n","        )\n","        print(\"✅ Text splitter initialized\")\n","\n","        # Try to load static FAISS vectorstore (may not exist initially)\n","        try:\n","            if os.path.exists(config.STATIC_FAISS_PATH):\n","                static_vectorstore = FAISS.load_local(\n","                    config.STATIC_FAISS_PATH,\n","                    embedding_model,\n","                    allow_dangerous_deserialization=True\n","                )\n","                bm25_static, bm25_docs_static, bm25_sources_static, text_to_docs_static = build_bm25_from_vectorstore(static_vectorstore)\n","                print(\"✅ Static FAISS vectorstore loaded\")\n","            else:\n","                print(\"ℹ️ No static FAISS index found - will work with dynamic index only\")\n","        except Exception as e:\n","            print(f\"⚠️ Could not load static FAISS: {str(e)}\")\n","\n","        # Try to load dynamic FAISS vectorstore (may not exist initially)\n","        try:\n","            if os.path.exists(config.DYNAMIC_FAISS_PATH):\n","                dynamic_vectorstore = FAISS.load_local(\n","                    config.DYNAMIC_FAISS_PATH,\n","                    embedding_model,\n","                    allow_dangerous_deserialization=True\n","                )\n","                bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic = build_bm25_from_vectorstore(dynamic_vectorstore)\n","                print(\"✅ Dynamic FAISS vectorstore loaded\")\n","            else:\n","                print(\"ℹ️ No dynamic FAISS index found - will create on first index\")\n","        except Exception as e:\n","            print(f\"ℹ️ Dynamic FAISS not found (will create on first index): {str(e)}\")\n","\n","        # Initialize LLM with environment variable\n","        llm = ChatGoogleGenerativeAI(\n","            model=\"gemini-1.5-flash\",\n","            temperature=0,\n","            google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n","        )\n","        print(\"✅ LLM initialized\")\n","\n","        # Create chat prompt template\n","        chat_prompt_template = \"\"\"\n","You are a helpful AI assistant with access to multiple knowledge sources. You can maintain context across conversations and provide accurate citations.\n","\n","Previous conversation context:\n","{conversation_context}\n","\n","Current context from knowledge base:\n","{context}\n","\n","Current question:\n","{question}\n","\n","Instructions:\n","1. Use the conversation context to understand references like \"it\", \"this\", \"that\", etc.\n","2. Provide accurate answers based on the knowledge base context\n","3. If you reference specific information, it should be from the provided context\n","4. If the answer is not in the knowledge base, say: \"I couldn't find specific information about that in my knowledge base.\"\n","5. Be conversational and natural in your responses\n","6. Handle follow-up questions by connecting them to previous context when appropriate\n","\n","Answer:\n","        \"\"\"\n","        chat_prompt = PromptTemplate(\n","            input_variables=[\"conversation_context\", \"context\", \"question\"],\n","            template=chat_prompt_template\n","        )\n","        print(\"✅ Chat prompt template created\")\n","\n","        # Load reranker\n","        if config.USE_RERANKER:\n","            reranker = CrossEncoder(config.RERANKER_MODEL)\n","            print(\"✅ Reranker loaded\")\n","\n","        print(\"🎉 All models initialized successfully!\")\n","\n","    except Exception as e:\n","        print(f\"❌ Error initializing models: {str(e)}\")\n","        raise\n","\n","# ========================================\n","# MODIFIED: SERVER STARTUP FOR AWS\n","# ========================================\n","\n","def start_aws_server():\n","    \"\"\"Start the FastAPI server for AWS deployment\"\"\"\n","    print(\"=\" * 60)\n","    print(\"🚀 CONVERSATIONAL RAG SYSTEM - AWS DEPLOYMENT\")\n","    print(\"=\" * 60)\n","    print(\"🔑 API Keys:\")\n","    print(\"   • demo-api-key-123 (full access)\")\n","    print(\"   • eval-key-456 (evaluation access)\")\n","    print(\"\")\n","    print(\"🎯 ENDPOINTS will be available at:\")\n","    print(\"  • POST /api/v1/chat - Chat with the system\")\n","    print(\"  • POST /api/v1/index - Index new URLs\")\n","    print(\"  • GET  /api/v1/sources - List all sources\")\n","    print(\"  • GET  /api/v1/sources/{hash} - Get source details\")\n","    print(\"  • POST /api/v1/evaluate - Run automated evaluation\")\n","    print(\"  • GET  /api/v1/conversations - List conversations\")\n","    print(\"  • GET  /health - Health check\")\n","    print(\"\")\n","    print(\"🌐 Server starting on 0.0.0.0:8000...\")\n","    print(\"📚 API docs will be at: http://your-ec2-ip:8000/docs\")\n","    print(\"=\" * 60)\n","\n","    # Start the server without ngrok\n","    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n","\n","# ========================================\n","# FASTAPI APPLICATION (Same as before)\n","# ========================================\n","\n","app = FastAPI(\n","    title=\"Conversational RAG API with Dynamic Indexing and Sources\",\n","    description=\"Hybrid Retrieval-Augmented Generation API with Conversation Support, BM25 + FAISS, Dynamic Web Indexing, and Source Management\",\n","    version=\"3.1.0\"\n",")\n","\n","app.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=[\"*\"],\n","    allow_credentials=True,\n","    allow_methods=[\"*\"],\n","    allow_headers=[\"*\"],\n",")\n","\n","security = HTTPBearer()\n","\n","# Authentication (same as before)\n","async def verify_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)):\n","    \"\"\"Verify API key from Authorization header\"\"\"\n","    api_key = credentials.credentials\n","    if api_key not in config.VALID_API_KEYS:\n","        logger.warning(f\"Invalid API key attempted: {api_key[:10]}...\")\n","        raise HTTPException(\n","            status_code=status.HTTP_401_UNAUTHORIZED,\n","            detail=\"Invalid API key\",\n","            headers={\"WWW-Authenticate\": \"Bearer\"},\n","        )\n","    return config.VALID_API_KEYS[api_key]\n","\n","# ========================================\n","# ========================================\n","# STEP 11: API ENDPOINTS\n","# ========================================\n","\n","@app.get(\"/health\", response_model=HealthResponse)\n","async def health_check():\n","    \"\"\"Health check endpoint\"\"\"\n","    clean_old_conversations()  # Cleanup old conversations on health check\n","\n","    components = {\n","        \"static_vectorstore\": static_vectorstore is not None,\n","        \"dynamic_vectorstore\": dynamic_vectorstore is not None,\n","        \"llm\": llm is not None,\n","        \"bm25_static\": bm25_static is not None,\n","        \"bm25_dynamic\": bm25_dynamic is not None,\n","        \"reranker\": reranker is not None if config.USE_RERANKER else \"disabled\",\n","        \"conversation_manager\": True\n","    }\n","    status = \"healthy\" if llm is not None else \"unhealthy\"\n","    return HealthResponse(\n","        status=status,\n","        components=components,\n","        conversations_active=len(active_conversations)\n","    )\n","\n","@app.post(\"/api/v1/chat\", response_model=ChatResponse)\n","async def chat_with_rag(\n","    request: ChatRequest,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Main conversational RAG endpoint\"\"\"\n","    try:\n","        # Check permissions\n","        if \"chat\" not in user_info.get(\"permissions\", []):\n","            raise HTTPException(\n","                status_code=status.HTTP_403_FORBIDDEN,\n","                detail=\"Insufficient permissions for chat\"\n","            )\n","\n","        logger.info(f\"Chat request from user {user_info['user']}\")\n","\n","        # Get or create session\n","        session_id = conversation_manager.get_or_create_session(request.session_id)\n","\n","        # Add conversation history to session (except the last message which is the current question)\n","        for message in request.messages[:-1]:\n","            conversation_manager.add_message(session_id, message)\n","\n","        # Get current question\n","        current_message = request.messages[-1]\n","        if current_message.role != \"user\":\n","            raise HTTPException(\n","                status_code=status.HTTP_400_BAD_REQUEST,\n","                detail=\"Last message must be from user\"\n","            )\n","\n","        # Add current question to conversation\n","        conversation_manager.add_message(session_id, current_message)\n","\n","        # Get conversation context for retrieval and generation\n","        conversation_context = conversation_manager.get_conversation_context(session_id)\n","\n","        # Perform hybrid search with conversation context\n","        docs = hybrid_search(\n","            current_message.content,\n","            use_dynamic=request.use_dynamic_index,\n","            bm_k=config.BM25_TOP_K,\n","            faiss_k=config.FAISS_TOP_K,\n","            top_k=request.top_k,\n","            use_reranker=request.use_reranker and config.USE_RERANKER,\n","            conversation_context=conversation_context\n","        )\n","\n","        if not docs:\n","            answer = \"I couldn't find specific information about that in my knowledge base.\"\n","            sources = []\n","        else:\n","            # Create context and query LLM\n","            doc_context = \"\\n\\n\".join([doc.page_content for doc in docs])\n","            formatted_prompt = chat_prompt.format(\n","                conversation_context=conversation_context,\n","                context=doc_context,\n","                question=current_message.content\n","            )\n","\n","            response = llm.invoke(formatted_prompt)\n","            answer = response.content.strip()\n","\n","            # Get unique sources\n","            sources = list(OrderedDict.fromkeys(doc.metadata.get(\"source\", \"Unknown\") for doc in docs))\n","            sources = format_sources(sources)\n","\n","        # Add assistant response to conversation\n","        assistant_message = ChatMessage(role=\"assistant\", content=answer)\n","        conversation_manager.add_message(session_id, assistant_message)\n","\n","        # Save conversation periodically\n","        if conversation_manager.get_conversation_length(session_id) % 4 == 0:  # Every 4 messages\n","            conversation_manager.save_conversation(session_id)\n","\n","        # UPDATED RESPONSE STRUCTURE WITH ENHANCED SOURCES\n","        response_data = {\n","            \"answer\": {\n","                \"content\": answer,\n","                \"role\": \"assistant\"\n","            },\n","            \"sources\": sources,  # Make sources more prominent\n","            \"citations\": sources,  # Keep backward compatibility\n","            \"retrieved_documents\": [\n","                {\n","                    \"content\": doc.page_content[:200] + \"...\" if len(doc.page_content) > 200 else doc.page_content,\n","                    \"source\": doc.metadata.get(\"source\", \"Unknown\"),\n","                    \"title\": doc.metadata.get(\"title\", \"\"),\n","                    \"chunk_id\": doc.metadata.get(\"chunk_id\", 0)\n","                } for doc in docs\n","            ] if docs else [],\n","            \"metadata\": {\n","                \"num_docs_retrieved\": len(docs),\n","                \"num_sources\": len(sources),\n","                \"reranker_used\": request.use_reranker and config.USE_RERANKER,\n","                \"dynamic_index_used\": request.use_dynamic_index,\n","                \"conversation_length\": conversation_manager.get_conversation_length(session_id),\n","                \"user\": user_info[\"user\"]\n","            }\n","        }\n","\n","        return ChatResponse(\n","            session_id=session_id,\n","            response=response_data,\n","            conversation_length=conversation_manager.get_conversation_length(session_id)\n","        )\n","\n","    except HTTPException:\n","        raise\n","    except Exception as e:\n","        logger.error(f\"Error processing chat: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Internal server error: {str(e)}\"\n","        )\n","\n","# NEW: Sources management endpoints\n","@app.get(\"/api/v1/sources\", response_model=SourcesResponse)\n","async def get_sources(user_info: dict = Depends(verify_api_key)):\n","    \"\"\"Get all available sources in the system\"\"\"\n","    try:\n","        # Check permissions\n","        if \"read\" not in user_info.get(\"permissions\", []):\n","            raise HTTPException(\n","                status_code=status.HTTP_403_FORBIDDEN,\n","                detail=\"Insufficient permissions to view sources\"\n","            )\n","\n","        static_sources = []\n","        dynamic_sources = []\n","\n","        # Get static sources\n","        if static_vectorstore:\n","            static_source_map = {}\n","            for doc_id, doc in static_vectorstore.docstore._dict.items():\n","                source = doc.metadata.get(\"source\", \"Unknown\")\n","                title = doc.metadata.get(\"title\", \"\")\n","\n","                if source not in static_source_map:\n","                    static_source_map[source] = {\n","                        \"count\": 0,\n","                        \"title\": title\n","                    }\n","                static_source_map[source][\"count\"] += 1\n","\n","            for source, info in static_source_map.items():\n","                # Convert file paths to URLs using source_url_map\n","                display_source = source_url_map.get(source, source)\n","                static_sources.append(SourceInfo(\n","                    source_url=display_source,\n","                    title=info[\"title\"],\n","                    document_count=info[\"count\"],\n","                    source_type=\"static\",\n","                    indexed_at=None,  # Static sources don't have index timestamp\n","                    last_updated=None\n","                ))\n","\n","        # Get dynamic sources\n","        if dynamic_vectorstore:\n","            dynamic_source_map = {}\n","            for doc_id, doc in dynamic_vectorstore.docstore._dict.items():\n","                source = doc.metadata.get(\"source\", \"Unknown\")\n","                title = doc.metadata.get(\"title\", \"\")\n","                indexed_at = doc.metadata.get(\"indexed_at\")\n","\n","                if source not in dynamic_source_map:\n","                    dynamic_source_map[source] = {\n","                        \"count\": 0,\n","                        \"title\": title,\n","                        \"indexed_at\": indexed_at\n","                    }\n","                dynamic_source_map[source][\"count\"] += 1\n","\n","                # Keep the most recent indexed_at\n","                if indexed_at and (not dynamic_source_map[source][\"indexed_at\"] or indexed_at > dynamic_source_map[source][\"indexed_at\"]):\n","                    dynamic_source_map[source][\"indexed_at\"] = indexed_at\n","\n","            for source, info in dynamic_source_map.items():\n","                indexed_datetime = None\n","                if info[\"indexed_at\"]:\n","                    try:\n","                        indexed_datetime = datetime.fromisoformat(info[\"indexed_at\"]) if isinstance(info[\"indexed_at\"], str) else info[\"indexed_at\"]\n","                    except:\n","                        indexed_datetime = None\n","\n","                dynamic_sources.append(SourceInfo(\n","                    source_url=source,\n","                    title=info[\"title\"],\n","                    document_count=info[\"count\"],\n","                    source_type=\"dynamic\",\n","                    indexed_at=indexed_datetime,\n","                    last_updated=indexed_datetime\n","                ))\n","\n","        # Sort sources by document count (descending)\n","        static_sources.sort(key=lambda x: x.document_count, reverse=True)\n","        dynamic_sources.sort(key=lambda x: x.document_count, reverse=True)\n","\n","        return SourcesResponse(\n","            total_sources=len(static_sources) + len(dynamic_sources),\n","            static_sources=static_sources,\n","            dynamic_sources=dynamic_sources\n","        )\n","\n","    except Exception as e:\n","        logger.error(f\"Error retrieving sources: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Failed to retrieve sources: {str(e)}\"\n","        )\n","\n","@app.get(\"/api/v1/sources/{source_hash}\")\n","async def get_source_details(\n","    source_hash: str,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Get detailed information about a specific source\"\"\"\n","    # Check permissions\n","    if \"read\" not in user_info.get(\"permissions\", []):\n","        raise HTTPException(\n","            status_code=status.HTTP_403_FORBIDDEN,\n","            detail=\"Insufficient permissions to view source details\"\n","        )\n","\n","    # Find source by hash or URL\n","    source_found = False\n","    source_details = {\n","        \"source_url\": None,\n","        \"title\": None,\n","        \"chunks\": [],\n","        \"source_type\": None,\n","        \"indexed_at\": None\n","    }\n","\n","    # Search in both vectorstores\n","    for vectorstore, source_type in [(static_vectorstore, \"static\"), (dynamic_vectorstore, \"dynamic\")]:\n","        if vectorstore:\n","            for doc_id, doc in vectorstore.docstore._dict.items():\n","                source = doc.metadata.get(\"source\", \"\")\n","                url_hash = get_url_hash(source)\n","\n","                if url_hash == source_hash or source.endswith(source_hash):\n","                    source_found = True\n","                    source_details.update({\n","                        \"source_url\": source_url_map.get(source, source),\n","                        \"title\": doc.metadata.get(\"title\", \"\"),\n","                        \"source_type\": source_type,\n","                        \"indexed_at\": doc.metadata.get(\"indexed_at\")\n","                    })\n","\n","                    source_details[\"chunks\"].append({\n","                        \"chunk_id\": doc.metadata.get(\"chunk_id\", 0),\n","                        \"content_preview\": doc.page_content[:300] + \"...\" if len(doc.page_content) > 300 else doc.page_content,\n","                        \"content_length\": len(doc.page_content)\n","                    })\n","\n","    if not source_found:\n","        raise HTTPException(\n","            status_code=status.HTTP_404_NOT_FOUND,\n","            detail=\"Source not found\"\n","        )\n","\n","    return source_details\n","\n","@app.post(\"/api/v1/index\", response_model=IndexResponse)\n","async def index_urls(\n","    request: IndexRequest,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Index URLs into the dynamic vector database\"\"\"\n","    global dynamic_vectorstore, bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic\n","\n","    # Check permissions\n","    if \"index\" not in user_info.get(\"permissions\", []):\n","        raise HTTPException(\n","            status_code=status.HTTP_403_FORBIDDEN,\n","            detail=\"Insufficient permissions for indexing\"\n","        )\n","\n","    logger.info(f\"Indexing request from {user_info['user']}: {len(request.url)} URLs\")\n","\n","    scraper = WebScraper()\n","    indexed_urls = []\n","    failed_urls = []\n","\n","    try:\n","        new_documents = []\n","\n","        for url in request.url:\n","            try:\n","                logger.info(f\"Processing URL: {url}\")\n","\n","                # Extract content\n","                result = scraper.extract_content(url)\n","\n","                if not result['success']:\n","                    failed_urls.append({\n","                        \"url\": url,\n","                        \"error\": result['error'],\n","                        \"error_type\": \"EXTRACTION_FAILED\"\n","                    })\n","                    continue\n","\n","                # Split content into chunks\n","                chunks = text_splitter.split_text(result['content'])\n","\n","                # Create documents\n","                for i, chunk in enumerate(chunks):\n","                    doc = Document(\n","                        page_content=chunk,\n","                        metadata={\n","                            \"source\": url,\n","                            \"title\": result['title'],\n","                            \"chunk_id\": i,\n","                            \"total_chunks\": len(chunks),\n","                            \"indexed_at\": datetime.now().isoformat(),\n","                            \"url_hash\": get_url_hash(url)\n","                        }\n","                    )\n","                    new_documents.append(doc)\n","\n","                indexed_urls.append(url)\n","                logger.info(f\"✅ Successfully processed {url} - {len(chunks)} chunks\")\n","\n","            except Exception as e:\n","                logger.error(f\"Error processing {url}: {str(e)}\")\n","                failed_urls.append({\n","                    \"url\": url,\n","                    \"error\": str(e),\n","                    \"error_type\": \"PROCESSING_ERROR\"\n","                })\n","\n","        # Update vector database if we have new documents\n","        if new_documents:\n","            try:\n","                if dynamic_vectorstore is None:\n","                    # Create new FAISS index\n","                    dynamic_vectorstore = FAISS.from_documents(new_documents, embedding_model)\n","                    logger.info(\"✅ Created new dynamic FAISS index\")\n","                else:\n","                    # Add to existing index\n","                    dynamic_vectorstore.add_documents(new_documents)\n","                    logger.info(f\"✅ Added {len(new_documents)} documents to existing index\")\n","\n","                # Save updated index\n","                dynamic_vectorstore.save_local(config.DYNAMIC_FAISS_PATH)\n","\n","                # Rebuild BM25 and mappings\n","                bm25_dynamic, bm25_docs_dynamic, bm25_sources_dynamic, text_to_docs_dynamic = build_bm25_from_vectorstore(dynamic_vectorstore)\n","\n","                logger.info(f\"✅ Dynamic index updated\")\n","\n","            except Exception as e:\n","                logger.error(f\"Error updating vector database: {str(e)}\")\n","                raise HTTPException(\n","                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","                    detail=f\"Failed to update vector database: {str(e)}\"\n","                )\n","\n","        # Prepare response\n","        response_status = \"success\" if indexed_urls else \"failed\"\n","        if indexed_urls and failed_urls:\n","            response_status = \"partial_success\"\n","\n","        metadata = {\n","            \"total_requested\": len(request.url),\n","            \"successfully_indexed\": len(indexed_urls),\n","            \"failed\": len(failed_urls),\n","            \"new_documents_added\": len(new_documents),\n","            \"user\": user_info[\"user\"]\n","        }\n","\n","        return IndexResponse(\n","            status=response_status,\n","            indexed_url=indexed_urls,\n","            failed_url=failed_urls if failed_urls else None,\n","            metadata=metadata\n","        )\n","\n","    except Exception as e:\n","        logger.error(f\"Critical error in indexing: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Indexing failed: {str(e)}\"\n","        )\n","\n","@app.post(\"/api/v1/evaluate\", response_model=EvaluationResponse)\n","async def evaluate_system(\n","    request: EvaluationRequest,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Run automated evaluation of the RAG system\"\"\"\n","    # Check permissions\n","    if \"eval\" not in user_info.get(\"permissions\", []):\n","        raise HTTPException(\n","            status_code=status.HTTP_403_FORBIDDEN,\n","            detail=\"Insufficient permissions for evaluation\"\n","        )\n","\n","    logger.info(f\"Evaluation request from user {user_info['user']}\")\n","\n","    try:\n","        # Use provided test cases or create default ones\n","        test_cases = request.test_cases if request.test_cases else evaluator.create_test_dataset()\n","\n","        # Run evaluation\n","        evaluation_results = await evaluator.run_evaluation(test_cases)\n","\n","        return EvaluationResponse(\n","            overall_score=evaluation_results[\"overall_score\"],\n","            detailed_results=evaluation_results[\"detailed_results\"],\n","            metrics=evaluation_results[\"metrics\"]\n","        )\n","\n","    except Exception as e:\n","        logger.error(f\"Error running evaluation: {str(e)}\")\n","        raise HTTPException(\n","            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n","            detail=f\"Evaluation failed: {str(e)}\"\n","        )\n","\n","@app.get(\"/api/v1/conversations/{session_id}\")\n","async def get_conversation(\n","    session_id: str,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Get conversation history\"\"\"\n","    if session_id not in active_conversations:\n","        raise HTTPException(\n","            status_code=status.HTTP_404_NOT_FOUND,\n","            detail=\"Conversation not found\"\n","        )\n","\n","    conversation_data = active_conversations[session_id]\n","    return {\n","        \"session_id\": session_id,\n","        \"messages\": conversation_data[\"messages\"],\n","        \"created_at\": conversation_data[\"created_at\"],\n","        \"last_active\": conversation_data[\"last_active\"],\n","        \"message_count\": len(conversation_data[\"messages\"])\n","    }\n","\n","@app.delete(\"/api/v1/conversations/{session_id}\")\n","async def delete_conversation(\n","    session_id: str,\n","    user_info: dict = Depends(verify_api_key)\n","):\n","    \"\"\"Delete a conversation\"\"\"\n","    if session_id not in active_conversations:\n","        raise HTTPException(\n","            status_code=status.HTTP_404_NOT_FOUND,\n","            detail=\"Conversation not found\"\n","        )\n","\n","    del active_conversations[session_id]\n","    return {\"status\": \"deleted\", \"session_id\": session_id}\n","\n","@app.get(\"/api/v1/conversations\")\n","async def list_conversations(user_info: dict = Depends(verify_api_key)):\n","    \"\"\"List active conversations\"\"\"\n","    clean_old_conversations()\n","\n","    conversations_summary = []\n","    for session_id, conv_data in active_conversations.items():\n","        conversations_summary.append({\n","            \"session_id\": session_id,\n","            \"message_count\": len(conv_data[\"messages\"]),\n","            \"created_at\": conv_data[\"created_at\"],\n","            \"last_active\": conv_data[\"last_active\"],\n","            \"last_message_preview\": conv_data[\"messages\"][-1][\"content\"][:100] if conv_data[\"messages\"] else \"\"\n","        })\n","\n","    return {\n","        \"active_conversations\": len(conversations_summary),\n","        \"conversations\": conversations_summary\n","    }\n","\n","print(\"✅ API endpoints defined!\")\n","# ========================================\n","# MAIN EXECUTION\n","# ========================================\n","\n","if __name__ == \"__main__\":\n","    print(\"🔄 Initializing conversational RAG system for AWS...\")\n","\n","    # Initialize models first\n","    initialize_models()\n","\n","    # Create demo test cases\n","    print(\"\\n📝 Creating demo test cases...\")\n","    # create_demo_test_cases()  # Include this function from your original code\n","\n","    # Print startup info\n","    print(\"\\n🎓 SYSTEM READY FOR DEPLOYMENT!\")\n","    print(\"✅ All models loaded\")\n","    print(\"✅ API endpoints configured\")\n","    print(\"✅ Ready for recruiter demos\")\n","\n","    # Start the AWS server\n","    start_aws_server()"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"13b-tUP3fJxUbxPeWWJszruSJNkO_IkPL","authorship_tag":"ABX9TyPc6YArMF7T1fIEAw1/FAMt"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00ea95a09e804b51bc9afa1660a5e846":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01e6dcd04ff2453c991bc4f39fafa922":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0334d9bdc8814160811cfde584ed242a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03a1d102e9684912ba78b50bd429d69a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0765501ff35e487091bc4b51482cb61e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08cd2ccfeefa44299ef9c32af8e3b547":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08f2c5fd71b747b9b82cc6a051f43f5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cde91ad6d8f4cd0b0f5bf70dc1a504d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cfcd68d23fc404b81c313c6e2d40f6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d68c215f8fc47cc9f288e4edff193bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f0a4b774d454f43bd01d05d452e3a45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f211a9edfda45bb9afd17169f0e860a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bd9f6bf82ac40bb8435e9087923e201":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bd9f85f22134eb590d4b229be09ef05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d418c3e6a7e4d8aa254bfb34775cbdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70703871283249e4b794287e0df93736","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01e6dcd04ff2453c991bc4f39fafa922","value":349}},"1f722d8ce12144fbba1906a2adca05ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f948887f1ae49108a5c95940e6413b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ffb13c74ee543819d9375a7f90f0b09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20a10c30bcc34e6eb3087fa5a71afead":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f948887f1ae49108a5c95940e6413b6","placeholder":"​","style":"IPY_MODEL_d033c5629a804e1ca2cb4409d82f1564","value":" 10.5k/? [00:00&lt;00:00, 756kB/s]"}},"20d1dbad5442498787b1a03a9b2d8de2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26ed36f52652471f9d15c8c86ac85eb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"272cec19191a407eba9aca392c300d0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"280da422dffd48b18b6f41029e878d02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a7207ba41ad4bfda97020aa046ea153":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37c42167e9244c1a8bc580ac48628be1","placeholder":"​","style":"IPY_MODEL_2b9b1ba884cf43ee8a261cba9c5537b5","value":"tokenizer_config.json: 100%"}},"2b66102cd510401696f3c327b2bc0ec8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d9e50e4ffc54cfeae3a1a36657b338a","placeholder":"​","style":"IPY_MODEL_4bb9f039f5174245a695c79f89d95345","value":" 116/116 [00:00&lt;00:00, 7.28kB/s]"}},"2b6c0fbcabb144bbbbd99660bfb2cb2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f58478fe8b074fc99e24d05d8d66304b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bd6bdec047b41298e20f74053558fea","value":1}},"2b9b1ba884cf43ee8a261cba9c5537b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32da07357965400bbf44d40662a13a54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34b51f3c89314464bd7f5ac40db930e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3642add690b64b1c925eb095a1445026":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37c42167e9244c1a8bc580ac48628be1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bd6bdec047b41298e20f74053558fea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d9e50e4ffc54cfeae3a1a36657b338a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"400529ec58c349cfa49b9a15307b62ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbd35eb777974fe28fe2f7b3c18babcc","IPY_MODEL_1d418c3e6a7e4d8aa254bfb34775cbdd","IPY_MODEL_92bb196ac29642cb922c263391d17f9a"],"layout":"IPY_MODEL_b541932bda37446182c92f50329b9193"}},"45a3ea0eb10f456cb925e2a629352fd1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"470f7794777b48cb9ba04b21e21fa750":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bb9f039f5174245a695c79f89d95345":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c026d6070204bfaa827d02c50ba0e00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eed3de26550b4d8fa07f818d04dc8b22","placeholder":"​","style":"IPY_MODEL_fce13ca558264fe2bd88fa7079b86af3","value":"tokenizer.json: "}},"4c1b12dfe5614661973ec3fee1065d11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acd5a4b1eb9c471b9c270765a4b1814c","placeholder":"​","style":"IPY_MODEL_03a1d102e9684912ba78b50bd429d69a","value":"README.md: "}},"4f60165293d24f38ba4863abc7fee29d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_759feddd5a9842a9b8e4b2e3a34b4bed","placeholder":"​","style":"IPY_MODEL_0cfcd68d23fc404b81c313c6e2d40f6d","value":"sentence_bert_config.json: 100%"}},"4fae92e8a4d34e469efb2501a8393dcc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5852f9ad37f64dd1966f7284c1b1e780":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59d07cb22dc941aeb09e47397c5df579":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bd9f6bf82ac40bb8435e9087923e201","placeholder":"​","style":"IPY_MODEL_0f211a9edfda45bb9afd17169f0e860a","value":"vocab.txt: "}},"604bc8e427944da78af3b2867930d43c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62439ec205ab4ffaa0b80447964257ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"661317923f144e4ab35c1c98f14c2aa2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f722d8ce12144fbba1906a2adca05ce","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1bd9f85f22134eb590d4b229be09ef05","value":112}},"664e6896797f4915b2ff6f2f2ba6b1cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c1b12dfe5614661973ec3fee1065d11","IPY_MODEL_6a528ee46de94434bd30bd62af1745aa","IPY_MODEL_20a10c30bcc34e6eb3087fa5a71afead"],"layout":"IPY_MODEL_d1133354fc4d44c49f8e2df90e79a225"}},"66eee02ec1404767802e2fb91a961cfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6905ae290e204634ab144de7f8e86235","IPY_MODEL_f2eca5f8157b4dc19398e848794fa1f4","IPY_MODEL_9643f22a76d24fefbaa0b545175d874f"],"layout":"IPY_MODEL_1ffb13c74ee543819d9375a7f90f0b09"}},"6905ae290e204634ab144de7f8e86235":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9fb8ef68be84829ba3a4f2767c50dfe","placeholder":"​","style":"IPY_MODEL_e4958389e1324dcf96260c8d08dcd33f","value":"model.safetensors: 100%"}},"6a478368fa02461bbdf41bc4230abe9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a528ee46de94434bd30bd62af1745aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbbed00dd239452e851710c7822a7c21","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26ed36f52652471f9d15c8c86ac85eb8","value":1}},"6dee2a6bd3d24f1e88c6d8f63af523c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f4b5eb9f8ec404db0eba1eeeb863961":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fae92e8a4d34e469efb2501a8393dcc","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f0a4b774d454f43bd01d05d452e3a45","value":612}},"70703871283249e4b794287e0df93736":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"725c91296b4f440aac36386bc3cdbf74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"74ea1485b6464ced93468139862884d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_725c91296b4f440aac36386bc3cdbf74","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a478368fa02461bbdf41bc4230abe9b","value":1}},"759feddd5a9842a9b8e4b2e3a34b4bed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79f6864ae2c94373b8fae469e4937724":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f4383d34f7643e89fd39593d2b20014":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0765501ff35e487091bc4b51482cb61e","placeholder":"​","style":"IPY_MODEL_86997c9f7b1c41b687abe5f1d94b34e5","value":" 350/350 [00:00&lt;00:00, 22.5kB/s]"}},"808a98d0ad2e459e86261bfdcaa47164":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a7207ba41ad4bfda97020aa046ea153","IPY_MODEL_f4080c3f23304c31aba573debec374e6","IPY_MODEL_7f4383d34f7643e89fd39593d2b20014"],"layout":"IPY_MODEL_d97912bcca1c4ff3961aa987c80fa791"}},"86398427d4ff488aaf4f4885939fecd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_272cec19191a407eba9aca392c300d0b","placeholder":"​","style":"IPY_MODEL_f074ee191bb6408ab7ab6c261546741f","value":" 232k/? [00:00&lt;00:00, 6.11MB/s]"}},"86997c9f7b1c41b687abe5f1d94b34e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a854b67345146c9b2272422a3b15253":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59d07cb22dc941aeb09e47397c5df579","IPY_MODEL_74ea1485b6464ced93468139862884d7","IPY_MODEL_86398427d4ff488aaf4f4885939fecd7"],"layout":"IPY_MODEL_0cde91ad6d8f4cd0b0f5bf70dc1a504d"}},"8a8b3cc74b204f18a79b795fca6d3a46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b344a352b2d42739683d6b856f5235f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91a90939c1554e8fba754af639f680b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"92bb196ac29642cb922c263391d17f9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d67fb7cecdd47b689ab952f44216e8e","placeholder":"​","style":"IPY_MODEL_62439ec205ab4ffaa0b80447964257ef","value":" 349/349 [00:00&lt;00:00, 31.1kB/s]"}},"9643f22a76d24fefbaa0b545175d874f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecdc34cea2354eec9e73326f2d88e783","placeholder":"​","style":"IPY_MODEL_9f209bfbb53340b181ba20565e072c10","value":" 90.9M/90.9M [00:01&lt;00:00, 100MB/s]"}},"98766379eb324797ab0fa7d3632fe7c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08cd2ccfeefa44299ef9c32af8e3b547","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd801a4375bb4df39e2c19379a746a91","value":53}},"99025d20b74c40d18fb234eb7e36d3f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7bad02a417c49c0bb0e002d58365e79","IPY_MODEL_6f4b5eb9f8ec404db0eba1eeeb863961","IPY_MODEL_9e0c7d07304a428689e5dd6b76338e12"],"layout":"IPY_MODEL_a29771d7e69b45ec86d2e7c5997c8425"}},"9b06c87e953145c490346a7be7ce8803":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b54557d71414731b3f85e123c0e6738":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f60165293d24f38ba4863abc7fee29d","IPY_MODEL_98766379eb324797ab0fa7d3632fe7c2","IPY_MODEL_9db7e8d254734a0fbd638ba5a7552035"],"layout":"IPY_MODEL_cd5ce3ff2b314e51bff41603395c1e98"}},"9d67fb7cecdd47b689ab952f44216e8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9db7e8d254734a0fbd638ba5a7552035":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32da07357965400bbf44d40662a13a54","placeholder":"​","style":"IPY_MODEL_08f2c5fd71b747b9b82cc6a051f43f5d","value":" 53.0/53.0 [00:00&lt;00:00, 3.09kB/s]"}},"9e0c7d07304a428689e5dd6b76338e12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b516cbc50a264aa89f606c2744d1d076","placeholder":"​","style":"IPY_MODEL_0d68c215f8fc47cc9f288e4edff193bb","value":" 612/612 [00:00&lt;00:00, 55.5kB/s]"}},"9f209bfbb53340b181ba20565e072c10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a29771d7e69b45ec86d2e7c5997c8425":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3a892523129473bbef023f38310a43a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a588b2220ce04968ad18efeaf2740f4f","placeholder":"​","style":"IPY_MODEL_8a8b3cc74b204f18a79b795fca6d3a46","value":"config.json: 100%"}},"a54ea7a38d6c41a7835e6ac7b36ac1ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5852f9ad37f64dd1966f7284c1b1e780","placeholder":"​","style":"IPY_MODEL_a73a9932364245fdb0c6d21489168e34","value":"special_tokens_map.json: 100%"}},"a588b2220ce04968ad18efeaf2740f4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a67d38aa6bda4dc7863cfd3cd7cb3f49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c026d6070204bfaa827d02c50ba0e00","IPY_MODEL_2b6c0fbcabb144bbbbd99660bfb2cb2d","IPY_MODEL_fb6d9aecb92d47e39e0acdff9ad0362e"],"layout":"IPY_MODEL_34b51f3c89314464bd7f5ac40db930e1"}},"a73a9932364245fdb0c6d21489168e34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8016c7b7ddf4482b9eeef04789b6212":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbe71ab850884cc2a6dcd0d226986194","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_280da422dffd48b18b6f41029e878d02","value":116}},"a9af02ed91f14b289de14d1e2f5b423f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac3a76f2efaa4222a4c0de4ab3d68488":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a54ea7a38d6c41a7835e6ac7b36ac1ea","IPY_MODEL_661317923f144e4ab35c1c98f14c2aa2","IPY_MODEL_de6ad47623484fc79a76aa6e5dc97939"],"layout":"IPY_MODEL_eb78df2038ed457494e42751aa153ea7"}},"ac9ddcbaa56f4740a8d406aa35784abb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acd5a4b1eb9c471b9c270765a4b1814c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b24f5e7fec9543ffa3f502135c042ff9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45a3ea0eb10f456cb925e2a629352fd1","placeholder":"​","style":"IPY_MODEL_c2b9dcec16324d63a69837ea28d47e00","value":" 190/190 [00:00&lt;00:00, 9.42kB/s]"}},"b516cbc50a264aa89f606c2744d1d076":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b541932bda37446182c92f50329b9193":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7bad02a417c49c0bb0e002d58365e79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3642add690b64b1c925eb095a1445026","placeholder":"​","style":"IPY_MODEL_d14461776fe5406a8d1e8d0484b8ed66","value":"config.json: 100%"}},"b9fb8ef68be84829ba3a4f2767c50dfe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbd35eb777974fe28fe2f7b3c18babcc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac9ddcbaa56f4740a8d406aa35784abb","placeholder":"​","style":"IPY_MODEL_9b06c87e953145c490346a7be7ce8803","value":"modules.json: 100%"}},"bd801a4375bb4df39e2c19379a746a91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2b9dcec16324d63a69837ea28d47e00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7335ba7e0d74506a198cc40a383955f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbe71ab850884cc2a6dcd0d226986194":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd5ce3ff2b314e51bff41603395c1e98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfe222934ee34f58b930e0d66776a085":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d003c44c1d964fe1b74dc16e4cae7184":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d033c5629a804e1ca2cb4409d82f1564":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1133354fc4d44c49f8e2df90e79a225":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d14461776fe5406a8d1e8d0484b8ed66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d51727dd1827439a8c29974ef94189fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d97912bcca1c4ff3961aa987c80fa791":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbbed00dd239452e851710c7822a7c21":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"de6ad47623484fc79a76aa6e5dc97939":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79f6864ae2c94373b8fae469e4937724","placeholder":"​","style":"IPY_MODEL_c7335ba7e0d74506a198cc40a383955f","value":" 112/112 [00:00&lt;00:00, 7.44kB/s]"}},"e4958389e1324dcf96260c8d08dcd33f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea4c11f7ca2f457f8703c219564256f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b344a352b2d42739683d6b856f5235f","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0334d9bdc8814160811cfde584ed242a","value":190}},"eb78df2038ed457494e42751aa153ea7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecdc34cea2354eec9e73326f2d88e783":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed3de26550b4d8fa07f818d04dc8b22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eef82c807adf45ee8b1ef026a3c469a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a3a892523129473bbef023f38310a43a","IPY_MODEL_ea4c11f7ca2f457f8703c219564256f6","IPY_MODEL_b24f5e7fec9543ffa3f502135c042ff9"],"layout":"IPY_MODEL_604bc8e427944da78af3b2867930d43c"}},"f074ee191bb6408ab7ab6c261546741f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2eca5f8157b4dc19398e848794fa1f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d51727dd1827439a8c29974ef94189fa","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00ea95a09e804b51bc9afa1660a5e846","value":90868376}},"f4080c3f23304c31aba573debec374e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d003c44c1d964fe1b74dc16e4cae7184","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91a90939c1554e8fba754af639f680b2","value":350}},"f58478fe8b074fc99e24d05d8d66304b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f677109fef634d94a0b56f4be2a9b8fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f995aec1a6104b39887cd75115b0fe95","IPY_MODEL_a8016c7b7ddf4482b9eeef04789b6212","IPY_MODEL_2b66102cd510401696f3c327b2bc0ec8"],"layout":"IPY_MODEL_a9af02ed91f14b289de14d1e2f5b423f"}},"f995aec1a6104b39887cd75115b0fe95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dee2a6bd3d24f1e88c6d8f63af523c7","placeholder":"​","style":"IPY_MODEL_470f7794777b48cb9ba04b21e21fa750","value":"config_sentence_transformers.json: 100%"}},"fb6d9aecb92d47e39e0acdff9ad0362e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfe222934ee34f58b930e0d66776a085","placeholder":"​","style":"IPY_MODEL_20d1dbad5442498787b1a03a9b2d8de2","value":" 466k/? [00:00&lt;00:00, 16.2MB/s]"}},"fce13ca558264fe2bd88fa7079b86af3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5080609b39e4ff9a3bd20bae2347126":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e836a7beee85433ebdc2a896fe4b3ca4","IPY_MODEL_2dbd8323f4c245199b5402bd81382bf4","IPY_MODEL_52c2fa68b6c74b0f9a58df7b0f82e1fa"],"layout":"IPY_MODEL_cba2d71af7aa41d390a9674a8612b188"}},"e836a7beee85433ebdc2a896fe4b3ca4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4ff940199924007bd8a77b58d8c1f03","placeholder":"​","style":"IPY_MODEL_dc98714e6cc14f0aa0680b551b93a660","value":"modules.json: 100%"}},"2dbd8323f4c245199b5402bd81382bf4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c5da1397c3d4d9496253482648f5cbb","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb32e6ae4f55415fa15e3637fe0bcbbe","value":349}},"52c2fa68b6c74b0f9a58df7b0f82e1fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9295985b250642fc85943e27784751f6","placeholder":"​","style":"IPY_MODEL_e3a113a5bacb417fb34a8683a2666e7e","value":" 349/349 [00:00&lt;00:00, 19.2kB/s]"}},"cba2d71af7aa41d390a9674a8612b188":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4ff940199924007bd8a77b58d8c1f03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc98714e6cc14f0aa0680b551b93a660":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c5da1397c3d4d9496253482648f5cbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb32e6ae4f55415fa15e3637fe0bcbbe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9295985b250642fc85943e27784751f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3a113a5bacb417fb34a8683a2666e7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d33668328ed34224ba372365b65edeb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d37dc10cbb1c40d2bedb804b1b9ae645","IPY_MODEL_eb535af16ce9493fa8dea754f5675599","IPY_MODEL_3591d06ab5f1400096c1bbe48f9897a2"],"layout":"IPY_MODEL_793bd6da3ced4cb0a06a57b2a91d8242"}},"d37dc10cbb1c40d2bedb804b1b9ae645":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6be7eb99915643d7951ac281b1e8b365","placeholder":"​","style":"IPY_MODEL_9b22bff7015d47f0a7b77f5cbb72ee85","value":"config_sentence_transformers.json: 100%"}},"eb535af16ce9493fa8dea754f5675599":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfcdecb68cd44e8b8a950e47c5ca2ebc","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8921f1754cbb442db29d19e6b6d2ce63","value":116}},"3591d06ab5f1400096c1bbe48f9897a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_faf5cd0d577e42ad93ccff39042b5fcd","placeholder":"​","style":"IPY_MODEL_2921be2fe7044b5d8409a71be3160df6","value":" 116/116 [00:00&lt;00:00, 5.27kB/s]"}},"793bd6da3ced4cb0a06a57b2a91d8242":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6be7eb99915643d7951ac281b1e8b365":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b22bff7015d47f0a7b77f5cbb72ee85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfcdecb68cd44e8b8a950e47c5ca2ebc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8921f1754cbb442db29d19e6b6d2ce63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"faf5cd0d577e42ad93ccff39042b5fcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2921be2fe7044b5d8409a71be3160df6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"536983a8c5a54b3cab3b233761245837":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a8ea87253db41bdb9312a337e509fd2","IPY_MODEL_884552d755644bfd85cf290e370d76d7","IPY_MODEL_eed22dfc29bf4db39f9518c2ae55ccfc"],"layout":"IPY_MODEL_a414a478cde74942b2605a992a3599c0"}},"8a8ea87253db41bdb9312a337e509fd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a48dedb3078d493b920c6f79eda9cbbf","placeholder":"​","style":"IPY_MODEL_5c7683de9b574a4297819dc8b78cab58","value":"README.md: "}},"884552d755644bfd85cf290e370d76d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e83b005a5e544d6b6ca30134936365c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ad8eab90bcf4406bdeadc042b9d07a6","value":1}},"eed22dfc29bf4db39f9518c2ae55ccfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66aab399efcc42939299802d3853cc7d","placeholder":"​","style":"IPY_MODEL_e8948019129240a68e803829cc3c9e17","value":" 10.5k/? [00:00&lt;00:00, 381kB/s]"}},"a414a478cde74942b2605a992a3599c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a48dedb3078d493b920c6f79eda9cbbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c7683de9b574a4297819dc8b78cab58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e83b005a5e544d6b6ca30134936365c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1ad8eab90bcf4406bdeadc042b9d07a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66aab399efcc42939299802d3853cc7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8948019129240a68e803829cc3c9e17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d842eca30b1a4cf6a2ce2f1a68e01509":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e8145e3e8674ac1b3cead063169e5c7","IPY_MODEL_43dbece4033c4149830ad329b33e0a01","IPY_MODEL_7ab6025a96a947f4834bea2b925aa6ce"],"layout":"IPY_MODEL_c3b8541027364377aef8f2534beec592"}},"1e8145e3e8674ac1b3cead063169e5c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b3ff548d2f0499e9b561ca570d976fe","placeholder":"​","style":"IPY_MODEL_8eb3447fac8e4702b4f780552403b4fd","value":"sentence_bert_config.json: 100%"}},"43dbece4033c4149830ad329b33e0a01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c21ab3aee934241ad3b571a3b572b65","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fb4b5e77ffa488aaa30a9fae6b9b6b7","value":53}},"7ab6025a96a947f4834bea2b925aa6ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83518cd2b0bf4f03af1892fcea6db259","placeholder":"​","style":"IPY_MODEL_b031d42457de4c1091896dc9ba762cff","value":" 53.0/53.0 [00:00&lt;00:00, 4.67kB/s]"}},"c3b8541027364377aef8f2534beec592":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b3ff548d2f0499e9b561ca570d976fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eb3447fac8e4702b4f780552403b4fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c21ab3aee934241ad3b571a3b572b65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fb4b5e77ffa488aaa30a9fae6b9b6b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83518cd2b0bf4f03af1892fcea6db259":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b031d42457de4c1091896dc9ba762cff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b4710e02340428faee8e13e3ad14d36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_79b6c9b5be9e4b83a7109e64fd58b130","IPY_MODEL_66ea787eb5dd4616b2091daf21faaa1d","IPY_MODEL_d9e1368524e248e1b4b3332fe17ec0f5"],"layout":"IPY_MODEL_707ee970053545eabe2d20b1b6eb6dc0"}},"79b6c9b5be9e4b83a7109e64fd58b130":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c7792d4201a46d5ab3e9e1213ab771a","placeholder":"​","style":"IPY_MODEL_0452546088934d918fee58c18e53a42a","value":"config.json: 100%"}},"66ea787eb5dd4616b2091daf21faaa1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8e585a2a1434c7e8976b9b3ce012cda","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e81d69b433b44281b07f5732c687da9b","value":612}},"d9e1368524e248e1b4b3332fe17ec0f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a52b4d648aa0471cb27fd2887e076ceb","placeholder":"​","style":"IPY_MODEL_33f473a00b5846629868aaa6867384aa","value":" 612/612 [00:00&lt;00:00, 55.3kB/s]"}},"707ee970053545eabe2d20b1b6eb6dc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c7792d4201a46d5ab3e9e1213ab771a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0452546088934d918fee58c18e53a42a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8e585a2a1434c7e8976b9b3ce012cda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e81d69b433b44281b07f5732c687da9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a52b4d648aa0471cb27fd2887e076ceb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33f473a00b5846629868aaa6867384aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e46abfbd1dd4b429f1720fb50f03624":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca13102344d745449327b2778f2c9994","IPY_MODEL_0936b6f84d41438db2d59521616eb111","IPY_MODEL_7426018c73f9462db4eb9d5da46c5ace"],"layout":"IPY_MODEL_b8d6d3a359cc4430a1c7e27942cb1137"}},"ca13102344d745449327b2778f2c9994":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6877f43997bb461f97f10b04698f6d19","placeholder":"​","style":"IPY_MODEL_84f3743b67cc42f0bc8a547e1347f2c0","value":"model.safetensors: 100%"}},"0936b6f84d41438db2d59521616eb111":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc9a786f345d45299c4dd8e74e2a6dff","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e2efd46146d4e508efb760f7bc76d83","value":90868376}},"7426018c73f9462db4eb9d5da46c5ace":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aaeb73fc742d43d6a53ec7be27cb6b38","placeholder":"​","style":"IPY_MODEL_5152966c0af346bf87c424c73ecae010","value":" 90.9M/90.9M [00:01&lt;00:00, 65.6MB/s]"}},"b8d6d3a359cc4430a1c7e27942cb1137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6877f43997bb461f97f10b04698f6d19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84f3743b67cc42f0bc8a547e1347f2c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc9a786f345d45299c4dd8e74e2a6dff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e2efd46146d4e508efb760f7bc76d83":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aaeb73fc742d43d6a53ec7be27cb6b38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5152966c0af346bf87c424c73ecae010":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdecca07237445a4b9025514cf462816":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c55b80693104542adddcb860f3e31f5","IPY_MODEL_e1e98839e1cc420cbb7e1da4f4325c9b","IPY_MODEL_a1c6b2c1d2c04f268ae969239786ec24"],"layout":"IPY_MODEL_7dd52bc4e7954b95b5fc0263731cd42d"}},"8c55b80693104542adddcb860f3e31f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a27500cfbe454e83915ea07df22020df","placeholder":"​","style":"IPY_MODEL_9672e3df91df45b594039698a7b54408","value":"tokenizer_config.json: 100%"}},"e1e98839e1cc420cbb7e1da4f4325c9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c26af8c96463423e85fcfb17ce55c4a0","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72c75a9a3c43463b80e678b05c620cf4","value":350}},"a1c6b2c1d2c04f268ae969239786ec24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c99f6e1e7f7465e86c34f57f076da76","placeholder":"​","style":"IPY_MODEL_96a2ce6a2ebb4eb480b3c4af60adec7d","value":" 350/350 [00:00&lt;00:00, 16.3kB/s]"}},"7dd52bc4e7954b95b5fc0263731cd42d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a27500cfbe454e83915ea07df22020df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9672e3df91df45b594039698a7b54408":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c26af8c96463423e85fcfb17ce55c4a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72c75a9a3c43463b80e678b05c620cf4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c99f6e1e7f7465e86c34f57f076da76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96a2ce6a2ebb4eb480b3c4af60adec7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"027fe5448b3a494ebe0a475630dca320":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f6b28bfa35549d3aa384591cdb9d969","IPY_MODEL_04e49d1bf12d474faed565246d33583e","IPY_MODEL_689672ad7c074a90b4ec1f4986510234"],"layout":"IPY_MODEL_e2f58570c43348918db67fe2ab1df318"}},"2f6b28bfa35549d3aa384591cdb9d969":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d53624f68555420baf0f0d86fad0fb9f","placeholder":"​","style":"IPY_MODEL_4d0833bdd26e431f89c360555495a2bb","value":"vocab.txt: "}},"04e49d1bf12d474faed565246d33583e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_699aa604457344bd8b6a79f28e2b5cfe","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11ecbf75d9c64211ac719abb0ed87090","value":1}},"689672ad7c074a90b4ec1f4986510234":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2a1877ed9b04b7fbf6b7b1216f86100","placeholder":"​","style":"IPY_MODEL_40fc3faa0db0495ba2524c9f32372ef0","value":" 232k/? [00:00&lt;00:00, 4.27MB/s]"}},"e2f58570c43348918db67fe2ab1df318":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d53624f68555420baf0f0d86fad0fb9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d0833bdd26e431f89c360555495a2bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"699aa604457344bd8b6a79f28e2b5cfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"11ecbf75d9c64211ac719abb0ed87090":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2a1877ed9b04b7fbf6b7b1216f86100":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40fc3faa0db0495ba2524c9f32372ef0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49af321e62554bb3b01989d299382f8f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98df43a121794c0e9ce34472d41b52bc","IPY_MODEL_2010886561dc4fe7812e563ae2fc7b50","IPY_MODEL_0cf8e8eaa7be4829aa0bd7e047a35a7c"],"layout":"IPY_MODEL_3c3477dc9dd1437b93aea8414d80af0d"}},"98df43a121794c0e9ce34472d41b52bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8b49c066ef345528c881dc9e2893a29","placeholder":"​","style":"IPY_MODEL_558f03fa306a4c0abb0c75769ab1ea2a","value":"tokenizer.json: "}},"2010886561dc4fe7812e563ae2fc7b50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2aae9b0454346edb5ca507beb395544","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a41d710b4e88463197aa1ef8db14eb58","value":1}},"0cf8e8eaa7be4829aa0bd7e047a35a7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_384d2a564d0f4f678c7311ff15bca1ea","placeholder":"​","style":"IPY_MODEL_d0e053c6aaf84fcd94114fc412c3c721","value":" 466k/? [00:00&lt;00:00, 8.27MB/s]"}},"3c3477dc9dd1437b93aea8414d80af0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8b49c066ef345528c881dc9e2893a29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"558f03fa306a4c0abb0c75769ab1ea2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2aae9b0454346edb5ca507beb395544":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a41d710b4e88463197aa1ef8db14eb58":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"384d2a564d0f4f678c7311ff15bca1ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0e053c6aaf84fcd94114fc412c3c721":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4d6c32eb478484da7943a9211cd54bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_863a2b2420ef4933b6d548d319508f1d","IPY_MODEL_8fb0e4d1599c44d9a252ada8bd2f087f","IPY_MODEL_f80322ef0e36424bb991015eab3e09bf"],"layout":"IPY_MODEL_c440012f520641c59bdd60e3af6c31a0"}},"863a2b2420ef4933b6d548d319508f1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f915cbee0ca4df1a522ec641e65557d","placeholder":"​","style":"IPY_MODEL_46af01b6418242f5bb69d365472f8bfe","value":"special_tokens_map.json: 100%"}},"8fb0e4d1599c44d9a252ada8bd2f087f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c2f18395a8f439c92e57594c6a75582","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7e97b82002940a28f319acef93ca029","value":112}},"f80322ef0e36424bb991015eab3e09bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_115f1eec2d2645a1832771e4a9bb5f05","placeholder":"​","style":"IPY_MODEL_577b9161067349e9a3d52add550e4905","value":" 112/112 [00:00&lt;00:00, 5.05kB/s]"}},"c440012f520641c59bdd60e3af6c31a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f915cbee0ca4df1a522ec641e65557d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46af01b6418242f5bb69d365472f8bfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c2f18395a8f439c92e57594c6a75582":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7e97b82002940a28f319acef93ca029":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"115f1eec2d2645a1832771e4a9bb5f05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"577b9161067349e9a3d52add550e4905":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"316628db0e4b4c1cb42b64e1b882698a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa7b107841c14c71af37d671c0e47c92","IPY_MODEL_c75a24b86ce64a11be23d0c810c73721","IPY_MODEL_b6f78813effa4bf08292dd09270ba2c6"],"layout":"IPY_MODEL_df4cec9c4f344f1ea4135f11a00b015c"}},"aa7b107841c14c71af37d671c0e47c92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f6e223b00d14f348d4d7c5bcc310464","placeholder":"​","style":"IPY_MODEL_3baf3ee1d9e0441ba59ce2ba4a35c5d9","value":"config.json: 100%"}},"c75a24b86ce64a11be23d0c810c73721":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_280a1fc2709242998c178f7e39303bdf","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adea9ec407114e01b11333339dabb183","value":190}},"b6f78813effa4bf08292dd09270ba2c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23159f16cf53407c99851b9147b41a7b","placeholder":"​","style":"IPY_MODEL_810f3cc2d32645bc827f48cbc9261a2f","value":" 190/190 [00:00&lt;00:00, 8.24kB/s]"}},"df4cec9c4f344f1ea4135f11a00b015c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f6e223b00d14f348d4d7c5bcc310464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3baf3ee1d9e0441ba59ce2ba4a35c5d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"280a1fc2709242998c178f7e39303bdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adea9ec407114e01b11333339dabb183":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23159f16cf53407c99851b9147b41a7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"810f3cc2d32645bc827f48cbc9261a2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49c4d6c7ac59449f8a281a4e556b3599":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b03837f2824e413d8628c5c880c65ff1","IPY_MODEL_390ee2d551f44ec1afe3245eedef5605","IPY_MODEL_30803759b88f45cd89e972a8c65438a0"],"layout":"IPY_MODEL_973939450a604b11814657aa6b87896b"}},"b03837f2824e413d8628c5c880c65ff1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91221915f629449aaddcd6e0737bf7a1","placeholder":"​","style":"IPY_MODEL_21e8dd6c0c63417da3d3922b8f22ca62","value":"config.json: 100%"}},"390ee2d551f44ec1afe3245eedef5605":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c707bfc96cc144ef84bb9e44f549f355","max":794,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c657f06cd0f24ac8b616c476ce2835de","value":794}},"30803759b88f45cd89e972a8c65438a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5f877f3212747a48419ee3768e59732","placeholder":"​","style":"IPY_MODEL_e2c11c24b1d54e8d899883a4f7341d25","value":" 794/794 [00:00&lt;00:00, 65.5kB/s]"}},"973939450a604b11814657aa6b87896b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91221915f629449aaddcd6e0737bf7a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21e8dd6c0c63417da3d3922b8f22ca62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c707bfc96cc144ef84bb9e44f549f355":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c657f06cd0f24ac8b616c476ce2835de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5f877f3212747a48419ee3768e59732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2c11c24b1d54e8d899883a4f7341d25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01698688b9564a2cad47d46ec33f9818":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71df578ded3943d8a1b6e01003f74de8","IPY_MODEL_9fb63ba1021f4ed3b941bbc2a4644965","IPY_MODEL_b8f217dceacc4bf1a573a148638635fc"],"layout":"IPY_MODEL_9562360ae28c47179f0d4805a1e55010"}},"71df578ded3943d8a1b6e01003f74de8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08d7bebe9e244980814346a045634234","placeholder":"​","style":"IPY_MODEL_998530fbc77b4d43aafa36f60172ae9a","value":"model.safetensors: 100%"}},"9fb63ba1021f4ed3b941bbc2a4644965":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d40490dbc9f431b8ddad5f6855dd2b3","max":90870598,"min":0,"orientation":"horizontal","style":"IPY_MODEL_805a997cfcdd4d01be01af1bf6ca6499","value":90870598}},"b8f217dceacc4bf1a573a148638635fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fd8ff8e93844f5b88f8372ffdbb4774","placeholder":"​","style":"IPY_MODEL_e3912d2e5d944dba8dd26e3fe82a299d","value":" 90.9M/90.9M [00:01&lt;00:00, 79.4MB/s]"}},"9562360ae28c47179f0d4805a1e55010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08d7bebe9e244980814346a045634234":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"998530fbc77b4d43aafa36f60172ae9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d40490dbc9f431b8ddad5f6855dd2b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"805a997cfcdd4d01be01af1bf6ca6499":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fd8ff8e93844f5b88f8372ffdbb4774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3912d2e5d944dba8dd26e3fe82a299d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc9aca68aae940a6ad9d9adc692e46bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a87956263fe4e3bad8a562ec9b80ff6","IPY_MODEL_39338c83bc07410e9f764ad2a440bd5b","IPY_MODEL_a108d5ed7400424da90debebe2161f7a"],"layout":"IPY_MODEL_e01cb4ef7a004b13a4b45df0004f4e33"}},"0a87956263fe4e3bad8a562ec9b80ff6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8105af9e0a94459cb5cc9420d608d3cc","placeholder":"​","style":"IPY_MODEL_72acddf30c004fbfa8716fedae8ca43a","value":"tokenizer_config.json: "}},"39338c83bc07410e9f764ad2a440bd5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cebd7689b672469bb7332577d735524f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc34b52c5c3241d0a35081092c485366","value":1}},"a108d5ed7400424da90debebe2161f7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac0246572ab04cae954c2eb5801e664b","placeholder":"​","style":"IPY_MODEL_bf70eccc23ba4269b7d2d13901e15c61","value":" 1.33k/? [00:00&lt;00:00, 89.4kB/s]"}},"e01cb4ef7a004b13a4b45df0004f4e33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8105af9e0a94459cb5cc9420d608d3cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72acddf30c004fbfa8716fedae8ca43a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cebd7689b672469bb7332577d735524f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bc34b52c5c3241d0a35081092c485366":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac0246572ab04cae954c2eb5801e664b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf70eccc23ba4269b7d2d13901e15c61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40359639360a43b197556edd41110188":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7363a0ba63cd40d384504a1af5b3253c","IPY_MODEL_7dd8bcfc14474fd6a7874fc8c40d04f1","IPY_MODEL_404c49b2c1084722b2bb407fb7d678d4"],"layout":"IPY_MODEL_07729278440a47c8b050a79bb2859360"}},"7363a0ba63cd40d384504a1af5b3253c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d31a2821d0a34a8589ea745575f2e782","placeholder":"​","style":"IPY_MODEL_4b23eb0af8024fb9aaab03d1f1152ecd","value":"vocab.txt: "}},"7dd8bcfc14474fd6a7874fc8c40d04f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51f51033869747b9bd0adbf970fc2a30","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c490e3bb81dc49cb9a6d3c7ab8e82fd1","value":1}},"404c49b2c1084722b2bb407fb7d678d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c40852fb47d049ce82d846c4489173df","placeholder":"​","style":"IPY_MODEL_c6af4323688844b58cf7c9336708248a","value":" 232k/? [00:00&lt;00:00, 12.4MB/s]"}},"07729278440a47c8b050a79bb2859360":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d31a2821d0a34a8589ea745575f2e782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b23eb0af8024fb9aaab03d1f1152ecd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51f51033869747b9bd0adbf970fc2a30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c490e3bb81dc49cb9a6d3c7ab8e82fd1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c40852fb47d049ce82d846c4489173df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6af4323688844b58cf7c9336708248a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29389ce93a1e4550bc02ad07e0a81a95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aef1a9a1446b476e95a7ddd4e390a564","IPY_MODEL_a6dcc38f48174a4796fe67729c51b6c9","IPY_MODEL_ae479e805f8448fd871f2299abf7383c"],"layout":"IPY_MODEL_4f697e3a2aaf49b2a102ba74e420bf5a"}},"aef1a9a1446b476e95a7ddd4e390a564":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_385897c94028481d80b9e4a3a2fc704b","placeholder":"​","style":"IPY_MODEL_8f8d5becbc1d43e89793be1317433e86","value":"tokenizer.json: "}},"a6dcc38f48174a4796fe67729c51b6c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_143fbe895b3c417ca789d4f6e7274645","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f101adcd262d452d886c722ed6e9b489","value":1}},"ae479e805f8448fd871f2299abf7383c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68dca70ac9734cc88a61740eddcbe371","placeholder":"​","style":"IPY_MODEL_37c6dfb7671b47b191e688cf0bbda54d","value":" 711k/? [00:00&lt;00:00, 22.7MB/s]"}},"4f697e3a2aaf49b2a102ba74e420bf5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"385897c94028481d80b9e4a3a2fc704b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f8d5becbc1d43e89793be1317433e86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"143fbe895b3c417ca789d4f6e7274645":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f101adcd262d452d886c722ed6e9b489":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68dca70ac9734cc88a61740eddcbe371":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37c6dfb7671b47b191e688cf0bbda54d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d5f687cb3e54f3b8eb533a0a10988f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_193103746d2c4bf19438105fd9d5cbb8","IPY_MODEL_1998fc7ee068466c90d8c840bf98e315","IPY_MODEL_d2ac96714e604d76b99cffd0a29d77c0"],"layout":"IPY_MODEL_df104bcae27e414ebc33acd6628b56b8"}},"193103746d2c4bf19438105fd9d5cbb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a2ecd187cd44a809dc2975d2177bac2","placeholder":"​","style":"IPY_MODEL_92b40202a42e4bdf8e0722f6f8db8184","value":"special_tokens_map.json: 100%"}},"1998fc7ee068466c90d8c840bf98e315":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_536ee2f14c7b473b873fc4c2b45f194f","max":132,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92ec5337b5fa4f0587cf96ddb627c2d7","value":132}},"d2ac96714e604d76b99cffd0a29d77c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8986eb158cf44ab98697c440b2b4d971","placeholder":"​","style":"IPY_MODEL_d979d8baa7be40f282a565b6bca45bab","value":" 132/132 [00:00&lt;00:00, 9.10kB/s]"}},"df104bcae27e414ebc33acd6628b56b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a2ecd187cd44a809dc2975d2177bac2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92b40202a42e4bdf8e0722f6f8db8184":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"536ee2f14c7b473b873fc4c2b45f194f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92ec5337b5fa4f0587cf96ddb627c2d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8986eb158cf44ab98697c440b2b4d971":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d979d8baa7be40f282a565b6bca45bab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"610cfc723c974ee5832454bee61d4e61":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3169a440a7ea43818eecb37ad779d3aa","IPY_MODEL_53a9cc27dd47418eac0420d435f4a2e7","IPY_MODEL_927fac3c4231465f8fcafc4b9b4331bb"],"layout":"IPY_MODEL_d9f55e3fec374c7bb16b46334d7a1534"}},"3169a440a7ea43818eecb37ad779d3aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec878925cd814566abcd4a590e146c70","placeholder":"​","style":"IPY_MODEL_f5a55ad7d68b4540803c193309c8679b","value":"README.md: "}},"53a9cc27dd47418eac0420d435f4a2e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b51c6c1d1a041a38334cd8e95d89d11","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d58e49da203349ef849295556bed7a04","value":1}},"927fac3c4231465f8fcafc4b9b4331bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f8a83028cea4967a7213b4d4e02b883","placeholder":"​","style":"IPY_MODEL_9aefa4d856764e3194dfe13f753dccce","value":" 3.66k/? [00:00&lt;00:00, 332kB/s]"}},"d9f55e3fec374c7bb16b46334d7a1534":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec878925cd814566abcd4a590e146c70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5a55ad7d68b4540803c193309c8679b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b51c6c1d1a041a38334cd8e95d89d11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d58e49da203349ef849295556bed7a04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f8a83028cea4967a7213b4d4e02b883":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aefa4d856764e3194dfe13f753dccce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}