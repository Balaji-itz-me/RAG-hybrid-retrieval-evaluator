import streamlit as st
import requests
import json
from datetime import datetime
import time

# Page configuration
st.set_page_config(
    page_title="Conversational RAG System",
    page_icon="🤖",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
.main-header {
    font-size: 2.5rem;
    color: #1f77b4;
    text-align: center;
    margin-bottom: 1rem;
    font-weight: 600;
}

.chat-message {
    padding: 1rem;
    border-radius: 10px;
    margin: 1rem 0;
    border-left: 4px solid #1f77b4;
}

.user-message {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-left: 4px solid #667eea;
    margin-left: 2rem;
}

.bot-message {
    background: #f8f9fa;
    color: #333;
    border-left: 4px solid #28a745;
}

.source-chip {
    display: inline-block;
    background: #e3f2fd;
    color: #1976d2;
    padding: 0.2rem 0.5rem;
    border-radius: 15px;
    font-size: 0.8rem;
    margin: 0.2rem;
    border: 1px solid #1976d2;
}

.metrics-container {
    background: #f0f2f6;
    padding: 1rem;
    border-radius: 10px;
    margin: 1rem 0;
}
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'session_id' not in st.session_state:
    st.session_state.session_id = None

# Mock RAG API call (replace with your actual API)
def call_rag_api(message, use_dynamic=True, top_k=3):
    """
    Replace this function with your actual RAG API call
    For now, returns mock data to demonstrate the interface
    """
    # Simulate API delay
    time.sleep(1)
    
    # Mock response - replace with actual API call
    #mock_response = {
        #"session_id": "demo-session-123",
        #"response": {
            ##"answer": {
               # "content": f"This is a mock response to your question: '{message}'. In a real implementation, this would be generated by your RAG system using retrieval-augmented generation with context from your knowledge base.",
              #  "role": "assistant"
          #  },
#"sources": [
             #   "https://example.com/source1",
             ##   "https://example.com/source2",
                "https://example.com/source3"
           # ],
          #  "metadata": {
           #     "num_docs_retrieved": top_k,
            #    "response_time": "1.2s",
            #    "confidence": 0.94
          #  }
     #   }
   # }
    
  # Modify this for your actual API:
try:
    response = requests.post(
        "https://ecc9e5b8fbd7.ngrok-free.app/api/v1/chat",   # <-- replace with your Colab ngrok URL
        headers={"Authorization": "Bearer demo-api-key-123"}, # <-- use your real API key
        json={
            "messages": [{"role": "user", "content": message}],
            "session_id": st.session_state.session_id,
            "use_dynamic_index": use_dynamic,
            "top_k": top_k
        }
    )
    return response.json()
except Exception as e:
    st.error(f"API Error: {str(e)}")
    return None

    
    return mock_response

def display_message(role, content, sources=None, metadata=None):
    """Display a chat message with proper styling"""
    if role == "user":
        st.markdown(f"""
        <div class="chat-message user-message">
            <strong>👤 You:</strong><br>
            {content}
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chat-message bot-message">
            <strong>🤖 Assistant:</strong><br>
            {content}
        </div>
        """, unsafe_allow_html=True)
        
        if sources:
            st.markdown("**📚 Sources:**")
            sources_html = ""
            for i, source in enumerate(sources[:3], 1):  # Show max 3 sources
                sources_html += f'<span class="source-chip">{i}. {source}</span>'
            st.markdown(sources_html, unsafe_allow_html=True)
        
        if metadata:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("📄 Docs Retrieved", metadata.get('num_docs_retrieved', 'N/A'))
            with col2:
                st.metric("⏱️ Response Time", metadata.get('response_time', 'N/A'))
            with col3:
                confidence = metadata.get('confidence', 0)
                if isinstance(confidence, float):
                    confidence = f"{confidence*100:.0f}%"
                st.metric("🎯 Confidence", confidence)

# Sidebar
with st.sidebar:
    st.title("🎛️ RAG Controls")
    
    # Settings
    use_dynamic_sources = st.checkbox("Use Dynamic Sources", value=True, help="Include dynamically indexed web content")
    top_k_results = st.slider("Number of Sources", min_value=1, max_value=5, value=3, help="Top-K results to retrieve")
    
    st.markdown("---")
    
    # System Info
    st.markdown("### 📊 System Status")
    st.success("🟢 System Online")
    st.info(f"💬 Messages: {len(st.session_state.messages)}")
    if st.session_state.session_id:
        st.info(f"🔗 Session: {st.session_state.session_id[:8]}...")
    
    st.markdown("---")
    
    # Quick Actions
    st.markdown("### ⚡ Quick Actions")
    if st.button("🗑️ Clear Chat"):
        st.session_state.messages = []
        st.session_state.session_id = None
        st.experimental_rerun()
    
    if st.button("📥 Export Chat"):
        if st.session_state.messages:
            chat_export = {
                "session_id": st.session_state.session_id,
                "messages": st.session_state.messages,
                "exported_at": datetime.now().isoformat()
            }
            st.download_button(
                label="💾 Download JSON",
                data=json.dumps(chat_export, indent=2),
                file_name=f"rag_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )

# Main content area
st.markdown('<h1 class="main-header">🤖 Conversational RAG System</h1>', unsafe_allow_html=True)

# Project description
with st.expander("ℹ️ About This System", expanded=False):
    st.markdown("""
    ### 🎯 What This Demonstrates:
    - **Conversational AI**: Multi-turn dialogue with context retention
    - **Retrieval-Augmented Generation**: Combines retrieval with language generation
    - **Hybrid Search**: BM25 (keyword) + FAISS (semantic) + Cross-encoder reranking
    - **Dynamic Indexing**: Real-time addition of new knowledge sources
    - **Source Citation**: Automatic attribution of information sources
    
    ### 🏗️ Technical Architecture:
    - **Backend**: FastAPI with LangChain and Google Gemini
    - **Vector Database**: FAISS for semantic search
    - **Keyword Search**: BM25 for traditional retrieval
    - **Frontend**: Streamlit for rapid prototyping
    - **Deployment**: Streamlit Cloud with AWS backend
    """)

# Chat interface
st.markdown("### 💬 Chat with the RAG System")

# Display chat history
for message in st.session_state.messages:
    display_message(
        message["role"], 
        message["content"], 
        message.get("sources"), 
        message.get("metadata")
    )

# Chat input
with st.form(key="chat_form", clear_on_submit=True):
    col1, col2 = st.columns([4, 1])
    
    with col1:
        user_input = st.text_area(
            "Ask anything about AI, machine learning, or technology...",
            placeholder="e.g., What is attention mechanism in transformers?",
            height=100,
            key="user_input"
        )
    
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)  # Add some spacing
        submit_button = st.form_submit_button("📤 Send", use_container_width=True)
        
        # Voice input placeholder (for future enhancement)
        st.button("🎤 Voice", use_container_width=True, disabled=True, help="Voice input coming soon!")

# Process user input
if submit_button and user_input.strip():
    # Add user message to chat history
    user_message = {
        "role": "user",
        "content": user_input,
        "timestamp": datetime.now().isoformat()
    }
    st.session_state.messages.append(user_message)
    
    # Display user message
    display_message("user", user_input)
    
    # Show thinking indicator
    with st.spinner("🤔 Thinking..."):
        # Call RAG API
        rag_response = call_rag_api(
            user_input, 
            use_dynamic=use_dynamic_sources,
            top_k=top_k_results
        )
    
    if rag_response:
        # Update session ID
        if not st.session_state.session_id:
            st.session_state.session_id = rag_response.get("session_id")
        
        # Extract response data
        response_data = rag_response.get("response", {})
        assistant_content = response_data.get("answer", {}).get("content", "Sorry, I couldn't generate a response.")
        sources = response_data.get("sources", [])
        metadata = response_data.get("metadata", {})
        
        # Add assistant message to chat history
        assistant_message = {
            "role": "assistant",
            "content": assistant_content,
            "sources": sources,
            "metadata": metadata,
            "timestamp": datetime.now().isoformat()
        }
        st.session_state.messages.append(assistant_message)
        
        # Display assistant message
        display_message("assistant", assistant_content, sources, metadata)
        
        # Success notification
        st.success(f"✅ Response generated in {metadata.get('response_time', 'N/A')}")
    else:
        st.error("❌ Failed to get response from RAG system")

# Footer
st.markdown("---")
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("**🏗️ Built with:**")
    st.markdown("- Python & Streamlit")
    st.markdown("- LangChain & FAISS")
    st.markdown("- Google Gemini")

with col2:
    st.markdown("**🚀 Features:**")
    st.markdown("- Conversational AI")
    st.markdown("- Source Citations")
    st.markdown("- Hybrid Search")

with col3:
    st.markdown("**📊 Portfolio Project**")
    st.markdown("Demonstrating RAG system capabilities with clean, professional interface.")

# Sample questions for first-time users
if len(st.session_state.messages) == 0:
    st.markdown("### 💡 Try These Sample Questions:")
    sample_questions = [
        "What is attention mechanism in transformers?",
        "How do RAG systems work?",
        "Explain the difference between BERT and GPT",
        "What are the challenges in building AI systems?"
    ]
    
    cols = st.columns(2)
    for i, question in enumerate(sample_questions):
        with cols[i % 2]:
            if st.button(f"💬 {question}", key=f"sample_{i}"):
                st.session_state.user_input = question
                st.experimental_rerun()
